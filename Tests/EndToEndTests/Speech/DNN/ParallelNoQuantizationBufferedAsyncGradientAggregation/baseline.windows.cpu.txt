CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU W3530 @ 2.80GHz
    Hardware threads: 4
    Total Memory: 12580404 kB
-------------------------------------------------------------------
=== Running C:\Program Files\Microsoft MPI\Bin\/mpiexec.exe -n 3 C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu DeviceId=-1 timestamping=true numCPUThreads=1 precision=double speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]] speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]] speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] speechTrain=[SGD=[maxEpochs=4]] speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]] stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Jul 14 2016 07:04:27
		Last modified date: Wed Jul 13 07:40:26 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: c:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: b918e06de12613a1773a0976ab94e213bd09ce52
		Built by svcphil on cntk-muc01
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Jul 14 2016 07:04:27
		Last modified date: Wed Jul 13 07:40:26 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: c:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: b918e06de12613a1773a0976ab94e213bd09ce52
		Built by svcphil on cntk-muc01
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Jul 14 2016 07:04:27
		Last modified date: Wed Jul 13 07:40:26 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: c:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: b918e06de12613a1773a0976ab94e213bd09ce52
		Built by svcphil on cntk-muc01
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 3 nodes pinging each other
ping [requestnodes (before change)]: 3 nodes pinging each other
ping [requestnodes (before change)]: 3 nodes pinging each other
ping [requestnodes (before change)]: all 3 nodes responded
requestnodes [MPIWrapper]: using 3 out of 3 MPI nodes (3 requested); we (2) are in (participating)
ping [requestnodes (after change)]: 3 nodes pinging each other
ping [requestnodes (before change)]: all 3 nodes responded
ping [requestnodes (before change)]: all 3 nodes responded
requestnodes [MPIWrapper]: using 3 out of 3 MPI nodes (3 requested); we (1) are in (participating)
requestnodes [MPIWrapper]: using 3 out of 3 MPI nodes (3 requested); we (0) are in (participating)
ping [requestnodes (after change)]: 3 nodes pinging each other
ping [requestnodes (after change)]: 3 nodes pinging each other
ping [requestnodes (after change)]: all 3 nodes responded
ping [requestnodes (after change)]: all 3 nodes responded
mpihelper: we are cog 2 in a gearbox of 3
mpihelper: we are cog 1 in a gearbox of 3
ping [mpihelper]: 3 nodes pinging each other
ping [mpihelper]: 3 nodes pinging each other
ping [requestnodes (after change)]: all 3 nodes responded
mpihelper: we are cog 0 in a gearbox of 3
ping [mpihelper]: 3 nodes pinging each other
ping [mpihelper]: all 3 nodes responded
ping [mpihelper]: all 3 nodes responded
ping [mpihelper]: all 3 nodes responded
MPI Rank 0: 07/14/2016 07:52:57: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr_speechTrain.logrank0
MPI Rank 0: 07/14/2016 07:52:57: -------------------------------------------------------------------
MPI Rank 0: 07/14/2016 07:52:57: Build info: 
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:57: 		Built time: Jul 14 2016 07:04:27
MPI Rank 0: 07/14/2016 07:52:57: 		Last modified date: Wed Jul 13 07:40:26 2016
MPI Rank 0: 07/14/2016 07:52:57: 		Build type: Release
MPI Rank 0: 07/14/2016 07:52:57: 		Build target: GPU
MPI Rank 0: 07/14/2016 07:52:57: 		With 1bit-SGD: no
MPI Rank 0: 07/14/2016 07:52:57: 		Math lib: mkl
MPI Rank 0: 07/14/2016 07:52:57: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
MPI Rank 0: 07/14/2016 07:52:57: 		CUB_PATH: c:\src\cub-1.4.1
MPI Rank 0: 07/14/2016 07:52:57: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
MPI Rank 0: 07/14/2016 07:52:57: 		Build Branch: HEAD
MPI Rank 0: 07/14/2016 07:52:57: 		Build SHA1: b918e06de12613a1773a0976ab94e213bd09ce52
MPI Rank 0: 07/14/2016 07:52:57: 		Built by svcphil on cntk-muc01
MPI Rank 0: 07/14/2016 07:52:57: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
MPI Rank 0: 07/14/2016 07:52:57: -------------------------------------------------------------------
MPI Rank 0: 07/14/2016 07:52:57: -------------------------------------------------------------------
MPI Rank 0: 07/14/2016 07:52:57: GPU info:
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:57: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8090 MB
MPI Rank 0: 07/14/2016 07:52:57: -------------------------------------------------------------------
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:57: Running on cntk-muc00 at 2016/07/14 07:52:57
MPI Rank 0: 07/14/2016 07:52:57: Command line: 
MPI Rank 0: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu  DeviceId=-1  timestamping=true  numCPUThreads=1  precision=double  speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]  speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  speechTrain=[SGD=[maxEpochs=4]]  speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:57: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 07/14/2016 07:52:57: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = $DeviceId$
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = $DeviceId$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 10
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 3
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "DataParallelSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             DataParallelSGD = [
MPI Rank 0:                 gradientBits = 32
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 0: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 0: DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 0: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN
MPI Rank 0: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 0: DeviceId=-1
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=1
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: speechTrain=[SGD=[maxEpochs=4]]
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 0: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:57: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:57: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 07/14/2016 07:52:57: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = -1
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = -1
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 10
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 3
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "DataParallelSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             DataParallelSGD = [
MPI Rank 0:                 gradientBits = 32
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 0: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 0: DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 0: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN
MPI Rank 0: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 0: DeviceId=-1
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=1
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: speechTrain=[SGD=[maxEpochs=4]]
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 0: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:57: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:57: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: cntk.cntk:command=speechTrain
MPI Rank 0: configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN
MPI Rank 0: configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 0: configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 0: configparameters: cntk.cntk:deviceId=-1
MPI Rank 0: configparameters: cntk.cntk:numCPUThreads=1
MPI Rank 0: configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 0: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 0: configparameters: cntk.cntk:precision=double
MPI Rank 0: configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 0: configparameters: cntk.cntk:speechTrain=[
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = -1
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 10
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 3
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "DataParallelSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             DataParallelSGD = [
MPI Rank 0:                 gradientBits = 32
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ] [SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]] [SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] [SGD=[maxEpochs=4]] [SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 0: 
MPI Rank 0: configparameters: cntk.cntk:stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 0: configparameters: cntk.cntk:timestamping=true
MPI Rank 0: 07/14/2016 07:52:57: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 07/14/2016 07:52:57: Commands: speechTrain
MPI Rank 0: 07/14/2016 07:52:57: Precision = "double"
MPI Rank 0: 07/14/2016 07:52:57: Using 1 CPU threads.
MPI Rank 0: 07/14/2016 07:52:57: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn
MPI Rank 0: 07/14/2016 07:52:57: CNTKCommandTrainInfo: speechTrain : 4
MPI Rank 0: 07/14/2016 07:52:57: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 4
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:57: ##############################################################################
MPI Rank 0: 07/14/2016 07:52:57: #                                                                            #
MPI Rank 0: 07/14/2016 07:52:57: # Action "train"                                                             #
MPI Rank 0: 07/14/2016 07:52:57: #                                                                            #
MPI Rank 0: 07/14/2016 07:52:57: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:57: CNTKCommandTrainBegin: speechTrain
MPI Rank 0: SimpleNetworkBuilder Using CPU
MPI Rank 0: reading script file glob_0000.scp ... 946 entries
MPI Rank 0: total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list
MPI Rank 0: htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
MPI Rank 0: ...............................................................................................feature set 0: 252508 frames in 946 out of 946 utterances
MPI Rank 0: label set 0: 129 classes
MPI Rank 0: minibatchutterancesource: 946 utterances grouped into 3 chunks, av. chunk size: 315.3 utterances, 84169.3 frames
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:58: Creating virgin network.
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 7 roots:
MPI Rank 0: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 0: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 0: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 	MeanOfFeatures = Mean()
MPI Rank 0: 	PosteriorProb = Softmax()
MPI Rank 0: 	Prior = Mean()
MPI Rank 0: 	ScaledLogLikelihood = Minus()
MPI Rank 0: 
MPI Rank 0: Validating network. 25 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 0: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 0: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 0: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 0: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 0: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 0: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 0: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 0: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 0: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 0: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 0: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 0: 
MPI Rank 0: Validating network. 17 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network, final pass.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:58: Created model with 25 nodes on CPU.
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:58: Training criterion node(s):
MPI Rank 0: 07/14/2016 07:52:58: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:58: Evaluation criterion node(s):
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:58: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 
MPI Rank 0: Memory Sharing Structure:
MPI Rank 0: 
MPI Rank 0: 0000000000000000: {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 0: 000000CAE5A368D0: {[B0 Value[512 x 1]] }
MPI Rank 0: 000000CAE5A36AB0: {[MeanOfFeatures Value[363]] }
MPI Rank 0: 000000CAE5A36DD0: {[features Value[363 x *]] }
MPI Rank 0: 000000CAE5A372D0: {[W0 Value[512 x 363]] }
MPI Rank 0: 000000CAE5A377D0: {[InvStdOfFeatures Value[363]] }
MPI Rank 0: 000000CAFA577190: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 0: 000000CAFA577410: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 0: 000000CAFA5774B0: {[LogOfPrior Value[132]] }
MPI Rank 0: 000000CAFA5775F0: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 0: 000000CAFA577870: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 0: 000000CAFA577910: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 0: 000000CAFA5779B0: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 0: 000000CAFA577AF0: {[B2 Value[132 x 1]] }
MPI Rank 0: 000000CAFA577E10: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 0: 000000CAFA577F50: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 0: 000000CAFA578130: {[labels Value[132 x *]] }
MPI Rank 0: 000000CAFA578270: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 0: 000000CAFA578310: {[W1 Value[512 x 512]] }
MPI Rank 0: 000000CAFA578450: {[W0*features Value[512 x *]] }
MPI Rank 0: 000000CAFA5784F0: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 0: 000000CAFA578810: {[EvalErrorPrediction Value[1]] }
MPI Rank 0: 000000CAFA5788B0: {[W2 Value[132 x 512]] }
MPI Rank 0: 000000CAFA578950: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 0: 000000CAFA5789F0: {[B1 Value[512 x 1]] }
MPI Rank 0: 000000CAFA578D10: {[Prior Value[132]] }
MPI Rank 0: 000000CAFA578DB0: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 0: 000000CAFA580130: {[B2 Gradient[132 x 1]] }
MPI Rank 0: 000000CAFA580270: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:58: Precomputing --> 3 PreCompute nodes found.
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:58: 	MeanOfFeatures = Mean()
MPI Rank 0: 07/14/2016 07:52:58: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 07/14/2016 07:52:58: 	Prior = Mean()
MPI Rank 0: minibatchiterator: epoch 0: frames [0..252508] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:52:59: Precomputing --> Completed.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:00: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 0: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:00: Starting minibatch loop.
MPI Rank 0: 07/14/2016 07:53:01:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.13%]: CrossEntropyWithSoftmax = 4.45416150 * 640; EvalErrorPrediction = 0.89687500 * 640; time = 0.3011s; samplesPerSecond = 2125.2
MPI Rank 0: 07/14/2016 07:53:01:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: CrossEntropyWithSoftmax = 4.33591146 * 640; EvalErrorPrediction = 0.88593750 * 640; time = 0.2716s; samplesPerSecond = 2356.2
MPI Rank 0: 07/14/2016 07:53:01:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: CrossEntropyWithSoftmax = 4.00507652 * 640; EvalErrorPrediction = 0.90781250 * 640; time = 0.2564s; samplesPerSecond = 2496.3
MPI Rank 0: 07/14/2016 07:53:02:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: CrossEntropyWithSoftmax = 3.82762088 * 640; EvalErrorPrediction = 0.85468750 * 640; time = 0.2641s; samplesPerSecond = 2423.0
MPI Rank 0: 07/14/2016 07:53:02:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.63%]: CrossEntropyWithSoftmax = 3.73892559 * 640; EvalErrorPrediction = 0.87187500 * 640; time = 0.2557s; samplesPerSecond = 2503.0
MPI Rank 0: 07/14/2016 07:53:02:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: CrossEntropyWithSoftmax = 3.71036275 * 640; EvalErrorPrediction = 0.85937500 * 640; time = 0.2632s; samplesPerSecond = 2431.2
MPI Rank 0: 07/14/2016 07:53:02:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: CrossEntropyWithSoftmax = 3.71827746 * 640; EvalErrorPrediction = 0.86406250 * 640; time = 0.2528s; samplesPerSecond = 2531.9
MPI Rank 0: 07/14/2016 07:53:03:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: CrossEntropyWithSoftmax = 3.53746828 * 640; EvalErrorPrediction = 0.79687500 * 640; time = 0.2551s; samplesPerSecond = 2508.3
MPI Rank 0: 07/14/2016 07:53:03:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.13%]: CrossEntropyWithSoftmax = 3.39240122 * 640; EvalErrorPrediction = 0.80937500 * 640; time = 0.2527s; samplesPerSecond = 2532.9
MPI Rank 0: 07/14/2016 07:53:03:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: CrossEntropyWithSoftmax = 3.43721506 * 640; EvalErrorPrediction = 0.80156250 * 640; time = 0.2519s; samplesPerSecond = 2540.4
MPI Rank 0: 07/14/2016 07:53:03:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: CrossEntropyWithSoftmax = 3.26915145 * 640; EvalErrorPrediction = 0.77968750 * 640; time = 0.2537s; samplesPerSecond = 2522.3
MPI Rank 0: 07/14/2016 07:53:04:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: CrossEntropyWithSoftmax = 3.14847957 * 640; EvalErrorPrediction = 0.77031250 * 640; time = 0.2576s; samplesPerSecond = 2484.8
MPI Rank 0: 07/14/2016 07:53:04:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.63%]: CrossEntropyWithSoftmax = 3.13805770 * 640; EvalErrorPrediction = 0.74375000 * 640; time = 0.2593s; samplesPerSecond = 2467.8
MPI Rank 0: 07/14/2016 07:53:04:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: CrossEntropyWithSoftmax = 2.99768374 * 640; EvalErrorPrediction = 0.71875000 * 640; time = 0.2515s; samplesPerSecond = 2544.6
MPI Rank 0: 07/14/2016 07:53:04:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: CrossEntropyWithSoftmax = 3.01058834 * 640; EvalErrorPrediction = 0.73281250 * 640; time = 0.2518s; samplesPerSecond = 2541.9
MPI Rank 0: 07/14/2016 07:53:05:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: CrossEntropyWithSoftmax = 3.02335619 * 640; EvalErrorPrediction = 0.74531250 * 640; time = 0.2549s; samplesPerSecond = 2510.6
MPI Rank 0: 07/14/2016 07:53:05:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.13%]: CrossEntropyWithSoftmax = 2.93449884 * 640; EvalErrorPrediction = 0.71562500 * 640; time = 0.2553s; samplesPerSecond = 2506.5
MPI Rank 0: 07/14/2016 07:53:05:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: CrossEntropyWithSoftmax = 2.77168265 * 640; EvalErrorPrediction = 0.69062500 * 640; time = 0.2533s; samplesPerSecond = 2526.4
MPI Rank 0: 07/14/2016 07:53:05:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: CrossEntropyWithSoftmax = 2.80254906 * 640; EvalErrorPrediction = 0.69687500 * 640; time = 0.2527s; samplesPerSecond = 2532.8
MPI Rank 0: 07/14/2016 07:53:06:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: CrossEntropyWithSoftmax = 2.64220148 * 640; EvalErrorPrediction = 0.68437500 * 640; time = 0.2522s; samplesPerSecond = 2537.6
MPI Rank 0: 07/14/2016 07:53:06:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.63%]: CrossEntropyWithSoftmax = 2.59237117 * 640; EvalErrorPrediction = 0.65937500 * 640; time = 0.2496s; samplesPerSecond = 2564.0
MPI Rank 0: 07/14/2016 07:53:06:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: CrossEntropyWithSoftmax = 2.66093734 * 640; EvalErrorPrediction = 0.68906250 * 640; time = 0.2507s; samplesPerSecond = 2553.3
MPI Rank 0: 07/14/2016 07:53:06:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: CrossEntropyWithSoftmax = 2.49158886 * 640; EvalErrorPrediction = 0.65781250 * 640; time = 0.2517s; samplesPerSecond = 2543.1
MPI Rank 0: 07/14/2016 07:53:07:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: CrossEntropyWithSoftmax = 2.60665098 * 640; EvalErrorPrediction = 0.66093750 * 640; time = 0.2521s; samplesPerSecond = 2538.4
MPI Rank 0: 07/14/2016 07:53:07:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.13%]: CrossEntropyWithSoftmax = 2.50170098 * 640; EvalErrorPrediction = 0.63125000 * 640; time = 0.2523s; samplesPerSecond = 2536.3
MPI Rank 0: 07/14/2016 07:53:07:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: CrossEntropyWithSoftmax = 2.35502599 * 640; EvalErrorPrediction = 0.59687500 * 640; time = 0.2537s; samplesPerSecond = 2522.4
MPI Rank 0: 07/14/2016 07:53:07:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: CrossEntropyWithSoftmax = 2.32071817 * 640; EvalErrorPrediction = 0.60156250 * 640; time = 0.2666s; samplesPerSecond = 2400.4
MPI Rank 0: 07/14/2016 07:53:08:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: CrossEntropyWithSoftmax = 2.37646415 * 640; EvalErrorPrediction = 0.62500000 * 640; time = 0.2575s; samplesPerSecond = 2485.3
MPI Rank 0: 07/14/2016 07:53:08:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.63%]: CrossEntropyWithSoftmax = 2.28159506 * 640; EvalErrorPrediction = 0.58906250 * 640; time = 0.2649s; samplesPerSecond = 2416.3
MPI Rank 0: 07/14/2016 07:53:08:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: CrossEntropyWithSoftmax = 2.26445286 * 640; EvalErrorPrediction = 0.59843750 * 640; time = 0.2604s; samplesPerSecond = 2457.5
MPI Rank 0: 07/14/2016 07:53:08:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: CrossEntropyWithSoftmax = 2.24143044 * 640; EvalErrorPrediction = 0.58125000 * 640; time = 0.2568s; samplesPerSecond = 2492.4
MPI Rank 0: 07/14/2016 07:53:09:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: CrossEntropyWithSoftmax = 2.28501255 * 640; EvalErrorPrediction = 0.61875000 * 640; time = 0.2587s; samplesPerSecond = 2473.8
MPI Rank 0: 07/14/2016 07:53:09: Finished Epoch[ 1 of 4]: [Training] CrossEntropyWithSoftmax = 3.02730057 * 20480; EvalErrorPrediction = 0.72924805 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=8.25555s
MPI Rank 0: 07/14/2016 07:53:09: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.1'
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:09: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 0: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:09: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Actual gradient aggregation time: 0.019035
MPI Rank 0: Async gradient aggregation wait time: 1e-006
MPI Rank 0: Actual gradient aggregation time: 0.007952
MPI Rank 0: 07/14/2016 07:53:09:  Epoch[ 2 of 4]-Minibatch[   1-  10, 12.50%]: CrossEntropyWithSoftmax = 2.18001252 * 2304; EvalErrorPrediction = 0.58984375 * 2304; time = 0.4094s; samplesPerSecond = 5627.7
MPI Rank 0: Async gradient aggregation wait time: 1e-006
MPI Rank 0: Actual gradient aggregation time: 0.01899
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.009682
MPI Rank 0: 07/14/2016 07:53:10:  Epoch[ 2 of 4]-Minibatch[  11-  20, 25.00%]: CrossEntropyWithSoftmax = 2.25843636 * 2560; EvalErrorPrediction = 0.60273438 * 2560; time = 0.3989s; samplesPerSecond = 6418.1
MPI Rank 0: Async gradient aggregation wait time: 1e-006
MPI Rank 0: Actual gradient aggregation time: 0.007871
MPI Rank 0: Async gradient aggregation wait time: 1e-006
MPI Rank 0: Actual gradient aggregation time: 0.007765
MPI Rank 0: 07/14/2016 07:53:10:  Epoch[ 2 of 4]-Minibatch[  21-  30, 37.50%]: CrossEntropyWithSoftmax = 2.25595348 * 2560; EvalErrorPrediction = 0.59609375 * 2560; time = 0.4012s; samplesPerSecond = 6380.7
MPI Rank 0: Async gradient aggregation wait time: 1e-006
MPI Rank 0: Actual gradient aggregation time: 0.007812
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.008902
MPI Rank 0: 07/14/2016 07:53:10:  Epoch[ 2 of 4]-Minibatch[  31-  40, 50.00%]: CrossEntropyWithSoftmax = 2.20099326 * 2560; EvalErrorPrediction = 0.57343750 * 2560; time = 0.3927s; samplesPerSecond = 6519.5
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.012385
MPI Rank 0: Async gradient aggregation wait time: 1e-006
MPI Rank 0: Actual gradient aggregation time: 0.007863
MPI Rank 0: 07/14/2016 07:53:11:  Epoch[ 2 of 4]-Minibatch[  41-  50, 62.50%]: CrossEntropyWithSoftmax = 2.24193716 * 2560; EvalErrorPrediction = 0.58515625 * 2560; time = 0.3735s; samplesPerSecond = 6853.3
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.014886
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.014084
MPI Rank 0: 07/14/2016 07:53:11:  Epoch[ 2 of 4]-Minibatch[  51-  60, 75.00%]: CrossEntropyWithSoftmax = 2.22339752 * 2560; EvalErrorPrediction = 0.58203125 * 2560; time = 0.3868s; samplesPerSecond = 6618.7
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.018021
MPI Rank 0: Async gradient aggregation wait time: 1e-006
MPI Rank 0: Actual gradient aggregation time: 0.007916
MPI Rank 0: 07/14/2016 07:53:12:  Epoch[ 2 of 4]-Minibatch[  61-  70, 87.50%]: CrossEntropyWithSoftmax = 2.08832841 * 2560; EvalErrorPrediction = 0.55195313 * 2560; time = 0.3907s; samplesPerSecond = 6553.0
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.007934
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.009253
MPI Rank 0: 07/14/2016 07:53:12:  Epoch[ 2 of 4]-Minibatch[  71-  80, 100.00%]: CrossEntropyWithSoftmax = 2.09020274 * 2560; EvalErrorPrediction = 0.57343750 * 2560; time = 0.3908s; samplesPerSecond = 6549.8
MPI Rank 0: Async gradient aggregation wait time: 0.003996
MPI Rank 0: Actual gradient aggregation time: 0.009429
MPI Rank 0: 07/14/2016 07:53:12: Finished Epoch[ 2 of 4]: [Training] CrossEntropyWithSoftmax = 2.19194914 * 20480; EvalErrorPrediction = 0.58208008 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=3.16547s
MPI Rank 0: 07/14/2016 07:53:12: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.2'
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:12: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:12: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.01026
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.008466
MPI Rank 0: 07/14/2016 07:53:14:  Epoch[ 3 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.98247501 * 9216; EvalErrorPrediction = 0.54806858 * 9216; time = 1.2890s; samplesPerSecond = 7149.7
MPI Rank 0: Async gradient aggregation wait time: 1e-006
MPI Rank 0: Actual gradient aggregation time: 0.008524
MPI Rank 0: Async gradient aggregation wait time: 1e-006
MPI Rank 0: Actual gradient aggregation time: 0.008156
MPI Rank 0: 07/14/2016 07:53:15:  Epoch[ 3 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.95499777 * 10240; EvalErrorPrediction = 0.53388672 * 10240; time = 1.2101s; samplesPerSecond = 8462.2
MPI Rank 0: 07/14/2016 07:53:15: Finished Epoch[ 3 of 4]: [Training] CrossEntropyWithSoftmax = 1.96491245 * 20480; EvalErrorPrediction = 0.53925781 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-005; epochTime=2.54009s
MPI Rank 0: 07/14/2016 07:53:15: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3'
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:15: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:15: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.00906
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.036009
MPI Rank 0: 07/14/2016 07:53:16:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01431515 * 9216; EvalErrorPrediction = 0.54796007 * 9216; time = 1.2344s; samplesPerSecond = 7465.9
MPI Rank 0: Async gradient aggregation wait time: 4e-006
MPI Rank 0: Actual gradient aggregation time: 0.028304
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.027797
MPI Rank 0: 07/14/2016 07:53:17:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.93746303 * 10240; EvalErrorPrediction = 0.52968750 * 10240; time = 1.1280s; samplesPerSecond = 9078.3
MPI Rank 0: Async gradient aggregation wait time: 0.014946
MPI Rank 0: 07/14/2016 07:53:17: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97304685 * 20480; EvalErrorPrediction = 0.53818359 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-005; epochTime=2.3966s
MPI Rank 0: 07/14/2016 07:53:17: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:17: learnRatePerSample reduced to 4.8828126e-005
MPI Rank 0: 07/14/2016 07:53:17: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:17: Starting Epoch 4: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:17: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.041467
MPI Rank 0: Async gradient aggregation wait time: 1e-006
MPI Rank 0: 07/14/2016 07:53:19:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01420005 * 8566; EvalErrorPrediction = 0.54716320 * 8566; time = 1.2052s; samplesPerSecond = 7107.8
MPI Rank 0: Actual gradient aggregation time: 0.008476
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.016782
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: 07/14/2016 07:53:20:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.93988024 * 10240; EvalErrorPrediction = 0.52968750 * 10240; time = 1.1382s; samplesPerSecond = 8996.8
MPI Rank 0: Actual gradient aggregation time: 0.013974
MPI Rank 0: 07/14/2016 07:53:20: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97311480 * 19830; EvalErrorPrediction = 0.53761977 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 4.8828126e-005; epochTime=2.37999s
MPI Rank 0: 07/14/2016 07:53:20: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:20: learnRatePerSample reduced to 2.4414063e-005
MPI Rank 0: 07/14/2016 07:53:20: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:20: Starting Epoch 4: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:20: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.046375
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.011477
MPI Rank 0: 07/14/2016 07:53:21:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01448512 * 8566; EvalErrorPrediction = 0.54751343 * 8566; time = 1.2015s; samplesPerSecond = 7129.2
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.028631
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.015985
MPI Rank 0: 07/14/2016 07:53:22:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94124338 * 10240; EvalErrorPrediction = 0.53027344 * 10240; time = 1.1255s; samplesPerSecond = 9098.0
MPI Rank 0: 07/14/2016 07:53:22: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97406471 * 19830; EvalErrorPrediction = 0.53797277 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 2.4414063e-005; epochTime=2.36128s
MPI Rank 0: 07/14/2016 07:53:22: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:22: learnRatePerSample reduced to 1.2207031e-005
MPI Rank 0: 07/14/2016 07:53:22: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:22: Starting Epoch 4: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:22: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.009001
MPI Rank 0: 07/14/2016 07:53:24:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01463547 * 8566; EvalErrorPrediction = 0.54751343 * 8566; time = 1.2047s; samplesPerSecond = 7110.4
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.036159
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.034183
MPI Rank 0: 07/14/2016 07:53:25:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94199445 * 10240; EvalErrorPrediction = 0.53056641 * 10240; time = 1.1318s; samplesPerSecond = 9047.9
MPI Rank 0: Async gradient aggregation wait time: 0.024516
MPI Rank 0: Actual gradient aggregation time: 0.009578
MPI Rank 0: 07/14/2016 07:53:25: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97458585 * 19830; EvalErrorPrediction = 0.53802320 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 1.2207031e-005; epochTime=2.37663s
MPI Rank 0: 07/14/2016 07:53:25: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:25: learnRatePerSample reduced to 6.1035157e-006
MPI Rank 0: 07/14/2016 07:53:25: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:25: Starting Epoch 4: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:25: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 4e-006
MPI Rank 0: Actual gradient aggregation time: 0.052303
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.013397
MPI Rank 0: 07/14/2016 07:53:26:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01471269 * 8566; EvalErrorPrediction = 0.54739668 * 8566; time = 1.1914s; samplesPerSecond = 7189.8
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.008106
MPI Rank 0: Async gradient aggregation wait time: 1e-006
MPI Rank 0: Actual gradient aggregation time: 0.008442
MPI Rank 0: 07/14/2016 07:53:27:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94239296 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1641s; samplesPerSecond = 8796.8
MPI Rank 0: 07/14/2016 07:53:27: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97486157 * 19830; EvalErrorPrediction = 0.53812405 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 6.1035157e-006; epochTime=2.38433s
MPI Rank 0: 07/14/2016 07:53:27: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:27: learnRatePerSample reduced to 3.0517579e-006
MPI Rank 0: 07/14/2016 07:53:27: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:27: Starting Epoch 4: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:27: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Actual gradient aggregation time: 0.077341
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.048834
MPI Rank 0: 07/14/2016 07:53:29:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01475181 * 8566; EvalErrorPrediction = 0.54763017 * 8566; time = 1.2034s; samplesPerSecond = 7117.9
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.038101
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.041946
MPI Rank 0: 07/14/2016 07:53:30:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94259891 * 10240; EvalErrorPrediction = 0.53076172 * 10240; time = 1.1479s; samplesPerSecond = 8920.8
MPI Rank 0: Async gradient aggregation wait time: 0.008627
MPI Rank 0: 07/14/2016 07:53:30: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97500384 * 19830; EvalErrorPrediction = 0.53827534 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 3.0517579e-006; epochTime=2.38076s
MPI Rank 0: 07/14/2016 07:53:30: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:30: learnRatePerSample reduced to 1.5258789e-006
MPI Rank 0: 07/14/2016 07:53:30: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:30: Starting Epoch 4: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:30: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.034048
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: 07/14/2016 07:53:31:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01477150 * 8566; EvalErrorPrediction = 0.54774691 * 8566; time = 1.2030s; samplesPerSecond = 7120.7
MPI Rank 0: Actual gradient aggregation time: 0.022442
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.019781
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: 07/14/2016 07:53:32:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94270369 * 10240; EvalErrorPrediction = 0.53076172 * 10240; time = 1.1408s; samplesPerSecond = 8976.4
MPI Rank 0: Actual gradient aggregation time: 0.015967
MPI Rank 0: 07/14/2016 07:53:32: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97507617 * 19830; EvalErrorPrediction = 0.53842663 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 1.5258789e-006; epochTime=2.37602s
MPI Rank 0: 07/14/2016 07:53:32: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:32: learnRatePerSample reduced to 7.6293946e-007
MPI Rank 0: 07/14/2016 07:53:32: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:32: Starting Epoch 4: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:32: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.051813
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.025497
MPI Rank 0: 07/14/2016 07:53:34:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01478138 * 8566; EvalErrorPrediction = 0.54763017 * 8566; time = 1.1980s; samplesPerSecond = 7150.3
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.039548
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.028026
MPI Rank 0: 07/14/2016 07:53:35:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94275655 * 10240; EvalErrorPrediction = 0.53085938 * 10240; time = 1.1255s; samplesPerSecond = 9098.3
MPI Rank 0: 07/14/2016 07:53:35: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97511264 * 19830; EvalErrorPrediction = 0.53842663 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 7.6293946e-007; epochTime=2.34852s
MPI Rank 0: 07/14/2016 07:53:35: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:35: learnRatePerSample reduced to 3.8146973e-007
MPI Rank 0: 07/14/2016 07:53:35: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:35: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:35: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.042622
MPI Rank 0: 07/14/2016 07:53:36:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01478633 * 8566; EvalErrorPrediction = 0.54763017 * 8566; time = 1.1915s; samplesPerSecond = 7189.5
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.009249
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.016971
MPI Rank 0: 07/14/2016 07:53:37:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94278310 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1429s; samplesPerSecond = 8959.4
MPI Rank 0: Async gradient aggregation wait time: 0.004753
MPI Rank 0: Actual gradient aggregation time: 0.006662
MPI Rank 0: 07/14/2016 07:53:37: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97513096 * 19830; EvalErrorPrediction = 0.53832577 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 3.8146973e-007; epochTime=2.35687s
MPI Rank 0: 07/14/2016 07:53:37: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:37: learnRatePerSample reduced to 1.9073487e-007
MPI Rank 0: 07/14/2016 07:53:37: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:37: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:37: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.009717
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.013123
MPI Rank 0: 07/14/2016 07:53:38:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01478880 * 8566; EvalErrorPrediction = 0.54763017 * 8566; time = 1.2149s; samplesPerSecond = 7050.7
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.015433
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.0156
MPI Rank 0: 07/14/2016 07:53:40:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94279640 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1434s; samplesPerSecond = 8955.6
MPI Rank 0: 07/14/2016 07:53:40: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97514014 * 19830; EvalErrorPrediction = 0.53832577 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 1.9073487e-007; epochTime=2.37838s
MPI Rank 0: 07/14/2016 07:53:40: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:40: learnRatePerSample reduced to 9.5367433e-008
MPI Rank 0: 07/14/2016 07:53:40: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:40: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:40: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Actual gradient aggregation time: 0.009107
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.009822
MPI Rank 0: 07/14/2016 07:53:41:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01479004 * 8566; EvalErrorPrediction = 0.54763017 * 8566; time = 1.2035s; samplesPerSecond = 7117.7
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.026156
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.032783
MPI Rank 0: 07/14/2016 07:53:42:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280306 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1303s; samplesPerSecond = 9059.9
MPI Rank 0: Async gradient aggregation wait time: 0.008862
MPI Rank 0: 07/14/2016 07:53:42: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97514473 * 19830; EvalErrorPrediction = 0.53832577 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 9.5367433e-008; epochTime=2.37608s
MPI Rank 0: 07/14/2016 07:53:42: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:42: learnRatePerSample reduced to 4.7683717e-008
MPI Rank 0: 07/14/2016 07:53:42: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:42: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:42: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.039245
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: 07/14/2016 07:53:43:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01479066 * 8566; EvalErrorPrediction = 0.54763017 * 8566; time = 1.1903s; samplesPerSecond = 7196.5
MPI Rank 0: Actual gradient aggregation time: 0.018625
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.025313
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: 07/14/2016 07:53:45:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280640 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1402s; samplesPerSecond = 8981.3
MPI Rank 0: Actual gradient aggregation time: 0.013408
MPI Rank 0: 07/14/2016 07:53:45: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97514703 * 19830; EvalErrorPrediction = 0.53832577 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 4.7683717e-008; epochTime=2.35911s
MPI Rank 0: 07/14/2016 07:53:45: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:45: learnRatePerSample reduced to 2.3841858e-008
MPI Rank 0: 07/14/2016 07:53:45: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:45: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:45: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.009417
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.054159
MPI Rank 0: 07/14/2016 07:53:46:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01479097 * 8566; EvalErrorPrediction = 0.54763017 * 8566; time = 1.2136s; samplesPerSecond = 7058.6
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.047519
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.009223
MPI Rank 0: 07/14/2016 07:53:47:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280806 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1448s; samplesPerSecond = 8944.6
MPI Rank 0: 07/14/2016 07:53:47: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97514818 * 19830; EvalErrorPrediction = 0.53832577 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 2.3841858e-008; epochTime=2.38298s
MPI Rank 0: 07/14/2016 07:53:47: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:47: learnRatePerSample reduced to 1.1920929e-008
MPI Rank 0: 07/14/2016 07:53:47: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:47: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:47: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.043565
MPI Rank 0: 07/14/2016 07:53:48:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01479112 * 8566; EvalErrorPrediction = 0.54763017 * 8566; time = 1.1923s; samplesPerSecond = 7184.7
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.02423
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.030575
MPI Rank 0: 07/14/2016 07:53:50:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280890 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1408s; samplesPerSecond = 8976.1
MPI Rank 0: Async gradient aggregation wait time: 0.0214
MPI Rank 0: Actual gradient aggregation time: 0.009987
MPI Rank 0: 07/14/2016 07:53:50: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97514875 * 19830; EvalErrorPrediction = 0.53832577 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 1.1920929e-008; epochTime=2.37094s
MPI Rank 0: 07/14/2016 07:53:50: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:50: learnRatePerSample reduced to 5.9604646e-009
MPI Rank 0: 07/14/2016 07:53:50: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:50: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:50: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 4e-006
MPI Rank 0: Actual gradient aggregation time: 0.043814
MPI Rank 0: Async gradient aggregation wait time: 1e-006
MPI Rank 0: Actual gradient aggregation time: 0.009542
MPI Rank 0: 07/14/2016 07:53:51:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01479120 * 8566; EvalErrorPrediction = 0.54763017 * 8566; time = 1.1995s; samplesPerSecond = 7141.6
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.013211
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.00916
MPI Rank 0: 07/14/2016 07:53:52:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280931 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1353s; samplesPerSecond = 9019.5
MPI Rank 0: 07/14/2016 07:53:52: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97514904 * 19830; EvalErrorPrediction = 0.53832577 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 5.9604646e-009; epochTime=2.35994s
MPI Rank 0: 07/14/2016 07:53:52: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:52: learnRatePerSample reduced to 2.9802323e-009
MPI Rank 0: 07/14/2016 07:53:52: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:52: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:52: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Actual gradient aggregation time: 0.014884
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.023214
MPI Rank 0: 07/14/2016 07:53:53:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01479124 * 8566; EvalErrorPrediction = 0.54763017 * 8566; time = 1.1944s; samplesPerSecond = 7172.0
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.012396
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.009451
MPI Rank 0: 07/14/2016 07:53:54:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280952 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1475s; samplesPerSecond = 8923.7
MPI Rank 0: Async gradient aggregation wait time: 0.009543
MPI Rank 0: 07/14/2016 07:53:54: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97514918 * 19830; EvalErrorPrediction = 0.53832577 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 2.9802323e-009; epochTime=2.37267s
MPI Rank 0: 07/14/2016 07:53:54: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:55: learnRatePerSample reduced to 1.4901161e-009
MPI Rank 0: 07/14/2016 07:53:55: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:55: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 3, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:55: Starting minibatch loop, DataParallelSGD training (MyRank = 0, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 0: Async gradient aggregation wait time: 3e-006
MPI Rank 0: Actual gradient aggregation time: 0.033562
MPI Rank 0: Async gradient aggregation wait time: 1e-006
MPI Rank 0: 07/14/2016 07:53:56:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01479126 * 8566; EvalErrorPrediction = 0.54763017 * 8566; time = 1.2084s; samplesPerSecond = 7088.8
MPI Rank 0: Actual gradient aggregation time: 0.01337
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: Actual gradient aggregation time: 0.019523
MPI Rank 0: Async gradient aggregation wait time: 2e-006
MPI Rank 0: 07/14/2016 07:53:57:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280963 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1328s; samplesPerSecond = 9039.7
MPI Rank 0: Actual gradient aggregation time: 0.015963
MPI Rank 0: 07/14/2016 07:53:57: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97514926 * 19830; EvalErrorPrediction = 0.53832577 * 19830; totalSamplesSeen = 81270; learningRatePerSample = 1.4901161e-009; epochTime=2.37662s
MPI Rank 0: 07/14/2016 07:53:57: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:57: learnRatePerSample reduced to 7.4505807e-010
MPI Rank 0: 07/14/2016 07:53:57: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 07/14/2016 07:53:57: Learn Rate Per Sample for Epoch[4] = 7.4505807e-010 is less than minLearnRate 9.9999997e-010. Training complete.
MPI Rank 0: 07/14/2016 07:53:57: CNTKCommandTrainEnd: speechTrain
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:57: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 07/14/2016 07:53:57: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: 07/14/2016 07:52:57: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr_speechTrain.logrank1
MPI Rank 1: 07/14/2016 07:52:57: -------------------------------------------------------------------
MPI Rank 1: 07/14/2016 07:52:57: Build info: 
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:57: 		Built time: Jul 14 2016 07:04:27
MPI Rank 1: 07/14/2016 07:52:57: 		Last modified date: Wed Jul 13 07:40:26 2016
MPI Rank 1: 07/14/2016 07:52:57: 		Build type: Release
MPI Rank 1: 07/14/2016 07:52:57: 		Build target: GPU
MPI Rank 1: 07/14/2016 07:52:57: 		With 1bit-SGD: no
MPI Rank 1: 07/14/2016 07:52:57: 		Math lib: mkl
MPI Rank 1: 07/14/2016 07:52:57: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
MPI Rank 1: 07/14/2016 07:52:57: 		CUB_PATH: c:\src\cub-1.4.1
MPI Rank 1: 07/14/2016 07:52:57: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
MPI Rank 1: 07/14/2016 07:52:57: 		Build Branch: HEAD
MPI Rank 1: 07/14/2016 07:52:57: 		Build SHA1: b918e06de12613a1773a0976ab94e213bd09ce52
MPI Rank 1: 07/14/2016 07:52:57: 		Built by svcphil on cntk-muc01
MPI Rank 1: 07/14/2016 07:52:57: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
MPI Rank 1: 07/14/2016 07:52:57: -------------------------------------------------------------------
MPI Rank 1: 07/14/2016 07:52:58: -------------------------------------------------------------------
MPI Rank 1: 07/14/2016 07:52:58: GPU info:
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8090 MB
MPI Rank 1: 07/14/2016 07:52:58: -------------------------------------------------------------------
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: Running on cntk-muc00 at 2016/07/14 07:52:58
MPI Rank 1: 07/14/2016 07:52:58: Command line: 
MPI Rank 1: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu  DeviceId=-1  timestamping=true  numCPUThreads=1  precision=double  speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]  speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  speechTrain=[SGD=[maxEpochs=4]]  speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 07/14/2016 07:52:58: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = $DeviceId$
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = $DeviceId$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 10
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 3
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "DataParallelSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             DataParallelSGD = [
MPI Rank 1:                 gradientBits = 32
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 1: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 1: DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 1: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN
MPI Rank 1: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 1: DeviceId=-1
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=1
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: speechTrain=[SGD=[maxEpochs=4]]
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 1: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 07/14/2016 07:52:58: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = -1
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = -1
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 10
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 3
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "DataParallelSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             DataParallelSGD = [
MPI Rank 1:                 gradientBits = 32
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 1: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 1: DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 1: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN
MPI Rank 1: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 1: DeviceId=-1
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=1
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: speechTrain=[SGD=[maxEpochs=4]]
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 1: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: cntk.cntk:command=speechTrain
MPI Rank 1: configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN
MPI Rank 1: configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 1: configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 1: configparameters: cntk.cntk:deviceId=-1
MPI Rank 1: configparameters: cntk.cntk:numCPUThreads=1
MPI Rank 1: configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 1: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 1: configparameters: cntk.cntk:precision=double
MPI Rank 1: configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 1: configparameters: cntk.cntk:speechTrain=[
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = -1
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 10
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 3
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "DataParallelSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             DataParallelSGD = [
MPI Rank 1:                 gradientBits = 32
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ] [SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]] [SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] [SGD=[maxEpochs=4]] [SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 1: 
MPI Rank 1: configparameters: cntk.cntk:stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 1: configparameters: cntk.cntk:timestamping=true
MPI Rank 1: 07/14/2016 07:52:58: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 07/14/2016 07:52:58: Commands: speechTrain
MPI Rank 1: 07/14/2016 07:52:58: Precision = "double"
MPI Rank 1: 07/14/2016 07:52:58: Using 1 CPU threads.
MPI Rank 1: 07/14/2016 07:52:58: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn
MPI Rank 1: 07/14/2016 07:52:58: CNTKCommandTrainInfo: speechTrain : 4
MPI Rank 1: 07/14/2016 07:52:58: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 4
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: ##############################################################################
MPI Rank 1: 07/14/2016 07:52:58: #                                                                            #
MPI Rank 1: 07/14/2016 07:52:58: # Action "train"                                                             #
MPI Rank 1: 07/14/2016 07:52:58: #                                                                            #
MPI Rank 1: 07/14/2016 07:52:58: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: CNTKCommandTrainBegin: speechTrain
MPI Rank 1: SimpleNetworkBuilder Using CPU
MPI Rank 1: reading script file glob_0000.scp ... 946 entries
MPI Rank 1: total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list
MPI Rank 1: htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
MPI Rank 1: ...............................................................................................feature set 0: 252508 frames in 946 out of 946 utterances
MPI Rank 1: label set 0: 129 classes
MPI Rank 1: minibatchutterancesource: 946 utterances grouped into 3 chunks, av. chunk size: 315.3 utterances, 84169.3 frames
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: Creating virgin network.
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 7 roots:
MPI Rank 1: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 1: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 1: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 	MeanOfFeatures = Mean()
MPI Rank 1: 	PosteriorProb = Softmax()
MPI Rank 1: 	Prior = Mean()
MPI Rank 1: 	ScaledLogLikelihood = Minus()
MPI Rank 1: 
MPI Rank 1: Validating network. 25 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 1: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 1: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 1: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 1: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 1: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 1: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 1: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 1: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 1: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 1: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 1: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 1: 
MPI Rank 1: Validating network. 17 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network, final pass.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: Created model with 25 nodes on CPU.
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: Training criterion node(s):
MPI Rank 1: 07/14/2016 07:52:58: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: Evaluation criterion node(s):
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 
MPI Rank 1: Memory Sharing Structure:
MPI Rank 1: 
MPI Rank 1: 0000000000000000: {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 1: 0000007008C64810: {[InvStdOfFeatures Value[363]] }
MPI Rank 1: 0000007008C64B30: {[MeanOfFeatures Value[363]] }
MPI Rank 1: 0000007008C64BD0: {[W0 Value[512 x 363]] }
MPI Rank 1: 0000007008C650D0: {[B0 Value[512 x 1]] }
MPI Rank 1: 0000007008C653F0: {[features Value[363 x *]] }
MPI Rank 1: 0000007023524210: {[B2 Gradient[132 x 1]] }
MPI Rank 1: 00000070235251B0: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 1: 0000007024209660: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 1: 0000007024209700: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 1: 0000007024209AC0: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 1: 0000007024209CA0: {[EvalErrorPrediction Value[1]] }
MPI Rank 1: 0000007024209DE0: {[LogOfPrior Value[132]] }
MPI Rank 1: 0000007024209FC0: {[B2 Value[132 x 1]] }
MPI Rank 1: 000000702420A420: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 1: 000000702420A4C0: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 1: 000000702420A600: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 1: 000000702420A6A0: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 1: 000000702420A740: {[W2 Value[132 x 512]] }
MPI Rank 1: 000000702420A920: {[labels Value[132 x *]] }
MPI Rank 1: 000000702420AC40: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 1: 000000702420AD80: {[W0*features Value[512 x *]] }
MPI Rank 1: 000000702420AE20: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 1: 000000702420AEC0: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 1: 000000702420AF60: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 1: 000000702420B0A0: {[W1 Value[512 x 512]] }
MPI Rank 1: 000000702420B140: {[B1 Value[512 x 1]] }
MPI Rank 1: 000000702420B280: {[Prior Value[132]] }
MPI Rank 1: 000000702420B460: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: Precomputing --> 3 PreCompute nodes found.
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:52:58: 	MeanOfFeatures = Mean()
MPI Rank 1: 07/14/2016 07:52:58: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 07/14/2016 07:52:58: 	Prior = Mean()
MPI Rank 1: minibatchiterator: epoch 0: frames [0..252508] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:00: Precomputing --> Completed.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:00: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 1: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:00: Starting minibatch loop.
MPI Rank 1: 07/14/2016 07:53:01:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.13%]: CrossEntropyWithSoftmax = 4.45416150 * 640; EvalErrorPrediction = 0.89687500 * 640; time = 0.3023s; samplesPerSecond = 2117.3
MPI Rank 1: 07/14/2016 07:53:01:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: CrossEntropyWithSoftmax = 4.33591146 * 640; EvalErrorPrediction = 0.88593750 * 640; time = 0.2708s; samplesPerSecond = 2363.1
MPI Rank 1: 07/14/2016 07:53:01:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: CrossEntropyWithSoftmax = 4.00507652 * 640; EvalErrorPrediction = 0.90781250 * 640; time = 0.2773s; samplesPerSecond = 2308.3
MPI Rank 1: 07/14/2016 07:53:02:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: CrossEntropyWithSoftmax = 3.82762088 * 640; EvalErrorPrediction = 0.85468750 * 640; time = 0.2517s; samplesPerSecond = 2542.7
MPI Rank 1: 07/14/2016 07:53:02:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.63%]: CrossEntropyWithSoftmax = 3.73892559 * 640; EvalErrorPrediction = 0.87187500 * 640; time = 0.2737s; samplesPerSecond = 2338.6
MPI Rank 1: 07/14/2016 07:53:02:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: CrossEntropyWithSoftmax = 3.71036275 * 640; EvalErrorPrediction = 0.85937500 * 640; time = 0.2648s; samplesPerSecond = 2417.2
MPI Rank 1: 07/14/2016 07:53:02:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: CrossEntropyWithSoftmax = 3.71827746 * 640; EvalErrorPrediction = 0.86406250 * 640; time = 0.2597s; samplesPerSecond = 2464.0
MPI Rank 1: 07/14/2016 07:53:03:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: CrossEntropyWithSoftmax = 3.53746828 * 640; EvalErrorPrediction = 0.79687500 * 640; time = 0.2541s; samplesPerSecond = 2518.6
MPI Rank 1: 07/14/2016 07:53:03:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.13%]: CrossEntropyWithSoftmax = 3.39240122 * 640; EvalErrorPrediction = 0.80937500 * 640; time = 0.2500s; samplesPerSecond = 2560.3
MPI Rank 1: 07/14/2016 07:53:03:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: CrossEntropyWithSoftmax = 3.43721506 * 640; EvalErrorPrediction = 0.80156250 * 640; time = 0.2543s; samplesPerSecond = 2516.7
MPI Rank 1: 07/14/2016 07:53:03:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: CrossEntropyWithSoftmax = 3.26915145 * 640; EvalErrorPrediction = 0.77968750 * 640; time = 0.2656s; samplesPerSecond = 2409.5
MPI Rank 1: 07/14/2016 07:53:04:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: CrossEntropyWithSoftmax = 3.14847957 * 640; EvalErrorPrediction = 0.77031250 * 640; time = 0.2553s; samplesPerSecond = 2506.7
MPI Rank 1: 07/14/2016 07:53:04:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.63%]: CrossEntropyWithSoftmax = 3.13805770 * 640; EvalErrorPrediction = 0.74375000 * 640; time = 0.2545s; samplesPerSecond = 2514.9
MPI Rank 1: 07/14/2016 07:53:04:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: CrossEntropyWithSoftmax = 2.99768374 * 640; EvalErrorPrediction = 0.71875000 * 640; time = 0.2521s; samplesPerSecond = 2538.5
MPI Rank 1: 07/14/2016 07:53:04:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: CrossEntropyWithSoftmax = 3.01058834 * 640; EvalErrorPrediction = 0.73281250 * 640; time = 0.2767s; samplesPerSecond = 2313.2
MPI Rank 1: 07/14/2016 07:53:05:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: CrossEntropyWithSoftmax = 3.02335619 * 640; EvalErrorPrediction = 0.74531250 * 640; time = 0.2540s; samplesPerSecond = 2519.8
MPI Rank 1: 07/14/2016 07:53:05:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.13%]: CrossEntropyWithSoftmax = 2.93449884 * 640; EvalErrorPrediction = 0.71562500 * 640; time = 0.2532s; samplesPerSecond = 2527.4
MPI Rank 1: 07/14/2016 07:53:05:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: CrossEntropyWithSoftmax = 2.77168265 * 640; EvalErrorPrediction = 0.69062500 * 640; time = 0.2529s; samplesPerSecond = 2530.5
MPI Rank 1: 07/14/2016 07:53:05:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: CrossEntropyWithSoftmax = 2.80254906 * 640; EvalErrorPrediction = 0.69687500 * 640; time = 0.2516s; samplesPerSecond = 2543.7
MPI Rank 1: 07/14/2016 07:53:06:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: CrossEntropyWithSoftmax = 2.64220148 * 640; EvalErrorPrediction = 0.68437500 * 640; time = 0.2518s; samplesPerSecond = 2541.9
MPI Rank 1: 07/14/2016 07:53:06:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.63%]: CrossEntropyWithSoftmax = 2.59237117 * 640; EvalErrorPrediction = 0.65937500 * 640; time = 0.2493s; samplesPerSecond = 2567.0
MPI Rank 1: 07/14/2016 07:53:06:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: CrossEntropyWithSoftmax = 2.66093734 * 640; EvalErrorPrediction = 0.68906250 * 640; time = 0.2522s; samplesPerSecond = 2537.3
MPI Rank 1: 07/14/2016 07:53:06:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: CrossEntropyWithSoftmax = 2.49158886 * 640; EvalErrorPrediction = 0.65781250 * 640; time = 0.2523s; samplesPerSecond = 2537.0
MPI Rank 1: 07/14/2016 07:53:07:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: CrossEntropyWithSoftmax = 2.60665098 * 640; EvalErrorPrediction = 0.66093750 * 640; time = 0.2523s; samplesPerSecond = 2536.7
MPI Rank 1: 07/14/2016 07:53:07:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.13%]: CrossEntropyWithSoftmax = 2.50170098 * 640; EvalErrorPrediction = 0.63125000 * 640; time = 0.2551s; samplesPerSecond = 2509.0
MPI Rank 1: 07/14/2016 07:53:07:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: CrossEntropyWithSoftmax = 2.35502599 * 640; EvalErrorPrediction = 0.59687500 * 640; time = 0.2659s; samplesPerSecond = 2407.2
MPI Rank 1: 07/14/2016 07:53:08:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: CrossEntropyWithSoftmax = 2.32071817 * 640; EvalErrorPrediction = 0.60156250 * 640; time = 0.2671s; samplesPerSecond = 2395.9
MPI Rank 1: 07/14/2016 07:53:08:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: CrossEntropyWithSoftmax = 2.37646415 * 640; EvalErrorPrediction = 0.62500000 * 640; time = 0.2589s; samplesPerSecond = 2471.9
MPI Rank 1: 07/14/2016 07:53:08:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.63%]: CrossEntropyWithSoftmax = 2.28159506 * 640; EvalErrorPrediction = 0.58906250 * 640; time = 0.2638s; samplesPerSecond = 2426.4
MPI Rank 1: 07/14/2016 07:53:08:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: CrossEntropyWithSoftmax = 2.26445286 * 640; EvalErrorPrediction = 0.59843750 * 640; time = 0.2549s; samplesPerSecond = 2510.9
MPI Rank 1: 07/14/2016 07:53:09:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: CrossEntropyWithSoftmax = 2.24143044 * 640; EvalErrorPrediction = 0.58125000 * 640; time = 0.2569s; samplesPerSecond = 2491.3
MPI Rank 1: 07/14/2016 07:53:09:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: CrossEntropyWithSoftmax = 2.28501255 * 640; EvalErrorPrediction = 0.61875000 * 640; time = 0.2468s; samplesPerSecond = 2592.7
MPI Rank 1: 07/14/2016 07:53:09: Finished Epoch[ 1 of 4]: [Training] CrossEntropyWithSoftmax = 3.02730057 * 20480; EvalErrorPrediction = 0.72924805 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=8.31603s
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:09: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 1: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:09: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Actual gradient aggregation time: 0.022134
MPI Rank 1: Async gradient aggregation wait time: 2e-006
MPI Rank 1: Actual gradient aggregation time: 0.044416
MPI Rank 1: 07/14/2016 07:53:09:  Epoch[ 2 of 4]-Minibatch[   1-  10, 12.50%]: CrossEntropyWithSoftmax = 2.18001252 * 2304; EvalErrorPrediction = 0.58984375 * 2304; time = 0.3874s; samplesPerSecond = 5946.8
MPI Rank 1: Async gradient aggregation wait time: 0.01264
MPI Rank 1: Actual gradient aggregation time: 0.04994
MPI Rank 1: Async gradient aggregation wait time: 0.003536
MPI Rank 1: Actual gradient aggregation time: 0.038776
MPI Rank 1: 07/14/2016 07:53:10:  Epoch[ 2 of 4]-Minibatch[  11-  20, 25.00%]: CrossEntropyWithSoftmax = 2.25843636 * 2560; EvalErrorPrediction = 0.60273438 * 2560; time = 0.4024s; samplesPerSecond = 6361.4
MPI Rank 1: Async gradient aggregation wait time: 0.012158
MPI Rank 1: Actual gradient aggregation time: 0.036034
MPI Rank 1: Async gradient aggregation wait time: 0.014491
MPI Rank 1: Actual gradient aggregation time: 0.035723
MPI Rank 1: 07/14/2016 07:53:10:  Epoch[ 2 of 4]-Minibatch[  21-  30, 37.50%]: CrossEntropyWithSoftmax = 2.25595348 * 2560; EvalErrorPrediction = 0.59609375 * 2560; time = 0.4039s; samplesPerSecond = 6337.7
MPI Rank 1: Async gradient aggregation wait time: 0.00815
MPI Rank 1: Actual gradient aggregation time: 0.041444
MPI Rank 1: Async gradient aggregation wait time: 0.012179
MPI Rank 1: Actual gradient aggregation time: 0.037406
MPI Rank 1: 07/14/2016 07:53:10:  Epoch[ 2 of 4]-Minibatch[  31-  40, 50.00%]: CrossEntropyWithSoftmax = 2.20099326 * 2560; EvalErrorPrediction = 0.57343750 * 2560; time = 0.3899s; samplesPerSecond = 6566.4
MPI Rank 1: Async gradient aggregation wait time: 0.009853
MPI Rank 1: Actual gradient aggregation time: 0.036653
MPI Rank 1: Async gradient aggregation wait time: 0.006821
MPI Rank 1: Actual gradient aggregation time: 0.038747
MPI Rank 1: 07/14/2016 07:53:11:  Epoch[ 2 of 4]-Minibatch[  41-  50, 62.50%]: CrossEntropyWithSoftmax = 2.24193716 * 2560; EvalErrorPrediction = 0.58515625 * 2560; time = 0.3832s; samplesPerSecond = 6681.0
MPI Rank 1: Async gradient aggregation wait time: 0.002943
MPI Rank 1: Actual gradient aggregation time: 0.037294
MPI Rank 1: Async gradient aggregation wait time: 0.005644
MPI Rank 1: Actual gradient aggregation time: 0.04064
MPI Rank 1: 07/14/2016 07:53:11:  Epoch[ 2 of 4]-Minibatch[  51-  60, 75.00%]: CrossEntropyWithSoftmax = 2.22339752 * 2560; EvalErrorPrediction = 0.58203125 * 2560; time = 0.3910s; samplesPerSecond = 6546.6
MPI Rank 1: Async gradient aggregation wait time: 2e-006
MPI Rank 1: Actual gradient aggregation time: 0.033965
MPI Rank 1: Async gradient aggregation wait time: 0.001246
MPI Rank 1: Actual gradient aggregation time: 0.047301
MPI Rank 1: 07/14/2016 07:53:12:  Epoch[ 2 of 4]-Minibatch[  61-  70, 87.50%]: CrossEntropyWithSoftmax = 2.08832841 * 2560; EvalErrorPrediction = 0.55195313 * 2560; time = 0.3871s; samplesPerSecond = 6614.0
MPI Rank 1: Async gradient aggregation wait time: 0.002191
MPI Rank 1: Actual gradient aggregation time: 0.04091
MPI Rank 1: Async gradient aggregation wait time: 0.008158
MPI Rank 1: Actual gradient aggregation time: 0.040354
MPI Rank 1: 07/14/2016 07:53:12:  Epoch[ 2 of 4]-Minibatch[  71-  80, 100.00%]: CrossEntropyWithSoftmax = 2.09020274 * 2560; EvalErrorPrediction = 0.57343750 * 2560; time = 0.3911s; samplesPerSecond = 6545.0
MPI Rank 1: Async gradient aggregation wait time: 0.024832
MPI Rank 1: Actual gradient aggregation time: 0.006886
MPI Rank 1: 07/14/2016 07:53:12: Finished Epoch[ 2 of 4]: [Training] CrossEntropyWithSoftmax = 2.19194914 * 20480; EvalErrorPrediction = 0.58208008 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=3.17809s
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:12: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:12: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 0.00904
MPI Rank 1: Actual gradient aggregation time: 0.127414
MPI Rank 1: Async gradient aggregation wait time: 0.02828
MPI Rank 1: Actual gradient aggregation time: 0.134799
MPI Rank 1: 07/14/2016 07:53:13:  Epoch[ 3 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.98247501 * 9216; EvalErrorPrediction = 0.54806858 * 9216; time = 1.1753s; samplesPerSecond = 7841.6
MPI Rank 1: Async gradient aggregation wait time: 0.018234
MPI Rank 1: Actual gradient aggregation time: 0.120555
MPI Rank 1: Async gradient aggregation wait time: 0.022675
MPI Rank 1: Actual gradient aggregation time: 0.118252
MPI Rank 1: 07/14/2016 07:53:15:  Epoch[ 3 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.95499777 * 10240; EvalErrorPrediction = 0.53388672 * 10240; time = 1.2245s; samplesPerSecond = 8362.3
MPI Rank 1: 07/14/2016 07:53:15: Finished Epoch[ 3 of 4]: [Training] CrossEntropyWithSoftmax = 1.96491245 * 20480; EvalErrorPrediction = 0.53925781 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-005; epochTime=2.54022s
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:15: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:15: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 3e-006
MPI Rank 1: Actual gradient aggregation time: 0.047136
MPI Rank 1: Async gradient aggregation wait time: 0.009178
MPI Rank 1: Actual gradient aggregation time: 0.110108
MPI Rank 1: 07/14/2016 07:53:16:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01431515 * 9216; EvalErrorPrediction = 0.54796007 * 9216; time = 1.1276s; samplesPerSecond = 8173.1
MPI Rank 1: Async gradient aggregation wait time: 0.009267
MPI Rank 1: Actual gradient aggregation time: 0.109644
MPI Rank 1: Async gradient aggregation wait time: 0.008674
MPI Rank 1: Actual gradient aggregation time: 0.108246
MPI Rank 1: 07/14/2016 07:53:17:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.93746303 * 10240; EvalErrorPrediction = 0.52968750 * 10240; time = 1.1537s; samplesPerSecond = 8875.8
MPI Rank 1: Async gradient aggregation wait time: 0.017267
MPI Rank 1: 07/14/2016 07:53:17: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97304685 * 20480; EvalErrorPrediction = 0.53818359 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-005; epochTime=2.39649s
MPI Rank 1: 07/14/2016 07:53:17: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:17: learnRatePerSample reduced to 4.8828126e-005
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:17: Starting Epoch 4: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:17: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 4e-006
MPI Rank 1: Actual gradient aggregation time: 0.114487
MPI Rank 1: Async gradient aggregation wait time: 0.015153
MPI Rank 1: 07/14/2016 07:53:18:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01491529 * 8508; EvalErrorPrediction = 0.54642689 * 8508; time = 1.0928s; samplesPerSecond = 7785.6
MPI Rank 1: Actual gradient aggregation time: 0.121554
MPI Rank 1: Async gradient aggregation wait time: 0.007704
MPI Rank 1: Actual gradient aggregation time: 0.109225
MPI Rank 1: Async gradient aggregation wait time: 0.010572
MPI Rank 1: 07/14/2016 07:53:20:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.93988024 * 10240; EvalErrorPrediction = 0.52968750 * 10240; time = 1.1586s; samplesPerSecond = 8838.5
MPI Rank 1: Actual gradient aggregation time: 0.10666
MPI Rank 1: 07/14/2016 07:53:20: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97330205 * 19772; EvalErrorPrediction = 0.53727493 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 4.8828126e-005; epochTime=2.38013s
MPI Rank 1: 07/14/2016 07:53:20: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:20: learnRatePerSample reduced to 2.4414063e-005
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:20: Starting Epoch 4: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:20: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 2e-006
MPI Rank 1: Actual gradient aggregation time: 0.105024
MPI Rank 1: Async gradient aggregation wait time: 0.005884
MPI Rank 1: Actual gradient aggregation time: 0.109621
MPI Rank 1: 07/14/2016 07:53:21:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01520229 * 8508; EvalErrorPrediction = 0.54677950 * 8508; time = 1.0939s; samplesPerSecond = 7777.9
MPI Rank 1: Async gradient aggregation wait time: 0.01006
MPI Rank 1: Actual gradient aggregation time: 0.117062
MPI Rank 1: Async gradient aggregation wait time: 0.018243
MPI Rank 1: Actual gradient aggregation time: 0.112683
MPI Rank 1: 07/14/2016 07:53:22:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94124338 * 10240; EvalErrorPrediction = 0.53027344 * 10240; time = 1.1502s; samplesPerSecond = 8902.8
MPI Rank 1: 07/14/2016 07:53:22: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97425474 * 19772; EvalErrorPrediction = 0.53762897 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 2.4414063e-005; epochTime=2.36166s
MPI Rank 1: 07/14/2016 07:53:22: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:22: learnRatePerSample reduced to 1.2207031e-005
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:22: Starting Epoch 4: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:22: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 2e-006
MPI Rank 1: Actual gradient aggregation time: 0.017053
MPI Rank 1: 07/14/2016 07:53:23:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01535367 * 8508; EvalErrorPrediction = 0.54677950 * 8508; time = 1.1256s; samplesPerSecond = 7558.4
MPI Rank 1: Async gradient aggregation wait time: 0.008118
MPI Rank 1: Actual gradient aggregation time: 0.117627
MPI Rank 1: Async gradient aggregation wait time: 0.006915
MPI Rank 1: Actual gradient aggregation time: 0.112191
MPI Rank 1: 07/14/2016 07:53:25:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94199445 * 10240; EvalErrorPrediction = 0.53056641 * 10240; time = 1.1323s; samplesPerSecond = 9043.5
MPI Rank 1: Async gradient aggregation wait time: 0.10652
MPI Rank 1: Actual gradient aggregation time: 0.007786
MPI Rank 1: 07/14/2016 07:53:25: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97477742 * 19772; EvalErrorPrediction = 0.53767955 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 1.2207031e-005; epochTime=2.37677s
MPI Rank 1: 07/14/2016 07:53:25: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:25: learnRatePerSample reduced to 6.1035157e-006
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:25: Starting Epoch 4: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:25: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 3e-006
MPI Rank 1: Actual gradient aggregation time: 0.111477
MPI Rank 1: Async gradient aggregation wait time: 0.005115
MPI Rank 1: Actual gradient aggregation time: 0.106975
MPI Rank 1: 07/14/2016 07:53:26:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01543141 * 8508; EvalErrorPrediction = 0.54666197 * 8508; time = 1.0766s; samplesPerSecond = 7902.4
MPI Rank 1: Async gradient aggregation wait time: 3e-006
MPI Rank 1: Actual gradient aggregation time: 0.114553
MPI Rank 1: Async gradient aggregation wait time: 0.018015
MPI Rank 1: Actual gradient aggregation time: 0.115783
MPI Rank 1: 07/14/2016 07:53:27:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94239296 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1765s; samplesPerSecond = 8703.5
MPI Rank 1: 07/14/2016 07:53:27: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97505394 * 19772; EvalErrorPrediction = 0.53778070 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 6.1035157e-006; epochTime=2.38446s
MPI Rank 1: 07/14/2016 07:53:27: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:27: learnRatePerSample reduced to 3.0517579e-006
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:27: Starting Epoch 4: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:27: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Actual gradient aggregation time: 0.113219
MPI Rank 1: Async gradient aggregation wait time: 2e-006
MPI Rank 1: Actual gradient aggregation time: 0.073456
MPI Rank 1: 07/14/2016 07:53:29:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01547080 * 8508; EvalErrorPrediction = 0.54689704 * 8508; time = 1.1661s; samplesPerSecond = 7295.9
MPI Rank 1: Async gradient aggregation wait time: 4e-006
MPI Rank 1: Actual gradient aggregation time: 0.076191
MPI Rank 1: Async gradient aggregation wait time: 2e-006
MPI Rank 1: Actual gradient aggregation time: 0.085959
MPI Rank 1: 07/14/2016 07:53:30:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94259891 * 10240; EvalErrorPrediction = 0.53076172 * 10240; time = 1.1316s; samplesPerSecond = 9049.0
MPI Rank 1: Async gradient aggregation wait time: 0.009029
MPI Rank 1: 07/14/2016 07:53:30: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97519663 * 19772; EvalErrorPrediction = 0.53793243 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 3.0517579e-006; epochTime=2.38101s
MPI Rank 1: 07/14/2016 07:53:30: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:30: learnRatePerSample reduced to 1.5258789e-006
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:30: Starting Epoch 4: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:30: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 2e-006
MPI Rank 1: Actual gradient aggregation time: 0.121042
MPI Rank 1: Async gradient aggregation wait time: 0.006266
MPI Rank 1: 07/14/2016 07:53:31:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01549063 * 8508; EvalErrorPrediction = 0.54701457 * 8508; time = 1.1121s; samplesPerSecond = 7650.7
MPI Rank 1: Actual gradient aggregation time: 0.113656
MPI Rank 1: Async gradient aggregation wait time: 0.007186
MPI Rank 1: Actual gradient aggregation time: 0.117978
MPI Rank 1: Async gradient aggregation wait time: 0.005411
MPI Rank 1: 07/14/2016 07:53:32:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94270369 * 10240; EvalErrorPrediction = 0.53076172 * 10240; time = 1.1332s; samplesPerSecond = 9036.4
MPI Rank 1: Actual gradient aggregation time: 0.114901
MPI Rank 1: 07/14/2016 07:53:32: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97526917 * 19772; EvalErrorPrediction = 0.53808416 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 1.5258789e-006; epochTime=2.37615s
MPI Rank 1: 07/14/2016 07:53:32: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:32: learnRatePerSample reduced to 7.6293946e-007
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:32: Starting Epoch 4: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:32: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 2e-006
MPI Rank 1: Actual gradient aggregation time: 0.098501
MPI Rank 1: Async gradient aggregation wait time: 2e-006
MPI Rank 1: Actual gradient aggregation time: 0.110923
MPI Rank 1: 07/14/2016 07:53:33:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01550057 * 8508; EvalErrorPrediction = 0.54689704 * 8508; time = 1.1007s; samplesPerSecond = 7729.6
MPI Rank 1: Async gradient aggregation wait time: 0.015608
MPI Rank 1: Actual gradient aggregation time: 0.114495
MPI Rank 1: Async gradient aggregation wait time: 0.004977
MPI Rank 1: Actual gradient aggregation time: 0.114421
MPI Rank 1: 07/14/2016 07:53:35:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94275655 * 10240; EvalErrorPrediction = 0.53085938 * 10240; time = 1.1447s; samplesPerSecond = 8945.7
MPI Rank 1: 07/14/2016 07:53:35: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97530575 * 19772; EvalErrorPrediction = 0.53808416 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 7.6293946e-007; epochTime=2.34865s
MPI Rank 1: 07/14/2016 07:53:35: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:35: learnRatePerSample reduced to 3.8146973e-007
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:35: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:35: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 0.007522
MPI Rank 1: Actual gradient aggregation time: 0.125077
MPI Rank 1: 07/14/2016 07:53:36:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01550555 * 8508; EvalErrorPrediction = 0.54689704 * 8508; time = 1.0840s; samplesPerSecond = 7849.0
MPI Rank 1: Async gradient aggregation wait time: 0.015488
MPI Rank 1: Actual gradient aggregation time: 0.11698
MPI Rank 1: Async gradient aggregation wait time: 0.013772
MPI Rank 1: Actual gradient aggregation time: 0.114129
MPI Rank 1: 07/14/2016 07:53:37:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94278310 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1533s; samplesPerSecond = 8878.8
MPI Rank 1: Async gradient aggregation wait time: 0.101845
MPI Rank 1: Actual gradient aggregation time: 0.009115
MPI Rank 1: 07/14/2016 07:53:37: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97532412 * 19772; EvalErrorPrediction = 0.53798301 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 3.8146973e-007; epochTime=2.35691s
MPI Rank 1: 07/14/2016 07:53:37: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:37: learnRatePerSample reduced to 1.9073487e-007
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:37: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:37: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 2e-006
MPI Rank 1: Actual gradient aggregation time: 0.084762
MPI Rank 1: Async gradient aggregation wait time: 0.01327
MPI Rank 1: Actual gradient aggregation time: 0.104865
MPI Rank 1: 07/14/2016 07:53:38:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01550805 * 8508; EvalErrorPrediction = 0.54689704 * 8508; time = 1.1109s; samplesPerSecond = 7658.8
MPI Rank 1: Async gradient aggregation wait time: 3e-006
MPI Rank 1: Actual gradient aggregation time: 0.108326
MPI Rank 1: Async gradient aggregation wait time: 0.010473
MPI Rank 1: Actual gradient aggregation time: 0.115952
MPI Rank 1: 07/14/2016 07:53:40:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94279640 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1550s; samplesPerSecond = 8865.9
MPI Rank 1: 07/14/2016 07:53:40: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97533332 * 19772; EvalErrorPrediction = 0.53798301 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 1.9073487e-007; epochTime=2.37839s
MPI Rank 1: 07/14/2016 07:53:40: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:40: learnRatePerSample reduced to 9.5367433e-008
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:40: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:40: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Actual gradient aggregation time: 0.046855
MPI Rank 1: Async gradient aggregation wait time: 0.004356
MPI Rank 1: Actual gradient aggregation time: 0.08377
MPI Rank 1: 07/14/2016 07:53:41:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01550929 * 8508; EvalErrorPrediction = 0.54689704 * 8508; time = 1.0890s; samplesPerSecond = 7812.6
MPI Rank 1: Async gradient aggregation wait time: 0.016364
MPI Rank 1: Actual gradient aggregation time: 0.118756
MPI Rank 1: Async gradient aggregation wait time: 0.006227
MPI Rank 1: Actual gradient aggregation time: 0.105268
MPI Rank 1: 07/14/2016 07:53:42:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280306 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1669s; samplesPerSecond = 8775.6
MPI Rank 1: Async gradient aggregation wait time: 0.005985
MPI Rank 1: 07/14/2016 07:53:42: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97533793 * 19772; EvalErrorPrediction = 0.53798301 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 9.5367433e-008; epochTime=2.37608s
MPI Rank 1: 07/14/2016 07:53:42: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:42: learnRatePerSample reduced to 4.7683717e-008
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:42: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:42: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 0.000527
MPI Rank 1: Actual gradient aggregation time: 0.099203
MPI Rank 1: Async gradient aggregation wait time: 3e-006
MPI Rank 1: 07/14/2016 07:53:43:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01550992 * 8508; EvalErrorPrediction = 0.54689704 * 8508; time = 1.1013s; samplesPerSecond = 7725.6
MPI Rank 1: Actual gradient aggregation time: 0.107736
MPI Rank 1: Async gradient aggregation wait time: 0.009904
MPI Rank 1: Actual gradient aggregation time: 0.117036
MPI Rank 1: Async gradient aggregation wait time: 0.008146
MPI Rank 1: 07/14/2016 07:53:44:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280640 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1297s; samplesPerSecond = 9064.0
MPI Rank 1: Actual gradient aggregation time: 0.114276
MPI Rank 1: 07/14/2016 07:53:45: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97534024 * 19772; EvalErrorPrediction = 0.53798301 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 4.7683717e-008; epochTime=2.35926s
MPI Rank 1: 07/14/2016 07:53:45: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:45: learnRatePerSample reduced to 2.3841858e-008
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:45: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:45: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 3e-006
MPI Rank 1: Actual gradient aggregation time: 0.057052
MPI Rank 1: Async gradient aggregation wait time: 3e-006
MPI Rank 1: Actual gradient aggregation time: 0.093883
MPI Rank 1: 07/14/2016 07:53:46:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01551023 * 8508; EvalErrorPrediction = 0.54689704 * 8508; time = 1.1371s; samplesPerSecond = 7482.3
MPI Rank 1: Async gradient aggregation wait time: 0.006243
MPI Rank 1: Actual gradient aggregation time: 0.115452
MPI Rank 1: Async gradient aggregation wait time: 0.012381
MPI Rank 1: Actual gradient aggregation time: 0.115912
MPI Rank 1: 07/14/2016 07:53:47:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280806 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1300s; samplesPerSecond = 9061.8
MPI Rank 1: 07/14/2016 07:53:47: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97534139 * 19772; EvalErrorPrediction = 0.53798301 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 2.3841858e-008; epochTime=2.38311s
MPI Rank 1: 07/14/2016 07:53:47: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:47: learnRatePerSample reduced to 1.1920929e-008
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:47: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:47: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 0.004813
MPI Rank 1: Actual gradient aggregation time: 0.112631
MPI Rank 1: 07/14/2016 07:53:48:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01551039 * 8508; EvalErrorPrediction = 0.54689704 * 8508; time = 1.1017s; samplesPerSecond = 7722.4
MPI Rank 1: Async gradient aggregation wait time: 0.005453
MPI Rank 1: Actual gradient aggregation time: 0.12105
MPI Rank 1: Async gradient aggregation wait time: 0.011439
MPI Rank 1: Actual gradient aggregation time: 0.112171
MPI Rank 1: 07/14/2016 07:53:49:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280890 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1380s; samplesPerSecond = 8998.2
MPI Rank 1: Async gradient aggregation wait time: 0.117492
MPI Rank 1: Actual gradient aggregation time: 0.007531
MPI Rank 1: 07/14/2016 07:53:50: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97534197 * 19772; EvalErrorPrediction = 0.53798301 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 1.1920929e-008; epochTime=2.37107s
MPI Rank 1: 07/14/2016 07:53:50: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:50: learnRatePerSample reduced to 5.9604646e-009
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:50: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:50: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 0.004689
MPI Rank 1: Actual gradient aggregation time: 0.118829
MPI Rank 1: Async gradient aggregation wait time: 2e-006
MPI Rank 1: Actual gradient aggregation time: 0.110734
MPI Rank 1: 07/14/2016 07:53:51:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01551046 * 8508; EvalErrorPrediction = 0.54689704 * 8508; time = 1.0927s; samplesPerSecond = 7786.0
MPI Rank 1: Async gradient aggregation wait time: 0.004933
MPI Rank 1: Actual gradient aggregation time: 0.114697
MPI Rank 1: Async gradient aggregation wait time: 0.012236
MPI Rank 1: Actual gradient aggregation time: 0.107582
MPI Rank 1: 07/14/2016 07:53:52:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280931 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1466s; samplesPerSecond = 8930.6
MPI Rank 1: 07/14/2016 07:53:52: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97534225 * 19772; EvalErrorPrediction = 0.53798301 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 5.9604646e-009; epochTime=2.36008s
MPI Rank 1: 07/14/2016 07:53:52: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:52: learnRatePerSample reduced to 2.9802323e-009
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:52: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:52: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Actual gradient aggregation time: 0.056147
MPI Rank 1: Async gradient aggregation wait time: 4e-006
MPI Rank 1: Actual gradient aggregation time: 0.090575
MPI Rank 1: 07/14/2016 07:53:53:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01551050 * 8508; EvalErrorPrediction = 0.54689704 * 8508; time = 1.0993s; samplesPerSecond = 7739.7
MPI Rank 1: Async gradient aggregation wait time: 0.003284
MPI Rank 1: Actual gradient aggregation time: 0.109059
MPI Rank 1: Async gradient aggregation wait time: 0.013114
MPI Rank 1: Actual gradient aggregation time: 0.115826
MPI Rank 1: 07/14/2016 07:53:54:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280952 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1519s; samplesPerSecond = 8889.3
MPI Rank 1: Async gradient aggregation wait time: 0.011961
MPI Rank 1: 07/14/2016 07:53:54: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97534240 * 19772; EvalErrorPrediction = 0.53798301 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 2.9802323e-009; epochTime=2.37299s
MPI Rank 1: 07/14/2016 07:53:54: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:55: learnRatePerSample reduced to 1.4901161e-009
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:55: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 3, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:55: Starting minibatch loop, DataParallelSGD training (MyRank = 1, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 1: Async gradient aggregation wait time: 2e-006
MPI Rank 1: Actual gradient aggregation time: 0.112651
MPI Rank 1: Async gradient aggregation wait time: 0.014358
MPI Rank 1: 07/14/2016 07:53:56:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01551052 * 8508; EvalErrorPrediction = 0.54689704 * 8508; time = 1.1033s; samplesPerSecond = 7711.4
MPI Rank 1: Actual gradient aggregation time: 0.118679
MPI Rank 1: Async gradient aggregation wait time: 0.006507
MPI Rank 1: Actual gradient aggregation time: 0.109226
MPI Rank 1: Async gradient aggregation wait time: 0.011404
MPI Rank 1: 07/14/2016 07:53:57:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280963 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1484s; samplesPerSecond = 8916.9
MPI Rank 1: Actual gradient aggregation time: 0.106674
MPI Rank 1: 07/14/2016 07:53:57: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97534247 * 19772; EvalErrorPrediction = 0.53798301 * 19772; totalSamplesSeen = 81212; learningRatePerSample = 1.4901161e-009; epochTime=2.37677s
MPI Rank 1: 07/14/2016 07:53:57: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:57: learnRatePerSample reduced to 7.4505807e-010
MPI Rank 1: 07/14/2016 07:53:57: Learn Rate Per Sample for Epoch[4] = 7.4505807e-010 is less than minLearnRate 9.9999997e-010. Training complete.
MPI Rank 1: 07/14/2016 07:53:57: CNTKCommandTrainEnd: speechTrain
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:57: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 07/14/2016 07:53:57: __COMPLETED__
MPI Rank 1: ~MPIWrapper
MPI Rank 2: 07/14/2016 07:52:58: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr_speechTrain.logrank2
MPI Rank 2: 07/14/2016 07:52:58: -------------------------------------------------------------------
MPI Rank 2: 07/14/2016 07:52:58: Build info: 
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:58: 		Built time: Jul 14 2016 07:04:27
MPI Rank 2: 07/14/2016 07:52:58: 		Last modified date: Wed Jul 13 07:40:26 2016
MPI Rank 2: 07/14/2016 07:52:58: 		Build type: Release
MPI Rank 2: 07/14/2016 07:52:58: 		Build target: GPU
MPI Rank 2: 07/14/2016 07:52:58: 		With 1bit-SGD: no
MPI Rank 2: 07/14/2016 07:52:58: 		Math lib: mkl
MPI Rank 2: 07/14/2016 07:52:58: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
MPI Rank 2: 07/14/2016 07:52:58: 		CUB_PATH: c:\src\cub-1.4.1
MPI Rank 2: 07/14/2016 07:52:58: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
MPI Rank 2: 07/14/2016 07:52:58: 		Build Branch: HEAD
MPI Rank 2: 07/14/2016 07:52:58: 		Build SHA1: b918e06de12613a1773a0976ab94e213bd09ce52
MPI Rank 2: 07/14/2016 07:52:58: 		Built by svcphil on cntk-muc01
MPI Rank 2: 07/14/2016 07:52:58: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
MPI Rank 2: 07/14/2016 07:52:58: -------------------------------------------------------------------
MPI Rank 2: 07/14/2016 07:52:58: -------------------------------------------------------------------
MPI Rank 2: 07/14/2016 07:52:58: GPU info:
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:58: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8090 MB
MPI Rank 2: 07/14/2016 07:52:58: -------------------------------------------------------------------
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:58: Running on cntk-muc00 at 2016/07/14 07:52:58
MPI Rank 2: 07/14/2016 07:52:58: Command line: 
MPI Rank 2: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu  DeviceId=-1  timestamping=true  numCPUThreads=1  precision=double  speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]  speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  speechTrain=[SGD=[maxEpochs=4]]  speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:58: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: 07/14/2016 07:52:58: precision = "float"
MPI Rank 2: command = speechTrain
MPI Rank 2: deviceId = $DeviceId$
MPI Rank 2: parallelTrain = true
MPI Rank 2: speechTrain = [
MPI Rank 2:     action = "train"
MPI Rank 2:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 2:     deviceId = $DeviceId$
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SimpleNetworkBuilder = [
MPI Rank 2:         layerSizes = 363:512:512:132
MPI Rank 2:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 2:         evalCriterion = "ErrorPrediction"
MPI Rank 2:         layerTypes = "Sigmoid"
MPI Rank 2:         initValueScale = 1.0
MPI Rank 2:         applyMeanVarNorm = true
MPI Rank 2:         uniformInit = true
MPI Rank 2:         needPrior = true
MPI Rank 2:     ]
MPI Rank 2:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 2:         layerSizes = 363:512:512:132
MPI Rank 2:         trainingCriterion = 'CE'
MPI Rank 2:         evalCriterion = 'Err'
MPI Rank 2:         applyMeanVarNorm = true
MPI Rank 2:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 2:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 2:         featNorm = if applyMeanVarNorm
MPI Rank 2:                    then MeanVarNorm(features)
MPI Rank 2:                    else features
MPI Rank 2:         layers[layer:1..L-1] = if layer > 1
MPI Rank 2:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 2:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 2:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 2:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 2:         CE = if trainingCriterion == 'CE'
MPI Rank 2:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 2:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 2:         Err = if evalCriterion == 'Err' then
MPI Rank 2:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 2:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 2:         logPrior = LogPrior(labels)
MPI Rank 2:         // TODO: how to add a tag to an infix operation?
MPI Rank 2:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 2:     ]
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize = 20480
MPI Rank 2:         minibatchSize = 64:256:1024
MPI Rank 2:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 2:         numMBsToShowResult = 10
MPI Rank 2:         momentumPerMB = 0.9:0.656119
MPI Rank 2:         dropoutRate = 0.0
MPI Rank 2:         maxEpochs = 3
MPI Rank 2:         keepCheckPointFiles = true
MPI Rank 2:         clippingThresholdPerSample = 1#INF
MPI Rank 2:         ParallelTrain = [
MPI Rank 2:             parallelizationMethod = "DataParallelSGD"
MPI Rank 2:             distributedMBReading = true
MPI Rank 2:             DataParallelSGD = [
MPI Rank 2:                 gradientBits = 32
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2:         AutoAdjust = [
MPI Rank 2:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 2:             loadBestModel = true
MPI Rank 2:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 2:             learnRateDecreaseFactor = 0.5
MPI Rank 2:             learnRateIncreaseFactor = 1.382
MPI Rank 2:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 2:         ]
MPI Rank 2:     ]
MPI Rank 2:     reader = [
MPI Rank 2:         readerType = "HTKMLFReader"
MPI Rank 2:         readMethod = "blockRandomize"
MPI Rank 2:         miniBatchMode = "partial"
MPI Rank 2:         randomize = "auto"
MPI Rank 2:         verbosity = 0
MPI Rank 2:         features = [
MPI Rank 2:             dim = 363
MPI Rank 2:             type = "real"
MPI Rank 2:             scpFile = "glob_0000.scp"
MPI Rank 2:         ]
MPI Rank 2:         labels = [
MPI Rank 2:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 2:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 2:             labelDim = 132
MPI Rank 2:             labelType = "category"
MPI Rank 2:         ]
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 2: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 2: DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 2: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN
MPI Rank 2: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 2: DeviceId=-1
MPI Rank 2: timestamping=true
MPI Rank 2: numCPUThreads=1
MPI Rank 2: precision=double
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 2: speechTrain=[SGD=[maxEpochs=4]]
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 2: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:58: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:58: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: 07/14/2016 07:52:58: precision = "float"
MPI Rank 2: command = speechTrain
MPI Rank 2: deviceId = -1
MPI Rank 2: parallelTrain = true
MPI Rank 2: speechTrain = [
MPI Rank 2:     action = "train"
MPI Rank 2:     modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn"
MPI Rank 2:     deviceId = -1
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SimpleNetworkBuilder = [
MPI Rank 2:         layerSizes = 363:512:512:132
MPI Rank 2:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 2:         evalCriterion = "ErrorPrediction"
MPI Rank 2:         layerTypes = "Sigmoid"
MPI Rank 2:         initValueScale = 1.0
MPI Rank 2:         applyMeanVarNorm = true
MPI Rank 2:         uniformInit = true
MPI Rank 2:         needPrior = true
MPI Rank 2:     ]
MPI Rank 2:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 2:         layerSizes = 363:512:512:132
MPI Rank 2:         trainingCriterion = 'CE'
MPI Rank 2:         evalCriterion = 'Err'
MPI Rank 2:         applyMeanVarNorm = true
MPI Rank 2:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 2:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 2:         featNorm = if applyMeanVarNorm
MPI Rank 2:                    then MeanVarNorm(features)
MPI Rank 2:                    else features
MPI Rank 2:         layers[layer:1..L-1] = if layer > 1
MPI Rank 2:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 2:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 2:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 2:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 2:         CE = if trainingCriterion == 'CE'
MPI Rank 2:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 2:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 2:         Err = if evalCriterion == 'Err' then
MPI Rank 2:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 2:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 2:         logPrior = LogPrior(labels)
MPI Rank 2:         // TODO: how to add a tag to an infix operation?
MPI Rank 2:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 2:     ]
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize = 20480
MPI Rank 2:         minibatchSize = 64:256:1024
MPI Rank 2:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 2:         numMBsToShowResult = 10
MPI Rank 2:         momentumPerMB = 0.9:0.656119
MPI Rank 2:         dropoutRate = 0.0
MPI Rank 2:         maxEpochs = 3
MPI Rank 2:         keepCheckPointFiles = true
MPI Rank 2:         clippingThresholdPerSample = 1#INF
MPI Rank 2:         ParallelTrain = [
MPI Rank 2:             parallelizationMethod = "DataParallelSGD"
MPI Rank 2:             distributedMBReading = true
MPI Rank 2:             DataParallelSGD = [
MPI Rank 2:                 gradientBits = 32
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2:         AutoAdjust = [
MPI Rank 2:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 2:             loadBestModel = true
MPI Rank 2:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 2:             learnRateDecreaseFactor = 0.5
MPI Rank 2:             learnRateIncreaseFactor = 1.382
MPI Rank 2:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 2:         ]
MPI Rank 2:     ]
MPI Rank 2:     reader = [
MPI Rank 2:         readerType = "HTKMLFReader"
MPI Rank 2:         readMethod = "blockRandomize"
MPI Rank 2:         miniBatchMode = "partial"
MPI Rank 2:         randomize = "auto"
MPI Rank 2:         verbosity = 0
MPI Rank 2:         features = [
MPI Rank 2:             dim = 363
MPI Rank 2:             type = "real"
MPI Rank 2:             scpFile = "glob_0000.scp"
MPI Rank 2:         ]
MPI Rank 2:         labels = [
MPI Rank 2:             mlfFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
MPI Rank 2:             labelMappingFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list"
MPI Rank 2:             labelDim = 132
MPI Rank 2:             labelType = "category"
MPI Rank 2:         ]
MPI Rank 2:     ]
MPI Rank 2: ]
MPI Rank 2: currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 2: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 2: DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 2: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN
MPI Rank 2: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 2: DeviceId=-1
MPI Rank 2: timestamping=true
MPI Rank 2: numCPUThreads=1
MPI Rank 2: precision=double
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]]
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]]
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 2: speechTrain=[SGD=[maxEpochs=4]]
MPI Rank 2: speechTrain=[SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 2: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:58: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:58: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 2: configparameters: cntk.cntk:command=speechTrain
MPI Rank 2: configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN
MPI Rank 2: configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 2: configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 2: configparameters: cntk.cntk:deviceId=-1
MPI Rank 2: configparameters: cntk.cntk:numCPUThreads=1
MPI Rank 2: configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 2: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 2: configparameters: cntk.cntk:precision=double
MPI Rank 2: configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu
MPI Rank 2: configparameters: cntk.cntk:speechTrain=[
MPI Rank 2:     action = "train"
MPI Rank 2:     modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn"
MPI Rank 2:     deviceId = -1
MPI Rank 2:     traceLevel = 1
MPI Rank 2:     SimpleNetworkBuilder = [
MPI Rank 2:         layerSizes = 363:512:512:132
MPI Rank 2:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 2:         evalCriterion = "ErrorPrediction"
MPI Rank 2:         layerTypes = "Sigmoid"
MPI Rank 2:         initValueScale = 1.0
MPI Rank 2:         applyMeanVarNorm = true
MPI Rank 2:         uniformInit = true
MPI Rank 2:         needPrior = true
MPI Rank 2:     ]
MPI Rank 2:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 2:         layerSizes = 363:512:512:132
MPI Rank 2:         trainingCriterion = 'CE'
MPI Rank 2:         evalCriterion = 'Err'
MPI Rank 2:         applyMeanVarNorm = true
MPI Rank 2:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 2:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 2:         featNorm = if applyMeanVarNorm
MPI Rank 2:                    then MeanVarNorm(features)
MPI Rank 2:                    else features
MPI Rank 2:         layers[layer:1..L-1] = if layer > 1
MPI Rank 2:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 2:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 2:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 2:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 2:         CE = if trainingCriterion == 'CE'
MPI Rank 2:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 2:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 2:         Err = if evalCriterion == 'Err' then
MPI Rank 2:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 2:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 2:         logPrior = LogPrior(labels)
MPI Rank 2:         // TODO: how to add a tag to an infix operation?
MPI Rank 2:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 2:     ]
MPI Rank 2:     SGD = [
MPI Rank 2:         epochSize = 20480
MPI Rank 2:         minibatchSize = 64:256:1024
MPI Rank 2:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 2:         numMBsToShowResult = 10
MPI Rank 2:         momentumPerMB = 0.9:0.656119
MPI Rank 2:         dropoutRate = 0.0
MPI Rank 2:         maxEpochs = 3
MPI Rank 2:         keepCheckPointFiles = true
MPI Rank 2:         clippingThresholdPerSample = 1#INF
MPI Rank 2:         ParallelTrain = [
MPI Rank 2:             parallelizationMethod = "DataParallelSGD"
MPI Rank 2:             distributedMBReading = true
MPI Rank 2:             DataParallelSGD = [
MPI Rank 2:                 gradientBits = 32
MPI Rank 2:             ]
MPI Rank 2:         ]
MPI Rank 2:         AutoAdjust = [
MPI Rank 2:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 2:             loadBestModel = true
MPI Rank 2:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 2:             learnRateDecreaseFactor = 0.5
MPI Rank 2:             learnRateIncreaseFactor = 1.382
MPI Rank 2:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 2:         ]
MPI Rank 2:     ]
MPI Rank 2:     reader = [
MPI Rank 2:         readerType = "HTKMLFReader"
MPI Rank 2:         readMethod = "blockRandomize"
MPI Rank 2:         miniBatchMode = "partial"
MPI Rank 2:         randomize = "auto"
MPI Rank 2:         verbosity = 0
MPI Rank 2:         features = [
MPI Rank 2:             dim = 363
MPI Rank 2:             type = "real"
MPI Rank 2:             scpFile = "glob_0000.scp"
MPI Rank 2:         ]
MPI Rank 2:         labels = [
MPI Rank 2:             mlfFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
MPI Rank 2:             labelMappingFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list"
MPI Rank 2:             labelDim = 132
MPI Rank 2:             labelType = "category"
MPI Rank 2:         ]
MPI Rank 2:     ]
MPI Rank 2: ] [SGD=[ParallelTrain=[DataParallelSGD=[gradientBits=64]]]] [SGD=[ParallelTrain=[DataParallelSGD=[useBufferedAsyncGradientAggregation=true]]]] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] [SGD=[maxEpochs=4]] [SGD=[ParallelTrain=[syncPerfStats=5]]]
MPI Rank 2: 
MPI Rank 2: configparameters: cntk.cntk:stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/stderr
MPI Rank 2: configparameters: cntk.cntk:timestamping=true
MPI Rank 2: 07/14/2016 07:52:58: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 2: 07/14/2016 07:52:58: Commands: speechTrain
MPI Rank 2: 07/14/2016 07:52:58: Precision = "double"
MPI Rank 2: 07/14/2016 07:52:58: Using 1 CPU threads.
MPI Rank 2: 07/14/2016 07:52:58: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn
MPI Rank 2: 07/14/2016 07:52:58: CNTKCommandTrainInfo: speechTrain : 4
MPI Rank 2: 07/14/2016 07:52:58: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 4
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:58: ##############################################################################
MPI Rank 2: 07/14/2016 07:52:58: #                                                                            #
MPI Rank 2: 07/14/2016 07:52:58: # Action "train"                                                             #
MPI Rank 2: 07/14/2016 07:52:58: #                                                                            #
MPI Rank 2: 07/14/2016 07:52:58: ##############################################################################
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:58: CNTKCommandTrainBegin: speechTrain
MPI Rank 2: SimpleNetworkBuilder Using CPU
MPI Rank 2: reading script file glob_0000.scp ... 946 entries
MPI Rank 2: total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list
MPI Rank 2: htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
MPI Rank 2: ...............................................................................................feature set 0: 252508 frames in 946 out of 946 utterances
MPI Rank 2: label set 0: 129 classes
MPI Rank 2: minibatchutterancesource: 946 utterances grouped into 3 chunks, av. chunk size: 315.3 utterances, 84169.3 frames
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:59: Creating virgin network.
MPI Rank 2: 
MPI Rank 2: Post-processing network...
MPI Rank 2: 
MPI Rank 2: 7 roots:
MPI Rank 2: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 2: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 2: 	InvStdOfFeatures = InvStdDev()
MPI Rank 2: 	MeanOfFeatures = Mean()
MPI Rank 2: 	PosteriorProb = Softmax()
MPI Rank 2: 	Prior = Mean()
MPI Rank 2: 	ScaledLogLikelihood = Minus()
MPI Rank 2: 
MPI Rank 2: Validating network. 25 nodes to process in pass 1.
MPI Rank 2: 
MPI Rank 2: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 2: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 2: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 2: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 2: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 2: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 2: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 2: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 2: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 2: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 2: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 2: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 2: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 2: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 2: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 2: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 2: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 2: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 2: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 2: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 2: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 2: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 2: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 2: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 2: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 2: 
MPI Rank 2: Validating network. 17 nodes to process in pass 2.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Validating network, final pass.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 2: 
MPI Rank 2: Post-processing network complete.
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:59: Created model with 25 nodes on CPU.
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:59: Training criterion node(s):
MPI Rank 2: 07/14/2016 07:52:59: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:59: Evaluation criterion node(s):
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:59: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: Allocating matrices for forward and/or backward propagation.
MPI Rank 2: 
MPI Rank 2: Memory Sharing Structure:
MPI Rank 2: 
MPI Rank 2: 0000000000000000: {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 2: 0000002AABB65C30: {[B0 Value[512 x 1]] }
MPI Rank 2: 0000002AABB65CD0: {[W0 Value[512 x 363]] }
MPI Rank 2: 0000002AABB66090: {[features Value[363 x *]] }
MPI Rank 2: 0000002AABB663B0: {[MeanOfFeatures Value[363]] }
MPI Rank 2: 0000002AABB666D0: {[InvStdOfFeatures Value[363]] }
MPI Rank 2: 0000002AC63F2D50: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 2: 0000002AC63F3750: {[B2 Gradient[132 x 1]] }
MPI Rank 2: 0000002AC650AEF0: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 2: 0000002AC650AF90: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 2: 0000002AC650B030: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 2: 0000002AC650B170: {[Prior Value[132]] }
MPI Rank 2: 0000002AC650B3F0: {[B2 Value[132 x 1]] }
MPI Rank 2: 0000002AC650B5D0: {[labels Value[132 x *]] }
MPI Rank 2: 0000002AC650B7B0: {[W0*features Value[512 x *]] }
MPI Rank 2: 0000002AC650B990: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 2: 0000002AC650BA30: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 2: 0000002AC650BAD0: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 2: 0000002AC650BB70: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 2: 0000002AC650BC10: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 2: 0000002AC650BDF0: {[B1 Value[512 x 1]] }
MPI Rank 2: 0000002AC650BFD0: {[W1 Value[512 x 512]] }
MPI Rank 2: 0000002AC650C110: {[EvalErrorPrediction Value[1]] }
MPI Rank 2: 0000002AC650C1B0: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 2: 0000002AC650C250: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 2: 0000002AC650C430: {[W2 Value[132 x 512]] }
MPI Rank 2: 0000002AC650C570: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 2: 0000002AC650C9D0: {[LogOfPrior Value[132]] }
MPI Rank 2: 0000002AC650CB10: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:59: Precomputing --> 3 PreCompute nodes found.
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:52:59: 	MeanOfFeatures = Mean()
MPI Rank 2: 07/14/2016 07:52:59: 	InvStdOfFeatures = InvStdDev()
MPI Rank 2: 07/14/2016 07:52:59: 	Prior = Mean()
MPI Rank 2: minibatchiterator: epoch 0: frames [0..252508] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 2: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:00: Precomputing --> Completed.
MPI Rank 2: 
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:00: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 2: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:00: Starting minibatch loop.
MPI Rank 2: 07/14/2016 07:53:01:  Epoch[ 1 of 4]-Minibatch[   1-  10, 3.13%]: CrossEntropyWithSoftmax = 4.45416150 * 640; EvalErrorPrediction = 0.89687500 * 640; time = 0.2778s; samplesPerSecond = 2303.9
MPI Rank 2: 07/14/2016 07:53:01:  Epoch[ 1 of 4]-Minibatch[  11-  20, 6.25%]: CrossEntropyWithSoftmax = 4.33591146 * 640; EvalErrorPrediction = 0.88593750 * 640; time = 0.2708s; samplesPerSecond = 2363.3
MPI Rank 2: 07/14/2016 07:53:01:  Epoch[ 1 of 4]-Minibatch[  21-  30, 9.38%]: CrossEntropyWithSoftmax = 4.00507652 * 640; EvalErrorPrediction = 0.90781250 * 640; time = 0.2556s; samplesPerSecond = 2503.5
MPI Rank 2: 07/14/2016 07:53:02:  Epoch[ 1 of 4]-Minibatch[  31-  40, 12.50%]: CrossEntropyWithSoftmax = 3.82762088 * 640; EvalErrorPrediction = 0.85468750 * 640; time = 0.2547s; samplesPerSecond = 2513.2
MPI Rank 2: 07/14/2016 07:53:02:  Epoch[ 1 of 4]-Minibatch[  41-  50, 15.63%]: CrossEntropyWithSoftmax = 3.73892559 * 640; EvalErrorPrediction = 0.87187500 * 640; time = 0.2533s; samplesPerSecond = 2526.6
MPI Rank 2: 07/14/2016 07:53:02:  Epoch[ 1 of 4]-Minibatch[  51-  60, 18.75%]: CrossEntropyWithSoftmax = 3.71036275 * 640; EvalErrorPrediction = 0.85937500 * 640; time = 0.2786s; samplesPerSecond = 2297.3
MPI Rank 2: 07/14/2016 07:53:02:  Epoch[ 1 of 4]-Minibatch[  61-  70, 21.88%]: CrossEntropyWithSoftmax = 3.71827746 * 640; EvalErrorPrediction = 0.86406250 * 640; time = 0.2603s; samplesPerSecond = 2458.7
MPI Rank 2: 07/14/2016 07:53:03:  Epoch[ 1 of 4]-Minibatch[  71-  80, 25.00%]: CrossEntropyWithSoftmax = 3.53746828 * 640; EvalErrorPrediction = 0.79687500 * 640; time = 0.2561s; samplesPerSecond = 2498.6
MPI Rank 2: 07/14/2016 07:53:03:  Epoch[ 1 of 4]-Minibatch[  81-  90, 28.13%]: CrossEntropyWithSoftmax = 3.39240122 * 640; EvalErrorPrediction = 0.80937500 * 640; time = 0.2510s; samplesPerSecond = 2550.3
MPI Rank 2: 07/14/2016 07:53:03:  Epoch[ 1 of 4]-Minibatch[  91- 100, 31.25%]: CrossEntropyWithSoftmax = 3.43721506 * 640; EvalErrorPrediction = 0.80156250 * 640; time = 0.2514s; samplesPerSecond = 2545.9
MPI Rank 2: 07/14/2016 07:53:03:  Epoch[ 1 of 4]-Minibatch[ 101- 110, 34.38%]: CrossEntropyWithSoftmax = 3.26915145 * 640; EvalErrorPrediction = 0.77968750 * 640; time = 0.2656s; samplesPerSecond = 2410.0
MPI Rank 2: 07/14/2016 07:53:04:  Epoch[ 1 of 4]-Minibatch[ 111- 120, 37.50%]: CrossEntropyWithSoftmax = 3.14847957 * 640; EvalErrorPrediction = 0.77031250 * 640; time = 0.2609s; samplesPerSecond = 2452.8
MPI Rank 2: 07/14/2016 07:53:04:  Epoch[ 1 of 4]-Minibatch[ 121- 130, 40.63%]: CrossEntropyWithSoftmax = 3.13805770 * 640; EvalErrorPrediction = 0.74375000 * 640; time = 0.2575s; samplesPerSecond = 2485.5
MPI Rank 2: 07/14/2016 07:53:04:  Epoch[ 1 of 4]-Minibatch[ 131- 140, 43.75%]: CrossEntropyWithSoftmax = 2.99768374 * 640; EvalErrorPrediction = 0.71875000 * 640; time = 0.2515s; samplesPerSecond = 2544.5
MPI Rank 2: 07/14/2016 07:53:04:  Epoch[ 1 of 4]-Minibatch[ 141- 150, 46.88%]: CrossEntropyWithSoftmax = 3.01058834 * 640; EvalErrorPrediction = 0.73281250 * 640; time = 0.2526s; samplesPerSecond = 2533.3
MPI Rank 2: 07/14/2016 07:53:05:  Epoch[ 1 of 4]-Minibatch[ 151- 160, 50.00%]: CrossEntropyWithSoftmax = 3.02335619 * 640; EvalErrorPrediction = 0.74531250 * 640; time = 0.2523s; samplesPerSecond = 2536.7
MPI Rank 2: 07/14/2016 07:53:05:  Epoch[ 1 of 4]-Minibatch[ 161- 170, 53.13%]: CrossEntropyWithSoftmax = 2.93449884 * 640; EvalErrorPrediction = 0.71562500 * 640; time = 0.2516s; samplesPerSecond = 2543.3
MPI Rank 2: 07/14/2016 07:53:05:  Epoch[ 1 of 4]-Minibatch[ 171- 180, 56.25%]: CrossEntropyWithSoftmax = 2.77168265 * 640; EvalErrorPrediction = 0.69062500 * 640; time = 0.2528s; samplesPerSecond = 2532.0
MPI Rank 2: 07/14/2016 07:53:05:  Epoch[ 1 of 4]-Minibatch[ 181- 190, 59.38%]: CrossEntropyWithSoftmax = 2.80254906 * 640; EvalErrorPrediction = 0.69687500 * 640; time = 0.2524s; samplesPerSecond = 2535.2
MPI Rank 2: 07/14/2016 07:53:06:  Epoch[ 1 of 4]-Minibatch[ 191- 200, 62.50%]: CrossEntropyWithSoftmax = 2.64220148 * 640; EvalErrorPrediction = 0.68437500 * 640; time = 0.2523s; samplesPerSecond = 2536.8
MPI Rank 2: 07/14/2016 07:53:06:  Epoch[ 1 of 4]-Minibatch[ 201- 210, 65.63%]: CrossEntropyWithSoftmax = 2.59237117 * 640; EvalErrorPrediction = 0.65937500 * 640; time = 0.2508s; samplesPerSecond = 2551.9
MPI Rank 2: 07/14/2016 07:53:06:  Epoch[ 1 of 4]-Minibatch[ 211- 220, 68.75%]: CrossEntropyWithSoftmax = 2.66093734 * 640; EvalErrorPrediction = 0.68906250 * 640; time = 0.2507s; samplesPerSecond = 2552.4
MPI Rank 2: 07/14/2016 07:53:06:  Epoch[ 1 of 4]-Minibatch[ 221- 230, 71.88%]: CrossEntropyWithSoftmax = 2.49158886 * 640; EvalErrorPrediction = 0.65781250 * 640; time = 0.2513s; samplesPerSecond = 2546.4
MPI Rank 2: 07/14/2016 07:53:07:  Epoch[ 1 of 4]-Minibatch[ 231- 240, 75.00%]: CrossEntropyWithSoftmax = 2.60665098 * 640; EvalErrorPrediction = 0.66093750 * 640; time = 0.2518s; samplesPerSecond = 2541.9
MPI Rank 2: 07/14/2016 07:53:07:  Epoch[ 1 of 4]-Minibatch[ 241- 250, 78.13%]: CrossEntropyWithSoftmax = 2.50170098 * 640; EvalErrorPrediction = 0.63125000 * 640; time = 0.2511s; samplesPerSecond = 2549.2
MPI Rank 2: 07/14/2016 07:53:07:  Epoch[ 1 of 4]-Minibatch[ 251- 260, 81.25%]: CrossEntropyWithSoftmax = 2.35502599 * 640; EvalErrorPrediction = 0.59687500 * 640; time = 0.2610s; samplesPerSecond = 2451.7
MPI Rank 2: 07/14/2016 07:53:07:  Epoch[ 1 of 4]-Minibatch[ 261- 270, 84.38%]: CrossEntropyWithSoftmax = 2.32071817 * 640; EvalErrorPrediction = 0.60156250 * 640; time = 0.2588s; samplesPerSecond = 2472.8
MPI Rank 2: 07/14/2016 07:53:08:  Epoch[ 1 of 4]-Minibatch[ 271- 280, 87.50%]: CrossEntropyWithSoftmax = 2.37646415 * 640; EvalErrorPrediction = 0.62500000 * 640; time = 0.2545s; samplesPerSecond = 2514.9
MPI Rank 2: 07/14/2016 07:53:08:  Epoch[ 1 of 4]-Minibatch[ 281- 290, 90.63%]: CrossEntropyWithSoftmax = 2.28159506 * 640; EvalErrorPrediction = 0.58906250 * 640; time = 0.2559s; samplesPerSecond = 2500.9
MPI Rank 2: 07/14/2016 07:53:08:  Epoch[ 1 of 4]-Minibatch[ 291- 300, 93.75%]: CrossEntropyWithSoftmax = 2.26445286 * 640; EvalErrorPrediction = 0.59843750 * 640; time = 0.2549s; samplesPerSecond = 2511.1
MPI Rank 2: 07/14/2016 07:53:08:  Epoch[ 1 of 4]-Minibatch[ 301- 310, 96.88%]: CrossEntropyWithSoftmax = 2.24143044 * 640; EvalErrorPrediction = 0.58125000 * 640; time = 0.2564s; samplesPerSecond = 2495.7
MPI Rank 2: 07/14/2016 07:53:09:  Epoch[ 1 of 4]-Minibatch[ 311- 320, 100.00%]: CrossEntropyWithSoftmax = 2.28501255 * 640; EvalErrorPrediction = 0.61875000 * 640; time = 0.2609s; samplesPerSecond = 2452.9
MPI Rank 2: 07/14/2016 07:53:09: Finished Epoch[ 1 of 4]: [Training] CrossEntropyWithSoftmax = 3.02730057 * 20480; EvalErrorPrediction = 0.72924805 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=8.23065s
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:09: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 2: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:09: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Actual gradient aggregation time: 0.017429
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.041565
MPI Rank 2: 07/14/2016 07:53:09:  Epoch[ 2 of 4]-Minibatch[   1-  10, 12.50%]: CrossEntropyWithSoftmax = 2.18001252 * 2304; EvalErrorPrediction = 0.58984375 * 2304; time = 0.3871s; samplesPerSecond = 5951.2
MPI Rank 2: Async gradient aggregation wait time: 0.015142
MPI Rank 2: Actual gradient aggregation time: 0.040508
MPI Rank 2: Async gradient aggregation wait time: 0.006968
MPI Rank 2: Actual gradient aggregation time: 0.038717
MPI Rank 2: 07/14/2016 07:53:10:  Epoch[ 2 of 4]-Minibatch[  11-  20, 25.00%]: CrossEntropyWithSoftmax = 2.25843636 * 2560; EvalErrorPrediction = 0.60273438 * 2560; time = 0.4026s; samplesPerSecond = 6358.5
MPI Rank 2: Async gradient aggregation wait time: 0.009363
MPI Rank 2: Actual gradient aggregation time: 0.038675
MPI Rank 2: Async gradient aggregation wait time: 0.013786
MPI Rank 2: Actual gradient aggregation time: 0.037639
MPI Rank 2: 07/14/2016 07:53:10:  Epoch[ 2 of 4]-Minibatch[  21-  30, 37.50%]: CrossEntropyWithSoftmax = 2.25595348 * 2560; EvalErrorPrediction = 0.59609375 * 2560; time = 0.4033s; samplesPerSecond = 6348.3
MPI Rank 2: Async gradient aggregation wait time: 0.008507
MPI Rank 2: Actual gradient aggregation time: 0.041325
MPI Rank 2: Async gradient aggregation wait time: 0.006225
MPI Rank 2: Actual gradient aggregation time: 0.037263
MPI Rank 2: 07/14/2016 07:53:10:  Epoch[ 2 of 4]-Minibatch[  31-  40, 50.00%]: CrossEntropyWithSoftmax = 2.20099326 * 2560; EvalErrorPrediction = 0.57343750 * 2560; time = 0.3903s; samplesPerSecond = 6559.4
MPI Rank 2: Async gradient aggregation wait time: 0.007873
MPI Rank 2: Actual gradient aggregation time: 0.039385
MPI Rank 2: Async gradient aggregation wait time: 0.008486
MPI Rank 2: Actual gradient aggregation time: 0.038384
MPI Rank 2: 07/14/2016 07:53:11:  Epoch[ 2 of 4]-Minibatch[  41-  50, 62.50%]: CrossEntropyWithSoftmax = 2.24193716 * 2560; EvalErrorPrediction = 0.58515625 * 2560; time = 0.3830s; samplesPerSecond = 6684.0
MPI Rank 2: Async gradient aggregation wait time: 0.005226
MPI Rank 2: Actual gradient aggregation time: 0.038825
MPI Rank 2: Async gradient aggregation wait time: 0.007417
MPI Rank 2: Actual gradient aggregation time: 0.040521
MPI Rank 2: 07/14/2016 07:53:11:  Epoch[ 2 of 4]-Minibatch[  51-  60, 75.00%]: CrossEntropyWithSoftmax = 2.22339752 * 2560; EvalErrorPrediction = 0.58203125 * 2560; time = 0.3821s; samplesPerSecond = 6699.2
MPI Rank 2: Async gradient aggregation wait time: 0.004931
MPI Rank 2: Actual gradient aggregation time: 0.044632
MPI Rank 2: Async gradient aggregation wait time: 0.005488
MPI Rank 2: Actual gradient aggregation time: 0.047083
MPI Rank 2: 07/14/2016 07:53:12:  Epoch[ 2 of 4]-Minibatch[  61-  70, 87.50%]: CrossEntropyWithSoftmax = 2.08832841 * 2560; EvalErrorPrediction = 0.55195313 * 2560; time = 0.3960s; samplesPerSecond = 6464.6
MPI Rank 2: Async gradient aggregation wait time: 0.005233
MPI Rank 2: Actual gradient aggregation time: 0.040049
MPI Rank 2: Async gradient aggregation wait time: 0.005268
MPI Rank 2: Actual gradient aggregation time: 0.040555
MPI Rank 2: 07/14/2016 07:53:12:  Epoch[ 2 of 4]-Minibatch[  71-  80, 100.00%]: CrossEntropyWithSoftmax = 2.09020274 * 2560; EvalErrorPrediction = 0.57343750 * 2560; time = 0.3914s; samplesPerSecond = 6540.9
MPI Rank 2: Async gradient aggregation wait time: 0.0247
MPI Rank 2: Actual gradient aggregation time: 0.012581
MPI Rank 2: 07/14/2016 07:53:12: Finished Epoch[ 2 of 4]: [Training] CrossEntropyWithSoftmax = 2.19194914 * 20480; EvalErrorPrediction = 0.58208008 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=3.17799s
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:12: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:12: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.05819
MPI Rank 2: Async gradient aggregation wait time: 0.015538
MPI Rank 2: Actual gradient aggregation time: 0.133959
MPI Rank 2: 07/14/2016 07:53:13:  Epoch[ 3 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 1.98247501 * 9216; EvalErrorPrediction = 0.54806858 * 9216; time = 1.1588s; samplesPerSecond = 7953.3
MPI Rank 2: Async gradient aggregation wait time: 0.016809
MPI Rank 2: Actual gradient aggregation time: 0.123586
MPI Rank 2: Async gradient aggregation wait time: 0.010991
MPI Rank 2: Actual gradient aggregation time: 0.116422
MPI Rank 2: 07/14/2016 07:53:15:  Epoch[ 3 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.95499777 * 10240; EvalErrorPrediction = 0.53388672 * 10240; time = 1.2249s; samplesPerSecond = 8359.7
MPI Rank 2: 07/14/2016 07:53:15: Finished Epoch[ 3 of 4]: [Training] CrossEntropyWithSoftmax = 1.96491245 * 20480; EvalErrorPrediction = 0.53925781 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-005; epochTime=2.52513s
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:15: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:15: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.028681
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.074746
MPI Rank 2: 07/14/2016 07:53:16:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01431515 * 9216; EvalErrorPrediction = 0.54796007 * 9216; time = 1.1405s; samplesPerSecond = 8080.4
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.096317
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.088297
MPI Rank 2: 07/14/2016 07:53:17:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.93746303 * 10240; EvalErrorPrediction = 0.52968750 * 10240; time = 1.1314s; samplesPerSecond = 9050.9
MPI Rank 2: Async gradient aggregation wait time: 0.012896
MPI Rank 2: 07/14/2016 07:53:17: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97304685 * 20480; EvalErrorPrediction = 0.53818359 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-005; epochTime=2.37071s
MPI Rank 2: 07/14/2016 07:53:17: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:17: learnRatePerSample reduced to 4.8828126e-005
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:17: Starting Epoch 4: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:17: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.086302
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: 07/14/2016 07:53:18:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01446155 * 8526; EvalErrorPrediction = 0.54574243 * 8526; time = 1.0969s; samplesPerSecond = 7773.0
MPI Rank 2: Actual gradient aggregation time: 0.118053
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.099681
MPI Rank 2: Async gradient aggregation wait time: 1e-006
MPI Rank 2: 07/14/2016 07:53:20:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.93988024 * 10240; EvalErrorPrediction = 0.52968750 * 10240; time = 1.1582s; samplesPerSecond = 8841.2
MPI Rank 2: Actual gradient aggregation time: 0.107707
MPI Rank 2: 07/14/2016 07:53:20: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97314442 * 19790; EvalErrorPrediction = 0.53698838 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 4.8828126e-005; epochTime=2.37992s
MPI Rank 2: 07/14/2016 07:53:20: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:20: learnRatePerSample reduced to 2.4414063e-005
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:20: Starting Epoch 4: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:20: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.095957
MPI Rank 2: Async gradient aggregation wait time: 0.006213
MPI Rank 2: Actual gradient aggregation time: 0.109657
MPI Rank 2: 07/14/2016 07:53:21:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01474795 * 8526; EvalErrorPrediction = 0.54609430 * 8526; time = 1.0991s; samplesPerSecond = 7757.0
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.111512
MPI Rank 2: Async gradient aggregation wait time: 0.000483
MPI Rank 2: Actual gradient aggregation time: 0.115485
MPI Rank 2: 07/14/2016 07:53:22:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94124338 * 10240; EvalErrorPrediction = 0.53027344 * 10240; time = 1.1451s; samplesPerSecond = 8942.4
MPI Rank 2: 07/14/2016 07:53:22: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97409625 * 19790; EvalErrorPrediction = 0.53734209 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 2.4414063e-005; epochTime=2.36123s
MPI Rank 2: 07/14/2016 07:53:22: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:22: learnRatePerSample reduced to 1.2207031e-005
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:22: Starting Epoch 4: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:22: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.031238
MPI Rank 2: 07/14/2016 07:53:23:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01489901 * 8526; EvalErrorPrediction = 0.54609430 * 8526; time = 1.1037s; samplesPerSecond = 7725.2
MPI Rank 2: Async gradient aggregation wait time: 1e-006
MPI Rank 2: Actual gradient aggregation time: 0.11554
MPI Rank 2: Async gradient aggregation wait time: 0.0007
MPI Rank 2: Actual gradient aggregation time: 0.110868
MPI Rank 2: 07/14/2016 07:53:25:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94199445 * 10240; EvalErrorPrediction = 0.53056641 * 10240; time = 1.1273s; samplesPerSecond = 9083.3
MPI Rank 2: Async gradient aggregation wait time: 0.098058
MPI Rank 2: Actual gradient aggregation time: 0.013901
MPI Rank 2: 07/14/2016 07:53:25: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97461844 * 19790; EvalErrorPrediction = 0.53739262 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 1.2207031e-005; epochTime=2.34918s
MPI Rank 2: 07/14/2016 07:53:25: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:25: learnRatePerSample reduced to 6.1035157e-006
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:25: Starting Epoch 4: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:25: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.054881
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.03614
MPI Rank 2: 07/14/2016 07:53:26:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01497659 * 8526; EvalErrorPrediction = 0.54597701 * 8526; time = 1.1512s; samplesPerSecond = 7406.5
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.04993
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.082578
MPI Rank 2: 07/14/2016 07:53:27:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94239296 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1288s; samplesPerSecond = 9071.6
MPI Rank 2: 07/14/2016 07:53:27: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97489472 * 19790; EvalErrorPrediction = 0.53749368 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 6.1035157e-006; epochTime=2.38428s
MPI Rank 2: 07/14/2016 07:53:27: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:27: learnRatePerSample reduced to 3.0517579e-006
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:27: Starting Epoch 4: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:27: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Actual gradient aggregation time: 0.081952
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.091002
MPI Rank 2: 07/14/2016 07:53:28:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01501589 * 8526; EvalErrorPrediction = 0.54621159 * 8526; time = 1.1094s; samplesPerSecond = 7685.2
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.117647
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.120567
MPI Rank 2: 07/14/2016 07:53:30:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94259891 * 10240; EvalErrorPrediction = 0.53076172 * 10240; time = 1.1519s; samplesPerSecond = 8889.8
MPI Rank 2: Async gradient aggregation wait time: 0.005993
MPI Rank 2: 07/14/2016 07:53:30: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97503727 * 19790; EvalErrorPrediction = 0.53764528 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 3.0517579e-006; epochTime=2.35246s
MPI Rank 2: 07/14/2016 07:53:30: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:30: learnRatePerSample reduced to 1.5258789e-006
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:30: Starting Epoch 4: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:30: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.070302
MPI Rank 2: Async gradient aggregation wait time: 0.001545
MPI Rank 2: 07/14/2016 07:53:31:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01503568 * 8526; EvalErrorPrediction = 0.54632888 * 8526; time = 1.0838s; samplesPerSecond = 7867.0
MPI Rank 2: Actual gradient aggregation time: 0.114161
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.10739
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: 07/14/2016 07:53:32:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94270369 * 10240; EvalErrorPrediction = 0.53076172 * 10240; time = 1.1520s; samplesPerSecond = 8888.9
MPI Rank 2: Actual gradient aggregation time: 0.103045
MPI Rank 2: 07/14/2016 07:53:32: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97510975 * 19790; EvalErrorPrediction = 0.53779687 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 1.5258789e-006; epochTime=2.34777s
MPI Rank 2: 07/14/2016 07:53:32: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:32: learnRatePerSample reduced to 7.6293946e-007
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:32: Starting Epoch 4: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:32: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.090339
MPI Rank 2: Async gradient aggregation wait time: 0.006768
MPI Rank 2: Actual gradient aggregation time: 0.115173
MPI Rank 2: 07/14/2016 07:53:33:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01504560 * 8526; EvalErrorPrediction = 0.54621159 * 8526; time = 1.1009s; samplesPerSecond = 7744.6
MPI Rank 2: Async gradient aggregation wait time: 0.003731
MPI Rank 2: Actual gradient aggregation time: 0.115121
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.11057
MPI Rank 2: 07/14/2016 07:53:35:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94275655 * 10240; EvalErrorPrediction = 0.53085938 * 10240; time = 1.1446s; samplesPerSecond = 8946.0
MPI Rank 2: 07/14/2016 07:53:35: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97514630 * 19790; EvalErrorPrediction = 0.53779687 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 7.6293946e-007; epochTime=2.34846s
MPI Rank 2: 07/14/2016 07:53:35: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:35: learnRatePerSample reduced to 3.8146973e-007
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:35: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:35: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.06388
MPI Rank 2: 07/14/2016 07:53:36:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01505057 * 8526; EvalErrorPrediction = 0.54621159 * 8526; time = 1.1463s; samplesPerSecond = 7438.1
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.054795
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.052282
MPI Rank 2: 07/14/2016 07:53:37:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94278310 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1485s; samplesPerSecond = 8915.8
MPI Rank 2: Async gradient aggregation wait time: 0.043085
MPI Rank 2: Actual gradient aggregation time: 0.012475
MPI Rank 2: 07/14/2016 07:53:37: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97516465 * 19790; EvalErrorPrediction = 0.53769581 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 3.8146973e-007; epochTime=2.35681s
MPI Rank 2: 07/14/2016 07:53:37: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:37: learnRatePerSample reduced to 1.9073487e-007
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:37: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:37: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.028337
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.062541
MPI Rank 2: 07/14/2016 07:53:38:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01505306 * 8526; EvalErrorPrediction = 0.54621159 * 8526; time = 1.1456s; samplesPerSecond = 7442.5
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.034789
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.04827
MPI Rank 2: 07/14/2016 07:53:40:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94279640 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1544s; samplesPerSecond = 8870.7
MPI Rank 2: 07/14/2016 07:53:40: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97517385 * 19790; EvalErrorPrediction = 0.53769581 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 1.9073487e-007; epochTime=2.3496s
MPI Rank 2: 07/14/2016 07:53:40: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:40: learnRatePerSample reduced to 9.5367433e-008
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:40: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:40: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Actual gradient aggregation time: 0.013857
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.024979
MPI Rank 2: 07/14/2016 07:53:41:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01505431 * 8526; EvalErrorPrediction = 0.54621159 * 8526; time = 1.1370s; samplesPerSecond = 7498.6
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.068383
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.024882
MPI Rank 2: 07/14/2016 07:53:42:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280306 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1874s; samplesPerSecond = 8623.9
MPI Rank 2: Async gradient aggregation wait time: 0.008408
MPI Rank 2: 07/14/2016 07:53:42: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97517845 * 19790; EvalErrorPrediction = 0.53769581 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 9.5367433e-008; epochTime=2.37604s
MPI Rank 2: 07/14/2016 07:53:42: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:42: learnRatePerSample reduced to 4.7683717e-008
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:42: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:42: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 0.001031
MPI Rank 2: Actual gradient aggregation time: 0.097483
MPI Rank 2: Async gradient aggregation wait time: 0.004751
MPI Rank 2: 07/14/2016 07:53:43:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01505493 * 8526; EvalErrorPrediction = 0.54621159 * 8526; time = 1.0924s; samplesPerSecond = 7804.8
MPI Rank 2: Actual gradient aggregation time: 0.116366
MPI Rank 2: Async gradient aggregation wait time: 0.001073
MPI Rank 2: Actual gradient aggregation time: 0.115214
MPI Rank 2: Async gradient aggregation wait time: 1e-006
MPI Rank 2: 07/14/2016 07:53:44:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280640 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1464s; samplesPerSecond = 8932.1
MPI Rank 2: Actual gradient aggregation time: 0.105221
MPI Rank 2: 07/14/2016 07:53:45: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97518075 * 19790; EvalErrorPrediction = 0.53769581 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 4.7683717e-008; epochTime=2.35908s
MPI Rank 2: 07/14/2016 07:53:45: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:45: learnRatePerSample reduced to 2.3841858e-008
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:45: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:45: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.015079
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.112706
MPI Rank 2: 07/14/2016 07:53:46:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01505524 * 8526; EvalErrorPrediction = 0.54621159 * 8526; time = 1.1075s; samplesPerSecond = 7698.2
MPI Rank 2: Async gradient aggregation wait time: 0.003576
MPI Rank 2: Actual gradient aggregation time: 0.115388
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.088985
MPI Rank 2: 07/14/2016 07:53:47:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280806 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1465s; samplesPerSecond = 8931.6
MPI Rank 2: 07/14/2016 07:53:47: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97518190 * 19790; EvalErrorPrediction = 0.53769581 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 2.3841858e-008; epochTime=2.35665s
MPI Rank 2: 07/14/2016 07:53:47: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:47: learnRatePerSample reduced to 1.1920929e-008
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:47: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:47: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.104021
MPI Rank 2: 07/14/2016 07:53:48:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01505540 * 8526; EvalErrorPrediction = 0.54621159 * 8526; time = 1.1014s; samplesPerSecond = 7741.2
MPI Rank 2: Async gradient aggregation wait time: 0.003959
MPI Rank 2: Actual gradient aggregation time: 0.120974
MPI Rank 2: Async gradient aggregation wait time: 0.004717
MPI Rank 2: Actual gradient aggregation time: 0.110848
MPI Rank 2: 07/14/2016 07:53:49:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280890 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1388s; samplesPerSecond = 8991.7
MPI Rank 2: Async gradient aggregation wait time: 0.110421
MPI Rank 2: Actual gradient aggregation time: 0.013916
MPI Rank 2: 07/14/2016 07:53:50: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97518248 * 19790; EvalErrorPrediction = 0.53769581 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 1.1920929e-008; epochTime=2.37087s
MPI Rank 2: 07/14/2016 07:53:50: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:50: learnRatePerSample reduced to 5.9604646e-009
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:50: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:50: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.105382
MPI Rank 2: Async gradient aggregation wait time: 0.010444
MPI Rank 2: Actual gradient aggregation time: 0.114265
MPI Rank 2: 07/14/2016 07:53:51:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01505547 * 8526; EvalErrorPrediction = 0.54621159 * 8526; time = 1.0926s; samplesPerSecond = 7803.7
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: Actual gradient aggregation time: 0.100877
MPI Rank 2: Async gradient aggregation wait time: 0.001128
MPI Rank 2: Actual gradient aggregation time: 0.109702
MPI Rank 2: 07/14/2016 07:53:52:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280931 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1546s; samplesPerSecond = 8868.6
MPI Rank 2: 07/14/2016 07:53:52: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97518277 * 19790; EvalErrorPrediction = 0.53769581 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 5.9604646e-009; epochTime=2.35988s
MPI Rank 2: 07/14/2016 07:53:52: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:52: learnRatePerSample reduced to 2.9802323e-009
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:52: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:52: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Actual gradient aggregation time: 0.049206
MPI Rank 2: Async gradient aggregation wait time: 0.001951
MPI Rank 2: Actual gradient aggregation time: 0.105703
MPI Rank 2: 07/14/2016 07:53:53:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01505551 * 8526; EvalErrorPrediction = 0.54621159 * 8526; time = 1.0987s; samplesPerSecond = 7760.0
MPI Rank 2: Async gradient aggregation wait time: 0.004431
MPI Rank 2: Actual gradient aggregation time: 0.109
MPI Rank 2: Async gradient aggregation wait time: 0.005436
MPI Rank 2: Actual gradient aggregation time: 0.114081
MPI Rank 2: 07/14/2016 07:53:54:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280952 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1514s; samplesPerSecond = 8893.3
MPI Rank 2: Async gradient aggregation wait time: 0.007069
MPI Rank 2: 07/14/2016 07:53:54: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97518291 * 19790; EvalErrorPrediction = 0.53769581 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 2.9802323e-009; epochTime=2.37255s
MPI Rank 2: 07/14/2016 07:53:54: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:55: learnRatePerSample reduced to 1.4901161e-009
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:55: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 2: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 2 of 3, with 1 datapasses
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:55: Starting minibatch loop, DataParallelSGD training (MyRank = 2, NumNodes = 3, NumGradientBits = 64), BufferedAsyncGradientAggregation is ENABLED, distributed reading is ENABLED.
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: Actual gradient aggregation time: 0.045305
MPI Rank 2: Async gradient aggregation wait time: 3e-006
MPI Rank 2: 07/14/2016 07:53:56:  Epoch[ 4 of 4]-Minibatch[   1-  10, 50.00%]: CrossEntropyWithSoftmax = 2.01505553 * 8526; EvalErrorPrediction = 0.54621159 * 8526; time = 1.1362s; samplesPerSecond = 7503.8
MPI Rank 2: Actual gradient aggregation time: 0.087884
MPI Rank 2: Async gradient aggregation wait time: 1e-006
MPI Rank 2: Actual gradient aggregation time: 0.105992
MPI Rank 2: Async gradient aggregation wait time: 2e-006
MPI Rank 2: 07/14/2016 07:53:57:  Epoch[ 4 of 4]-Minibatch[  11-  20, 100.00%]: CrossEntropyWithSoftmax = 1.94280963 * 10240; EvalErrorPrediction = 0.53066406 * 10240; time = 1.1356s; samplesPerSecond = 9017.5
MPI Rank 2: Actual gradient aggregation time: 0.090516
MPI Rank 2: 07/14/2016 07:53:57: Finished Epoch[ 4 of 4]: [Training] CrossEntropyWithSoftmax = 1.97518298 * 19790; EvalErrorPrediction = 0.53769581 * 19790; totalSamplesSeen = 81230; learningRatePerSample = 1.4901161e-009; epochTime=2.37656s
MPI Rank 2: 07/14/2016 07:53:57: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160714075121.487046\Speech\DNN_ParallelNoQuantizationBufferedAsyncGradientAggregation@release_cpu/models/cntkSpeech.dnn.3.
MPI Rank 2: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/14/2016 07:53:57: learnRatePerSample reduced to 7.4505807e-010
MPI Rank 2: 07/14/2016 07:53:57: Learn Rate Per Sample for Epoch[4] = 7.4505807e-010 is less than minLearnRate 9.9999997e-010. Training complete.
MPI Rank 2: 07/14/2016 07:53:57: CNTKCommandTrainEnd: speechTrain
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:57: Action "train" complete.
MPI Rank 2: 
MPI Rank 2: 07/14/2016 07:53:57: __COMPLETED__
MPI Rank 2: ~MPIWrapper