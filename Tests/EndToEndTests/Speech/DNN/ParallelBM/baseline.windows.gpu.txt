CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU W3530 @ 2.80GHz
    Hardware threads: 4
    Total Memory: 12580404 kB
-------------------------------------------------------------------
=== Running C:\Program Files\Microsoft MPI\Bin\/mpiexec.exe -n 2 C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN/ParallelBM/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu DeviceId=0 timestamping=true numCPUThreads=2 precision=double speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]] stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/stderr
-------------------------------------------------------------------
Build info: 

		Built time: Jul 15 2016 00:48:16
		Last modified date: Fri Jul  8 02:53:05 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: c:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 500f0ccaa040821405404d7879c0e823003f1544
		Built by svcphil on Philly-Pool1
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPIWrapper: initializing MPI
-------------------------------------------------------------------
Build info: 

		Built time: Jul 15 2016 00:48:16
		Last modified date: Fri Jul  8 02:53:05 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: c:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 500f0ccaa040821405404d7879c0e823003f1544
		Built by svcphil on Philly-Pool1
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPIWrapper: initializing MPI
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: 2 nodes pinging each other
ping [requestnodes (before change)]: all 2 nodes responded
ping [requestnodes (before change)]: all 2 nodes responded
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (0) are in (participating)
requestnodes [MPIWrapper]: using 2 out of 2 MPI nodes (2 requested); we (1) are in (participating)
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: 2 nodes pinging each other
ping [requestnodes (after change)]: all 2 nodes responded
ping [requestnodes (after change)]: all 2 nodes responded
mpihelper: we are cog 0 in a gearbox of 2
ping [mpihelper]: 2 nodes pinging each other
mpihelper: we are cog 1 in a gearbox of 2
ping [mpihelper]: 2 nodes pinging each other
ping [mpihelper]: all 2 nodes responded
ping [mpihelper]: all 2 nodes responded
MPI Rank 0: 07/15/2016 00:56:08: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/stderr_speechTrain.logrank0
MPI Rank 0: 07/15/2016 00:56:08: -------------------------------------------------------------------
MPI Rank 0: 07/15/2016 00:56:08: Build info: 
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: 		Built time: Jul 15 2016 00:48:16
MPI Rank 0: 07/15/2016 00:56:08: 		Last modified date: Fri Jul  8 02:53:05 2016
MPI Rank 0: 07/15/2016 00:56:08: 		Build type: Release
MPI Rank 0: 07/15/2016 00:56:08: 		Build target: GPU
MPI Rank 0: 07/15/2016 00:56:08: 		With 1bit-SGD: no
MPI Rank 0: 07/15/2016 00:56:08: 		Math lib: mkl
MPI Rank 0: 07/15/2016 00:56:08: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
MPI Rank 0: 07/15/2016 00:56:08: 		CUB_PATH: c:\src\cub-1.4.1
MPI Rank 0: 07/15/2016 00:56:08: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
MPI Rank 0: 07/15/2016 00:56:08: 		Build Branch: HEAD
MPI Rank 0: 07/15/2016 00:56:08: 		Build SHA1: 500f0ccaa040821405404d7879c0e823003f1544
MPI Rank 0: 07/15/2016 00:56:08: 		Built by svcphil on Philly-Pool1
MPI Rank 0: 07/15/2016 00:56:08: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
MPI Rank 0: 07/15/2016 00:56:08: -------------------------------------------------------------------
MPI Rank 0: 07/15/2016 00:56:08: -------------------------------------------------------------------
MPI Rank 0: 07/15/2016 00:56:08: GPU info:
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8090 MB
MPI Rank 0: 07/15/2016 00:56:08: -------------------------------------------------------------------
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: Running on cntk-muc00 at 2016/07/15 00:56:08
MPI Rank 0: 07/15/2016 00:56:08: Command line: 
MPI Rank 0: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN/ParallelBM/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=2  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 07/15/2016 00:56:08: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = $DeviceId$
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = $DeviceId$
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 0: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu
MPI Rank 0: DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 0: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN
MPI Rank 0: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=2
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: 07/15/2016 00:56:08: precision = "float"
MPI Rank 0: command = speechTrain
MPI Rank 0: deviceId = 0
MPI Rank 0: parallelTrain = true
MPI Rank 0: speechTrain = [
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = 0
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ]
MPI Rank 0: currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 0: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu
MPI Rank 0: DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 0: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN
MPI Rank 0: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu
MPI Rank 0: DeviceId=0
MPI Rank 0: timestamping=true
MPI Rank 0: numCPUThreads=2
MPI Rank 0: precision=double
MPI Rank 0: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/stderr
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 0: configparameters: cntk.cntk:command=speechTrain
MPI Rank 0: configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN
MPI Rank 0: configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 0: configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 0: configparameters: cntk.cntk:deviceId=0
MPI Rank 0: configparameters: cntk.cntk:numCPUThreads=2
MPI Rank 0: configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu
MPI Rank 0: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 0: configparameters: cntk.cntk:precision=double
MPI Rank 0: configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu
MPI Rank 0: configparameters: cntk.cntk:speechTrain=[
MPI Rank 0:     action = "train"
MPI Rank 0:     modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn"
MPI Rank 0:     deviceId = 0
MPI Rank 0:     traceLevel = 1
MPI Rank 0:     SimpleNetworkBuilder = [
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 0:         evalCriterion = "ErrorPrediction"
MPI Rank 0:         layerTypes = "Sigmoid"
MPI Rank 0:         initValueScale = 1.0
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         uniformInit = true
MPI Rank 0:         needPrior = true
MPI Rank 0:     ]
MPI Rank 0:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 0:         layerSizes = 363:512:512:132
MPI Rank 0:         trainingCriterion = 'CE'
MPI Rank 0:         evalCriterion = 'Err'
MPI Rank 0:         applyMeanVarNorm = true
MPI Rank 0:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 0:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 0:         featNorm = if applyMeanVarNorm
MPI Rank 0:                    then MeanVarNorm(features)
MPI Rank 0:                    else features
MPI Rank 0:         layers[layer:1..L-1] = if layer > 1
MPI Rank 0:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 0:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 0:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 0:         CE = if trainingCriterion == 'CE'
MPI Rank 0:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 0:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 0:         Err = if evalCriterion == 'Err' then
MPI Rank 0:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 0:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 0:         logPrior = LogPrior(labels)
MPI Rank 0:         // TODO: how to add a tag to an infix operation?
MPI Rank 0:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 0:     ]
MPI Rank 0:     SGD = [
MPI Rank 0:         epochSize = 20480
MPI Rank 0:         minibatchSize = 64:256:1024
MPI Rank 0:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 0:         numMBsToShowResult = 3
MPI Rank 0:         momentumPerMB = 0.9:0.656119
MPI Rank 0:         dropoutRate = 0.0
MPI Rank 0:         maxEpochs = 5
MPI Rank 0:         keepCheckPointFiles = true
MPI Rank 0:         clippingThresholdPerSample = 1#INF
MPI Rank 0:         ParallelTrain = [
MPI Rank 0:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 0:             distributedMBReading = true
MPI Rank 0:             syncPerfStats=1
MPI Rank 0:             BlockMomentumSGD = [
MPI Rank 0:                 blockSizePerWorker=2048
MPI Rank 0:                 resetSGDMomentum=true
MPI Rank 0:                 useNesterovMomentum=true
MPI Rank 0:             ]
MPI Rank 0:         ]
MPI Rank 0:         AutoAdjust = [
MPI Rank 0:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 0:             loadBestModel = true
MPI Rank 0:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 0:             learnRateDecreaseFactor = 0.5
MPI Rank 0:             learnRateIncreaseFactor = 1.382
MPI Rank 0:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0:     reader = [
MPI Rank 0:         readerType = "HTKMLFReader"
MPI Rank 0:         readMethod = "blockRandomize"
MPI Rank 0:         miniBatchMode = "partial"
MPI Rank 0:         randomize = "auto"
MPI Rank 0:         verbosity = 0
MPI Rank 0:         features = [
MPI Rank 0:             dim = 363
MPI Rank 0:             type = "real"
MPI Rank 0:             scpFile = "glob_0000.scp"
MPI Rank 0:         ]
MPI Rank 0:         labels = [
MPI Rank 0:             mlfFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
MPI Rank 0:             labelMappingFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list"
MPI Rank 0:             labelDim = 132
MPI Rank 0:             labelType = "category"
MPI Rank 0:         ]
MPI Rank 0:     ]
MPI Rank 0: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 0: 
MPI Rank 0: configparameters: cntk.cntk:stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/stderr
MPI Rank 0: configparameters: cntk.cntk:timestamping=true
MPI Rank 0: 07/15/2016 00:56:08: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 0: 07/15/2016 00:56:08: Commands: speechTrain
MPI Rank 0: 07/15/2016 00:56:08: Precision = "double"
MPI Rank 0: 07/15/2016 00:56:08: Using 2 CPU threads.
MPI Rank 0: 07/15/2016 00:56:08: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn
MPI Rank 0: 07/15/2016 00:56:08: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 0: 07/15/2016 00:56:08: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: ##############################################################################
MPI Rank 0: 07/15/2016 00:56:08: #                                                                            #
MPI Rank 0: 07/15/2016 00:56:08: # Action "train"                                                             #
MPI Rank 0: 07/15/2016 00:56:08: #                                                                            #
MPI Rank 0: 07/15/2016 00:56:08: ##############################################################################
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: CNTKCommandTrainBegin: speechTrain
MPI Rank 0: SimpleNetworkBuilder Using GPU 0
MPI Rank 0: reading script file glob_0000.scp ... 946 entries
MPI Rank 0: total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list
MPI Rank 0: htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
MPI Rank 0: ...............................................................................................feature set 0: 252508 frames in 946 out of 946 utterances
MPI Rank 0: label set 0: 129 classes
MPI Rank 0: minibatchutterancesource: 946 utterances grouped into 3 chunks, av. chunk size: 315.3 utterances, 84169.3 frames
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: Creating virgin network.
MPI Rank 0: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==8
MPI Rank 0: 
MPI Rank 0: Post-processing network...
MPI Rank 0: 
MPI Rank 0: 7 roots:
MPI Rank 0: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 0: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 0: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 	MeanOfFeatures = Mean()
MPI Rank 0: 	PosteriorProb = Softmax()
MPI Rank 0: 	Prior = Mean()
MPI Rank 0: 	ScaledLogLikelihood = Minus()
MPI Rank 0: 
MPI Rank 0: Validating network. 25 nodes to process in pass 1.
MPI Rank 0: 
MPI Rank 0: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 0: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 0: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 0: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 0: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 0: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 0: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 0: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 0: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 0: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 0: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 0: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 0: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 0: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 0: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 0: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 0: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 0: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 0: 
MPI Rank 0: Validating network. 17 nodes to process in pass 2.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Validating network, final pass.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 0: 
MPI Rank 0: Post-processing network complete.
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: Created model with 25 nodes on GPU 0.
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: Training criterion node(s):
MPI Rank 0: 07/15/2016 00:56:08: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: Evaluation criterion node(s):
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: Allocating matrices for forward and/or backward propagation.
MPI Rank 0: 
MPI Rank 0: Memory Sharing Structure:
MPI Rank 0: 
MPI Rank 0: 0000000000000000: {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 0: 00000047D5736CC0: {[features Value[363 x *]] }
MPI Rank 0: 00000047DFE45190: {[InvStdOfFeatures Value[363]] }
MPI Rank 0: 00000047DFE45230: {[W0 Value[512 x 363]] }
MPI Rank 0: 00000047DFE46810: {[MeanOfFeatures Value[363]] }
MPI Rank 0: 00000047E0C0E190: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 0: 00000047E0C0E230: {[W1 Value[512 x 512]] }
MPI Rank 0: 00000047E0C0E410: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 0: 00000047E0C0E5F0: {[B1 Value[512 x 1]] }
MPI Rank 0: 00000047E0C0E690: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 0: 00000047E0C0E910: {[B2 Value[132 x 1]] }
MPI Rank 0: 00000047E0C0EAF0: {[labels Value[132 x *]] }
MPI Rank 0: 00000047E0C0EFF0: {[LogOfPrior Value[132]] }
MPI Rank 0: 00000047E0C0F090: {[W0*features Value[512 x *]] }
MPI Rank 0: 00000047E0C0F270: {[W2 Value[132 x 512]] }
MPI Rank 0: 00000047E0C0F810: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 0: 00000047E0C0F8B0: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 0: 00000047E0C0F950: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 0: 00000047E0C0F9F0: {[B0 Value[512 x 1]] }
MPI Rank 0: 00000047E0C0FA90: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 0: 00000047E0C0FB30: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 0: 00000047E0C0FBD0: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 0: 00000047E0C0FC70: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 0: 00000047E0C0FD10: {[EvalErrorPrediction Value[1]] }
MPI Rank 0: 00000047E0C0FF90: {[Prior Value[132]] }
MPI Rank 0: 00000047E0F0FF60: {[B2 Gradient[132 x 1]] }
MPI Rank 0: 00000047E0F10140: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 0: 00000047E0F106E0: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 0: 00000047E0F10FA0: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: Precomputing --> 3 PreCompute nodes found.
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:08: 	MeanOfFeatures = Mean()
MPI Rank 0: 07/15/2016 00:56:08: 	InvStdOfFeatures = InvStdDev()
MPI Rank 0: 07/15/2016 00:56:08: 	Prior = Mean()
MPI Rank 0: minibatchiterator: epoch 0: frames [0..252508] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:10: Precomputing --> Completed.
MPI Rank 0: 
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:11: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 0: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:11: Starting minibatch loop.
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: CrossEntropyWithSoftmax = 4.54985671 * 192; EvalErrorPrediction = 0.90625000 * 192; time = 0.0294s; samplesPerSecond = 6521.1
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: CrossEntropyWithSoftmax = 4.62421727 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0277s; samplesPerSecond = 6926.7
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: CrossEntropyWithSoftmax = 4.60673092 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0280s; samplesPerSecond = 6858.9
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: CrossEntropyWithSoftmax = 4.97632255 * 192; EvalErrorPrediction = 0.94270833 * 192; time = 0.0269s; samplesPerSecond = 7124.6
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: CrossEntropyWithSoftmax = 4.66584622 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0268s; samplesPerSecond = 7161.0
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.63%]: CrossEntropyWithSoftmax = 4.18831920 * 192; EvalErrorPrediction = 0.92708333 * 192; time = 0.0269s; samplesPerSecond = 7135.7
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: CrossEntropyWithSoftmax = 4.13295634 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.0269s; samplesPerSecond = 7139.1
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: CrossEntropyWithSoftmax = 4.18511141 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0268s; samplesPerSecond = 7160.7
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: CrossEntropyWithSoftmax = 3.98331448 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0268s; samplesPerSecond = 7172.5
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: CrossEntropyWithSoftmax = 4.16919401 * 192; EvalErrorPrediction = 0.92187500 * 192; time = 0.0270s; samplesPerSecond = 7123.8
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: CrossEntropyWithSoftmax = 4.09981466 * 192; EvalErrorPrediction = 0.93750000 * 192; time = 0.0269s; samplesPerSecond = 7128.0
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: CrossEntropyWithSoftmax = 3.83972586 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0268s; samplesPerSecond = 7151.1
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: CrossEntropyWithSoftmax = 3.75721610 * 192; EvalErrorPrediction = 0.85937500 * 192; time = 0.0270s; samplesPerSecond = 7118.2
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.13%]: CrossEntropyWithSoftmax = 3.79732611 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0267s; samplesPerSecond = 7182.7
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: CrossEntropyWithSoftmax = 3.86692363 * 192; EvalErrorPrediction = 0.88541667 * 192; time = 0.0270s; samplesPerSecond = 7122.2
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: CrossEntropyWithSoftmax = 3.67286346 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0267s; samplesPerSecond = 7186.2
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: CrossEntropyWithSoftmax = 3.87106136 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0270s; samplesPerSecond = 7114.0
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: CrossEntropyWithSoftmax = 3.75056797 * 192; EvalErrorPrediction = 0.90104167 * 192; time = 0.0269s; samplesPerSecond = 7141.5
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: CrossEntropyWithSoftmax = 3.84544346 * 192; EvalErrorPrediction = 0.88541667 * 192; time = 0.0269s; samplesPerSecond = 7136.2
MPI Rank 0: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: CrossEntropyWithSoftmax = 3.64287052 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0268s; samplesPerSecond = 7151.4
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: CrossEntropyWithSoftmax = 3.92078976 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0270s; samplesPerSecond = 7119.5
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.63%]: CrossEntropyWithSoftmax = 3.79566577 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0268s; samplesPerSecond = 7168.5
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: CrossEntropyWithSoftmax = 3.61988387 * 192; EvalErrorPrediction = 0.82291667 * 192; time = 0.0268s; samplesPerSecond = 7153.5
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: CrossEntropyWithSoftmax = 3.74199773 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0269s; samplesPerSecond = 7148.4
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: CrossEntropyWithSoftmax = 3.63084952 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0270s; samplesPerSecond = 7123.0
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: CrossEntropyWithSoftmax = 3.45945773 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0269s; samplesPerSecond = 7141.5
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: CrossEntropyWithSoftmax = 3.55141658 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0269s; samplesPerSecond = 7142.6
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: CrossEntropyWithSoftmax = 3.44071315 * 192; EvalErrorPrediction = 0.82291667 * 192; time = 0.0268s; samplesPerSecond = 7155.4
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: CrossEntropyWithSoftmax = 3.31704470 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0269s; samplesPerSecond = 7142.9
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.13%]: CrossEntropyWithSoftmax = 3.62294748 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0270s; samplesPerSecond = 7116.1
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: CrossEntropyWithSoftmax = 3.51139878 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.0267s; samplesPerSecond = 7199.6
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: CrossEntropyWithSoftmax = 3.51339983 * 192; EvalErrorPrediction = 0.81250000 * 192; time = 0.0270s; samplesPerSecond = 7114.8
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: CrossEntropyWithSoftmax = 3.54667155 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0267s; samplesPerSecond = 7182.7
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: CrossEntropyWithSoftmax = 3.43704752 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0267s; samplesPerSecond = 7181.1
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: CrossEntropyWithSoftmax = 3.57815526 * 192; EvalErrorPrediction = 0.81250000 * 192; time = 0.0268s; samplesPerSecond = 7170.6
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: CrossEntropyWithSoftmax = 3.33757570 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.0269s; samplesPerSecond = 7134.1
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: CrossEntropyWithSoftmax = 3.15832412 * 192; EvalErrorPrediction = 0.75000000 * 192; time = 0.0270s; samplesPerSecond = 7111.4
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.63%]: CrossEntropyWithSoftmax = 3.05551739 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0268s; samplesPerSecond = 7160.2
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: CrossEntropyWithSoftmax = 3.40350558 * 192; EvalErrorPrediction = 0.82812500 * 192; time = 0.0269s; samplesPerSecond = 7147.4
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: CrossEntropyWithSoftmax = 3.18639281 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.0269s; samplesPerSecond = 7140.7
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: CrossEntropyWithSoftmax = 3.22695349 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0267s; samplesPerSecond = 7179.2
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: CrossEntropyWithSoftmax = 3.18736051 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0268s; samplesPerSecond = 7157.5
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: CrossEntropyWithSoftmax = 3.26793036 * 192; EvalErrorPrediction = 0.78645833 * 192; time = 0.0267s; samplesPerSecond = 7183.7
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: CrossEntropyWithSoftmax = 3.17620983 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0270s; samplesPerSecond = 7101.4
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: CrossEntropyWithSoftmax = 3.05395443 * 192; EvalErrorPrediction = 0.73958333 * 192; time = 0.0269s; samplesPerSecond = 7149.5
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.13%]: CrossEntropyWithSoftmax = 3.17101776 * 192; EvalErrorPrediction = 0.73958333 * 192; time = 0.0268s; samplesPerSecond = 7152.4
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: CrossEntropyWithSoftmax = 3.16266163 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0269s; samplesPerSecond = 7149.5
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: CrossEntropyWithSoftmax = 3.04947943 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0268s; samplesPerSecond = 7168.5
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: CrossEntropyWithSoftmax = 3.03787804 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0269s; samplesPerSecond = 7136.0
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: CrossEntropyWithSoftmax = 3.37505611 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0268s; samplesPerSecond = 7163.6
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: CrossEntropyWithSoftmax = 3.11576940 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0269s; samplesPerSecond = 7145.5
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: CrossEntropyWithSoftmax = 3.09661420 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0269s; samplesPerSecond = 7145.2
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: CrossEntropyWithSoftmax = 3.24909614 * 192; EvalErrorPrediction = 0.77083333 * 192; time = 0.0269s; samplesPerSecond = 7140.2
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.63%]: CrossEntropyWithSoftmax = 3.24574806 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0269s; samplesPerSecond = 7127.7
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: CrossEntropyWithSoftmax = 3.22551994 * 192; EvalErrorPrediction = 0.77083333 * 192; time = 0.0269s; samplesPerSecond = 7145.2
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: CrossEntropyWithSoftmax = 3.07646835 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0269s; samplesPerSecond = 7124.8
MPI Rank 0: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: CrossEntropyWithSoftmax = 2.96517688 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0269s; samplesPerSecond = 7138.9
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: CrossEntropyWithSoftmax = 3.02513893 * 192; EvalErrorPrediction = 0.78645833 * 192; time = 0.0268s; samplesPerSecond = 7161.8
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: CrossEntropyWithSoftmax = 2.88973893 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0268s; samplesPerSecond = 7152.4
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: CrossEntropyWithSoftmax = 2.75494001 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0268s; samplesPerSecond = 7152.7
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: CrossEntropyWithSoftmax = 3.25271651 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0269s; samplesPerSecond = 7132.0
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: CrossEntropyWithSoftmax = 2.68362652 * 192; EvalErrorPrediction = 0.65104167 * 192; time = 0.0268s; samplesPerSecond = 7165.2
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: CrossEntropyWithSoftmax = 2.91338829 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0268s; samplesPerSecond = 7151.9
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: CrossEntropyWithSoftmax = 2.94477536 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0269s; samplesPerSecond = 7131.4
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: CrossEntropyWithSoftmax = 2.94022818 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0268s; samplesPerSecond = 7165.8
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: CrossEntropyWithSoftmax = 2.76999441 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0269s; samplesPerSecond = 7127.7
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: CrossEntropyWithSoftmax = 2.57738224 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0268s; samplesPerSecond = 7156.2
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: CrossEntropyWithSoftmax = 2.80973999 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0269s; samplesPerSecond = 7133.3
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: CrossEntropyWithSoftmax = 2.80985528 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0268s; samplesPerSecond = 7165.8
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.63%]: CrossEntropyWithSoftmax = 2.65858712 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.0257s; samplesPerSecond = 7466.7
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: CrossEntropyWithSoftmax = 2.93366494 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0284s; samplesPerSecond = 6763.2
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: CrossEntropyWithSoftmax = 2.75795196 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.0257s; samplesPerSecond = 7464.4
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: CrossEntropyWithSoftmax = 2.77030221 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0279s; samplesPerSecond = 6886.2
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: CrossEntropyWithSoftmax = 2.93586418 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0268s; samplesPerSecond = 7170.1
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: CrossEntropyWithSoftmax = 2.56269117 * 192; EvalErrorPrediction = 0.69270833 * 192; time = 0.0269s; samplesPerSecond = 7135.4
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: CrossEntropyWithSoftmax = 2.68413019 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0268s; samplesPerSecond = 7166.6
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: CrossEntropyWithSoftmax = 2.61743301 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0267s; samplesPerSecond = 7180.0
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.13%]: CrossEntropyWithSoftmax = 2.70835473 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0269s; samplesPerSecond = 7136.2
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: CrossEntropyWithSoftmax = 2.77084696 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0269s; samplesPerSecond = 7139.1
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: CrossEntropyWithSoftmax = 2.72317929 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0269s; samplesPerSecond = 7130.7
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: CrossEntropyWithSoftmax = 2.70887975 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0268s; samplesPerSecond = 7153.5
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: CrossEntropyWithSoftmax = 2.64868942 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0268s; samplesPerSecond = 7172.7
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: CrossEntropyWithSoftmax = 2.75929689 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0268s; samplesPerSecond = 7158.0
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: CrossEntropyWithSoftmax = 2.48219263 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0269s; samplesPerSecond = 7148.4
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: CrossEntropyWithSoftmax = 2.69453834 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0268s; samplesPerSecond = 7151.9
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.63%]: CrossEntropyWithSoftmax = 2.36278558 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0268s; samplesPerSecond = 7163.9
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: CrossEntropyWithSoftmax = 2.47682883 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0269s; samplesPerSecond = 7144.5
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: CrossEntropyWithSoftmax = 2.49591450 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.0269s; samplesPerSecond = 7128.5
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: CrossEntropyWithSoftmax = 2.48175146 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0269s; samplesPerSecond = 7150.3
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: CrossEntropyWithSoftmax = 2.47786850 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.0267s; samplesPerSecond = 7184.0
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: CrossEntropyWithSoftmax = 2.57285866 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0269s; samplesPerSecond = 7142.3
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: CrossEntropyWithSoftmax = 2.61151360 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0270s; samplesPerSecond = 7108.7
MPI Rank 0: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: CrossEntropyWithSoftmax = 2.47733105 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0269s; samplesPerSecond = 7146.3
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.13%]: CrossEntropyWithSoftmax = 2.48334402 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0268s; samplesPerSecond = 7163.6
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: CrossEntropyWithSoftmax = 2.39018807 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0269s; samplesPerSecond = 7145.2
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: CrossEntropyWithSoftmax = 2.27697327 * 192; EvalErrorPrediction = 0.56250000 * 192; time = 0.0268s; samplesPerSecond = 7175.7
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: CrossEntropyWithSoftmax = 2.48766249 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0269s; samplesPerSecond = 7148.7
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: CrossEntropyWithSoftmax = 2.56024809 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0269s; samplesPerSecond = 7149.8
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: CrossEntropyWithSoftmax = 2.37722995 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.0270s; samplesPerSecond = 7120.1
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: CrossEntropyWithSoftmax = 2.24144919 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0270s; samplesPerSecond = 7123.5
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: CrossEntropyWithSoftmax = 2.47716220 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0270s; samplesPerSecond = 7122.7
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.63%]: CrossEntropyWithSoftmax = 2.30606477 * 192; EvalErrorPrediction = 0.57812500 * 192; time = 0.0267s; samplesPerSecond = 7189.1
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: CrossEntropyWithSoftmax = 2.32237792 * 192; EvalErrorPrediction = 0.58854167 * 192; time = 0.0269s; samplesPerSecond = 7135.2
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: CrossEntropyWithSoftmax = 2.36995349 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0269s; samplesPerSecond = 7130.7
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: CrossEntropyWithSoftmax = 2.21978806 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0270s; samplesPerSecond = 7122.5
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: CrossEntropyWithSoftmax = 2.67073901 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0268s; samplesPerSecond = 7159.9
MPI Rank 0: 07/15/2016 00:56:14: Finished Epoch[ 1 of 5]: [Training] CrossEntropyWithSoftmax = 3.15272097 * 20480; EvalErrorPrediction = 0.75156250 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=2.9078s
MPI Rank 0: 07/15/2016 00:56:14: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.1'
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:14: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:14: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: CrossEntropyWithSoftmax = 2.35548833 * 542; EvalErrorPrediction = 0.61254613 * 542; time = 0.0705s; samplesPerSecond = 7688.3
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: CrossEntropyWithSoftmax = 2.24445426 * 531; EvalErrorPrediction = 0.61581921 * 531; time = 0.0695s; samplesPerSecond = 7643.0
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: CrossEntropyWithSoftmax = 2.22427766 * 553; EvalErrorPrediction = 0.59312839 * 553; time = 0.0589s; samplesPerSecond = 9386.4
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.04-seconds latency this time; accumulated time on sync point = 0.04 seconds , average latency = 0.04 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.32 seconds since last report (0.00 seconds on comm.); 4236 samples processed by 2 workers (2172 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 13.37k samplesPerSecond , throughputPerWorker = 6.69k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: CrossEntropyWithSoftmax = 2.32847105 * 546; EvalErrorPrediction = 0.61172161 * 546; time = 0.1136s; samplesPerSecond = 4806.8
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: CrossEntropyWithSoftmax = 2.34117475 * 521; EvalErrorPrediction = 0.62188100 * 521; time = 0.0603s; samplesPerSecond = 8639.4
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: CrossEntropyWithSoftmax = 2.26647968 * 545; EvalErrorPrediction = 0.59816514 * 545; time = 0.0598s; samplesPerSecond = 9107.5
MPI Rank 0: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: CrossEntropyWithSoftmax = 2.23777774 * 553; EvalErrorPrediction = 0.58951175 * 553; time = 0.0604s; samplesPerSecond = 9157.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.04 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.31 seconds since last report (0.01 seconds on comm.); 4285 samples processed by 2 workers (2182 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 13.74k samplesPerSecond , throughputPerWorker = 6.87k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: CrossEntropyWithSoftmax = 2.12008484 * 563; EvalErrorPrediction = 0.58614565 * 563; time = 0.1300s; samplesPerSecond = 4332.3
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: CrossEntropyWithSoftmax = 2.08161388 * 557; EvalErrorPrediction = 0.56552962 * 557; time = 0.0571s; samplesPerSecond = 9755.7
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: CrossEntropyWithSoftmax = 2.11472852 * 548; EvalErrorPrediction = 0.55109489 * 548; time = 0.0606s; samplesPerSecond = 9043.1
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: CrossEntropyWithSoftmax = 2.12574584 * 544; EvalErrorPrediction = 0.56066176 * 544; time = 0.0597s; samplesPerSecond = 9116.7
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: CrossEntropyWithSoftmax = 2.05134892 * 551; EvalErrorPrediction = 0.55898367 * 551; time = 0.0996s; samplesPerSecond = 5531.3
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: CrossEntropyWithSoftmax = 1.98926736 * 547; EvalErrorPrediction = 0.55393053 * 547; time = 0.0350s; samplesPerSecond = 15643.8
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: CrossEntropyWithSoftmax = 2.09841744 * 528; EvalErrorPrediction = 0.55681818 * 528; time = 0.0345s; samplesPerSecond = 15306.6
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: CrossEntropyWithSoftmax = 2.06160732 * 564; EvalErrorPrediction = 0.55673759 * 564; time = 0.0368s; samplesPerSecond = 15326.1
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: CrossEntropyWithSoftmax = 2.12085493 * 528; EvalErrorPrediction = 0.58712121 * 528; time = 0.0344s; samplesPerSecond = 15342.6
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: CrossEntropyWithSoftmax = 2.11531933 * 542; EvalErrorPrediction = 0.56642066 * 542; time = 0.0350s; samplesPerSecond = 15506.1
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: CrossEntropyWithSoftmax = 2.19043067 * 554; EvalErrorPrediction = 0.55956679 * 554; time = 0.0355s; samplesPerSecond = 15625.4
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: CrossEntropyWithSoftmax = 2.01855358 * 522; EvalErrorPrediction = 0.56321839 * 522; time = 0.0341s; samplesPerSecond = 15325.4
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: CrossEntropyWithSoftmax = 2.14715251 * 526; EvalErrorPrediction = 0.59885932 * 526; time = 0.0347s; samplesPerSecond = 15176.4
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: CrossEntropyWithSoftmax = 2.08932141 * 546; EvalErrorPrediction = 0.53296703 * 546; time = 0.0349s; samplesPerSecond = 15626.3
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: CrossEntropyWithSoftmax = 2.06225599 * 543; EvalErrorPrediction = 0.55064457 * 543; time = 0.0344s; samplesPerSecond = 15766.6
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: CrossEntropyWithSoftmax = 2.06771427 * 521; EvalErrorPrediction = 0.56238004 * 521; time = 0.0343s; samplesPerSecond = 15192.2
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: CrossEntropyWithSoftmax = 2.13534525 * 571; EvalErrorPrediction = 0.58143608 * 571; time = 0.0371s; samplesPerSecond = 15407.0
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: CrossEntropyWithSoftmax = 2.11079279 * 544; EvalErrorPrediction = 0.57169118 * 544; time = 0.0352s; samplesPerSecond = 15439.2
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: CrossEntropyWithSoftmax = 2.04717186 * 554; EvalErrorPrediction = 0.54873646 * 554; time = 0.0368s; samplesPerSecond = 15073.6
MPI Rank 0: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: CrossEntropyWithSoftmax = 2.12723160 * 380; EvalErrorPrediction = 0.55000000 * 380; time = 0.0251s; samplesPerSecond = 15112.9
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.08 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.81 seconds since last report (0.00 seconds on comm.); 11959 samples processed by 2 workers (10170 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 14.72k samplesPerSecond , throughputPerWorker = 7.36k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:15: Finished Epoch[ 2 of 5]: [Training] CrossEntropyWithSoftmax = 2.16612986 * 20480; EvalErrorPrediction = 0.57690430 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=1.44229s
MPI Rank 0: 07/15/2016 00:56:15: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.2'
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:16: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:16: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4268 samples processed by 2 workers (2127 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.80k samplesPerSecond , throughputPerWorker = 7.90k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:16:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.09040671 * 2127; EvalErrorPrediction = 0.56887635 * 2127; time = 0.2656s; samplesPerSecond = 8008.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.03 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.26 seconds since last report (0.01 seconds on comm.); 4329 samples processed by 2 workers (2188 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 16.50k samplesPerSecond , throughputPerWorker = 8.25k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:16:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.07714729 * 2188; EvalErrorPrediction = 0.57129799 * 2188; time = 0.2620s; samplesPerSecond = 8352.2
MPI Rank 0: 07/15/2016 00:56:16:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.01701641 * 2171; EvalErrorPrediction = 0.54629203 * 2171; time = 0.2464s; samplesPerSecond = 8810.6
MPI Rank 0: 07/15/2016 00:56:16:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.09836762 * 2137; EvalErrorPrediction = 0.56808610 * 2137; time = 0.1369s; samplesPerSecond = 15604.5
MPI Rank 0: 07/15/2016 00:56:17:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.03896225 * 2125; EvalErrorPrediction = 0.54964706 * 2125; time = 0.1374s; samplesPerSecond = 15464.0
MPI Rank 0: 07/15/2016 00:56:17:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.01529067 * 2107; EvalErrorPrediction = 0.54579972 * 2107; time = 0.1370s; samplesPerSecond = 15384.1
MPI Rank 0: 07/15/2016 00:56:17:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.00785889 * 1407; EvalErrorPrediction = 0.53589197 * 1407; time = 0.0913s; samplesPerSecond = 15409.9
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.02 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.76 seconds since last report (0.00 seconds on comm.); 11883 samples processed by 2 workers (9947 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.59k samplesPerSecond , throughputPerWorker = 7.79k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:17: Finished Epoch[ 3 of 5]: [Training] CrossEntropyWithSoftmax = 2.05996534 * 20480; EvalErrorPrediction = 0.55991211 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-005; epochTime=1.29594s
MPI Rank 0: 07/15/2016 00:56:17: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3'
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:17: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.01 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.26k samplesPerSecond , throughputPerWorker = 7.63k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:17:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17044095 * 2128; EvalErrorPrediction = 0.59210526 * 2128; time = 0.2832s; samplesPerSecond = 7515.3
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.27 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 16.03k samplesPerSecond , throughputPerWorker = 8.02k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:18:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.11513964 * 2090; EvalErrorPrediction = 0.55789474 * 2090; time = 0.2726s; samplesPerSecond = 7665.6
MPI Rank 0: 07/15/2016 00:56:18:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.03787655 * 2075; EvalErrorPrediction = 0.56000000 * 2075; time = 0.2404s; samplesPerSecond = 8631.7
MPI Rank 0: 07/15/2016 00:56:18:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 1.99981908 * 2100; EvalErrorPrediction = 0.55952381 * 2100; time = 0.1376s; samplesPerSecond = 15260.0
MPI Rank 0: 07/15/2016 00:56:18:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.00489528 * 2099; EvalErrorPrediction = 0.54168652 * 2099; time = 0.1368s; samplesPerSecond = 15340.5
MPI Rank 0: 07/15/2016 00:56:18:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.00840897 * 2126; EvalErrorPrediction = 0.55079962 * 2126; time = 0.1374s; samplesPerSecond = 15468.0
MPI Rank 0: 07/15/2016 00:56:18:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.04127081 * 1397; EvalErrorPrediction = 0.55046528 * 1397; time = 0.0909s; samplesPerSecond = 15360.8
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.07 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.76 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.47k samplesPerSecond , throughputPerWorker = 7.73k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:18: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.06081675 * 20480; EvalErrorPrediction = 0.56269531 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-005; epochTime=1.31909s
MPI Rank 0: 07/15/2016 00:56:18: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:18: learnRatePerSample reduced to 4.8828126e-005
MPI Rank 0: 07/15/2016 00:56:18: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:19: Starting Epoch 4: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:19: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.28 seconds since last report (0.02 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.62k samplesPerSecond , throughputPerWorker = 7.81k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:19:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17102542 * 2128; EvalErrorPrediction = 0.59210526 * 2128; time = 0.2767s; samplesPerSecond = 7690.0
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.27 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 16.01k samplesPerSecond , throughputPerWorker = 8.01k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:19:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.11760208 * 2090; EvalErrorPrediction = 0.55837321 * 2090; time = 0.2730s; samplesPerSecond = 7656.6
MPI Rank 0: 07/15/2016 00:56:19:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04316028 * 2075; EvalErrorPrediction = 0.56000000 * 2075; time = 0.2403s; samplesPerSecond = 8633.4
MPI Rank 0: 07/15/2016 00:56:20:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.00646850 * 2100; EvalErrorPrediction = 0.56285714 * 2100; time = 0.1386s; samplesPerSecond = 15154.4
MPI Rank 0: 07/15/2016 00:56:20:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.01124014 * 2099; EvalErrorPrediction = 0.54692711 * 2099; time = 0.1371s; samplesPerSecond = 15314.9
MPI Rank 0: 07/15/2016 00:56:20:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.01725803 * 2126; EvalErrorPrediction = 0.55409219 * 2126; time = 0.1378s; samplesPerSecond = 15426.1
MPI Rank 0: 07/15/2016 00:56:20:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.05077405 * 1397; EvalErrorPrediction = 0.55332856 * 1397; time = 0.0915s; samplesPerSecond = 15275.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.76 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.44k samplesPerSecond , throughputPerWorker = 7.72k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:20: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.06545214 * 20480; EvalErrorPrediction = 0.56401367 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 4.8828126e-005; epochTime=1.31841s
MPI Rank 0: 07/15/2016 00:56:20: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:20: learnRatePerSample reduced to 2.4414063e-005
MPI Rank 0: 07/15/2016 00:56:20: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:20: Starting Epoch 4: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:20: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.02 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.36k samplesPerSecond , throughputPerWorker = 7.68k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:21:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17132344 * 2128; EvalErrorPrediction = 0.59257519 * 2128; time = 0.2811s; samplesPerSecond = 7570.7
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.27 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 16.08k samplesPerSecond , throughputPerWorker = 8.04k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:21:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.11892646 * 2090; EvalErrorPrediction = 0.55885167 * 2090; time = 0.2718s; samplesPerSecond = 7689.1
MPI Rank 0: 07/15/2016 00:56:21:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04601117 * 2075; EvalErrorPrediction = 0.56048193 * 2075; time = 0.2433s; samplesPerSecond = 8527.2
MPI Rank 0: 07/15/2016 00:56:21:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01052228 * 2100; EvalErrorPrediction = 0.56238095 * 2100; time = 0.1401s; samplesPerSecond = 14994.1
MPI Rank 0: 07/15/2016 00:56:21:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.01551944 * 2099; EvalErrorPrediction = 0.54978561 * 2099; time = 0.1389s; samplesPerSecond = 15113.7
MPI Rank 0: 07/15/2016 00:56:21:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.02302077 * 2126; EvalErrorPrediction = 0.55409219 * 2126; time = 0.1396s; samplesPerSecond = 15230.1
MPI Rank 0: 07/15/2016 00:56:22:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.05705948 * 1397; EvalErrorPrediction = 0.55905512 * 1397; time = 0.0925s; samplesPerSecond = 15098.3
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.25k samplesPerSecond , throughputPerWorker = 7.63k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:22: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.06826797 * 20480; EvalErrorPrediction = 0.56489258 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 2.4414063e-005; epochTime=1.32744s
MPI Rank 0: 07/15/2016 00:56:22: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:22: learnRatePerSample reduced to 1.2207031e-005
MPI Rank 0: 07/15/2016 00:56:22: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:22: Starting Epoch 4: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:22: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.02 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.15k samplesPerSecond , throughputPerWorker = 7.58k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:22:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17147393 * 2128; EvalErrorPrediction = 0.59351504 * 2128; time = 0.2855s; samplesPerSecond = 7453.0
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 15.73k samplesPerSecond , throughputPerWorker = 7.86k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:22:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.11961508 * 2090; EvalErrorPrediction = 0.55885167 * 2090; time = 0.2776s; samplesPerSecond = 7527.6
MPI Rank 0: 07/15/2016 00:56:23:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04749854 * 2075; EvalErrorPrediction = 0.56048193 * 2075; time = 0.2434s; samplesPerSecond = 8526.0
MPI Rank 0: 07/15/2016 00:56:23:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01276995 * 2100; EvalErrorPrediction = 0.56190476 * 2100; time = 0.1405s; samplesPerSecond = 14948.9
MPI Rank 0: 07/15/2016 00:56:23:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.01807578 * 2099; EvalErrorPrediction = 0.55169128 * 2099; time = 0.1387s; samplesPerSecond = 15135.0
MPI Rank 0: 07/15/2016 00:56:23:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.02655777 * 2126; EvalErrorPrediction = 0.55691439 * 2126; time = 0.1395s; samplesPerSecond = 15240.6
MPI Rank 0: 07/15/2016 00:56:23:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.06101791 * 1397; EvalErrorPrediction = 0.56120258 * 1397; time = 0.0925s; samplesPerSecond = 15110.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.24k samplesPerSecond , throughputPerWorker = 7.62k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:23: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.06988452 * 20480; EvalErrorPrediction = 0.56557617 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 1.2207031e-005; epochTime=1.33834s
MPI Rank 0: 07/15/2016 00:56:23: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:23: learnRatePerSample reduced to 6.1035157e-006
MPI Rank 0: 07/15/2016 00:56:23: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:23: Starting Epoch 4: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:23: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.02 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.15k samplesPerSecond , throughputPerWorker = 7.58k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:24:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17154954 * 2128; EvalErrorPrediction = 0.59351504 * 2128; time = 0.2854s; samplesPerSecond = 7456.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 15.83k samplesPerSecond , throughputPerWorker = 7.91k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:24:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.11996645 * 2090; EvalErrorPrediction = 0.55885167 * 2090; time = 0.2761s; samplesPerSecond = 7569.9
MPI Rank 0: 07/15/2016 00:56:24:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04825960 * 2075; EvalErrorPrediction = 0.56096386 * 2075; time = 0.2427s; samplesPerSecond = 8548.1
MPI Rank 0: 07/15/2016 00:56:24:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01395525 * 2100; EvalErrorPrediction = 0.56238095 * 2100; time = 0.1404s; samplesPerSecond = 14956.5
MPI Rank 0: 07/15/2016 00:56:24:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.01948082 * 2099; EvalErrorPrediction = 0.55216770 * 2099; time = 0.1388s; samplesPerSecond = 15121.5
MPI Rank 0: 07/15/2016 00:56:25:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.02855498 * 2126; EvalErrorPrediction = 0.55785513 * 2126; time = 0.1393s; samplesPerSecond = 15258.4
MPI Rank 0: 07/15/2016 00:56:25:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.06330822 * 1397; EvalErrorPrediction = 0.56335004 * 1397; time = 0.0925s; samplesPerSecond = 15098.6
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.01 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.23k samplesPerSecond , throughputPerWorker = 7.62k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:25: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07076247 * 20480; EvalErrorPrediction = 0.56601563 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 6.1035157e-006; epochTime=1.33668s
MPI Rank 0: 07/15/2016 00:56:25: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:25: learnRatePerSample reduced to 3.0517579e-006
MPI Rank 0: 07/15/2016 00:56:25: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:25: Starting Epoch 4: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:25: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.02 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.08k samplesPerSecond , throughputPerWorker = 7.54k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:25:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17158744 * 2128; EvalErrorPrediction = 0.59351504 * 2128; time = 0.2866s; samplesPerSecond = 7424.7
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 15.82k samplesPerSecond , throughputPerWorker = 7.91k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:26:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.12014395 * 2090; EvalErrorPrediction = 0.55885167 * 2090; time = 0.2762s; samplesPerSecond = 7566.6
MPI Rank 0: 07/15/2016 00:56:26:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04864476 * 2075; EvalErrorPrediction = 0.56048193 * 2075; time = 0.2434s; samplesPerSecond = 8526.4
MPI Rank 0: 07/15/2016 00:56:26:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01456421 * 2100; EvalErrorPrediction = 0.56190476 * 2100; time = 0.1402s; samplesPerSecond = 14973.5
MPI Rank 0: 07/15/2016 00:56:26:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.02021835 * 2099; EvalErrorPrediction = 0.55216770 * 2099; time = 0.1387s; samplesPerSecond = 15137.1
MPI Rank 0: 07/15/2016 00:56:26:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.02962087 * 2126; EvalErrorPrediction = 0.55879586 * 2126; time = 0.1394s; samplesPerSecond = 15246.5
MPI Rank 0: 07/15/2016 00:56:26:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.06454934 * 1397; EvalErrorPrediction = 0.56335004 * 1397; time = 0.0925s; samplesPerSecond = 15105.6
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.26k samplesPerSecond , throughputPerWorker = 7.63k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:26: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07122168 * 20480; EvalErrorPrediction = 0.56601563 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 3.0517579e-006; epochTime=1.33724s
MPI Rank 0: 07/15/2016 00:56:26: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:26: learnRatePerSample reduced to 1.5258789e-006
MPI Rank 0: 07/15/2016 00:56:26: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:27: Starting Epoch 4: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:27: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.02 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.39k samplesPerSecond , throughputPerWorker = 7.69k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:27:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17160642 * 2128; EvalErrorPrediction = 0.59351504 * 2128; time = 0.2809s; samplesPerSecond = 7575.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 15.72k samplesPerSecond , throughputPerWorker = 7.86k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:27:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.12023316 * 2090; EvalErrorPrediction = 0.55933014 * 2090; time = 0.2780s; samplesPerSecond = 7519.1
MPI Rank 0: 07/15/2016 00:56:27:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04883853 * 2075; EvalErrorPrediction = 0.56048193 * 2075; time = 0.2435s; samplesPerSecond = 8521.5
MPI Rank 0: 07/15/2016 00:56:28:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01487289 * 2100; EvalErrorPrediction = 0.56142857 * 2100; time = 0.1405s; samplesPerSecond = 14951.6
MPI Rank 0: 07/15/2016 00:56:28:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.02059632 * 2099; EvalErrorPrediction = 0.55312053 * 2099; time = 0.1388s; samplesPerSecond = 15119.4
MPI Rank 0: 07/15/2016 00:56:28:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.03017205 * 2126; EvalErrorPrediction = 0.55926623 * 2126; time = 0.1398s; samplesPerSecond = 15206.9
MPI Rank 0: 07/15/2016 00:56:28:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.06519652 * 1397; EvalErrorPrediction = 0.56478168 * 1397; time = 0.0925s; samplesPerSecond = 15102.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.24k samplesPerSecond , throughputPerWorker = 7.62k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:28: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07145673 * 20480; EvalErrorPrediction = 0.56625977 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 1.5258789e-006; epochTime=1.33346s
MPI Rank 0: 07/15/2016 00:56:28: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:28: learnRatePerSample reduced to 7.6293946e-007
MPI Rank 0: 07/15/2016 00:56:28: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:28: Starting Epoch 4: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:28: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.02 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.14k samplesPerSecond , throughputPerWorker = 7.57k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:28:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17161591 * 2128; EvalErrorPrediction = 0.59351504 * 2128; time = 0.2855s; samplesPerSecond = 7454.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 15.60k samplesPerSecond , throughputPerWorker = 7.80k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:29:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.12027789 * 2090; EvalErrorPrediction = 0.55933014 * 2090; time = 0.2801s; samplesPerSecond = 7461.1
MPI Rank 0: 07/15/2016 00:56:29:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04893572 * 2075; EvalErrorPrediction = 0.56048193 * 2075; time = 0.2426s; samplesPerSecond = 8554.2
MPI Rank 0: 07/15/2016 00:56:29:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01502830 * 2100; EvalErrorPrediction = 0.56142857 * 2100; time = 0.1406s; samplesPerSecond = 14935.0
MPI Rank 0: 07/15/2016 00:56:29:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.02078766 * 2099; EvalErrorPrediction = 0.55312053 * 2099; time = 0.1387s; samplesPerSecond = 15133.2
MPI Rank 0: 07/15/2016 00:56:29:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.03045238 * 2126; EvalErrorPrediction = 0.56020696 * 2126; time = 0.1397s; samplesPerSecond = 15219.5
MPI Rank 0: 07/15/2016 00:56:29:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.06552712 * 1397; EvalErrorPrediction = 0.56549749 * 1397; time = 0.0925s; samplesPerSecond = 15106.0
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.20 seconds , average latency = 0.07 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.26k samplesPerSecond , throughputPerWorker = 7.63k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:29: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07157567 * 20480; EvalErrorPrediction = 0.56640625 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 7.6293946e-007; epochTime=1.33933s
MPI Rank 0: 07/15/2016 00:56:29: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:30: learnRatePerSample reduced to 3.8146973e-007
MPI Rank 0: 07/15/2016 00:56:30: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:30: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:30: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.02 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.14k samplesPerSecond , throughputPerWorker = 7.57k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:30:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17162066 * 2128; EvalErrorPrediction = 0.59351504 * 2128; time = 0.2854s; samplesPerSecond = 7455.7
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 15.79k samplesPerSecond , throughputPerWorker = 7.90k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:30:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.12030028 * 2090; EvalErrorPrediction = 0.55933014 * 2090; time = 0.2767s; samplesPerSecond = 7552.3
MPI Rank 0: 07/15/2016 00:56:31:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04898440 * 2075; EvalErrorPrediction = 0.56048193 * 2075; time = 0.2438s; samplesPerSecond = 8511.7
MPI Rank 0: 07/15/2016 00:56:31:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01510627 * 2100; EvalErrorPrediction = 0.56142857 * 2100; time = 0.1406s; samplesPerSecond = 14941.0
MPI Rank 0: 07/15/2016 00:56:31:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.02088392 * 2099; EvalErrorPrediction = 0.55359695 * 2099; time = 0.1388s; samplesPerSecond = 15122.4
MPI Rank 0: 07/15/2016 00:56:31:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.03059376 * 2126; EvalErrorPrediction = 0.56020696 * 2126; time = 0.1396s; samplesPerSecond = 15234.1
MPI Rank 0: 07/15/2016 00:56:31:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.06569421 * 1397; EvalErrorPrediction = 0.56621331 * 1397; time = 0.0925s; samplesPerSecond = 15098.1
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.24k samplesPerSecond , throughputPerWorker = 7.62k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:31: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07163550 * 20480; EvalErrorPrediction = 0.56650391 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 3.8146973e-007; epochTime=1.33729s
MPI Rank 0: 07/15/2016 00:56:31: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:31: learnRatePerSample reduced to 1.9073487e-007
MPI Rank 0: 07/15/2016 00:56:31: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:31: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:31: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.02 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.17k samplesPerSecond , throughputPerWorker = 7.59k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:32:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17162303 * 2128; EvalErrorPrediction = 0.59351504 * 2128; time = 0.2850s; samplesPerSecond = 7465.6
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 15.74k samplesPerSecond , throughputPerWorker = 7.87k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:32:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.12031148 * 2090; EvalErrorPrediction = 0.55933014 * 2090; time = 0.2777s; samplesPerSecond = 7526.0
MPI Rank 0: 07/15/2016 00:56:32:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04900875 * 2075; EvalErrorPrediction = 0.56048193 * 2075; time = 0.2428s; samplesPerSecond = 8546.3
MPI Rank 0: 07/15/2016 00:56:32:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01514533 * 2100; EvalErrorPrediction = 0.56095238 * 2100; time = 0.1402s; samplesPerSecond = 14975.4
MPI Rank 0: 07/15/2016 00:56:32:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.02093221 * 2099; EvalErrorPrediction = 0.55359695 * 2099; time = 0.1386s; samplesPerSecond = 15141.6
MPI Rank 0: 07/15/2016 00:56:33:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.03066475 * 2126; EvalErrorPrediction = 0.55973659 * 2126; time = 0.1394s; samplesPerSecond = 15254.1
MPI Rank 0: 07/15/2016 00:56:33:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.06577821 * 1397; EvalErrorPrediction = 0.56692913 * 1397; time = 0.0922s; samplesPerSecond = 15159.1
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.28k samplesPerSecond , throughputPerWorker = 7.64k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:33: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07166550 * 20480; EvalErrorPrediction = 0.56645508 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 1.9073487e-007; epochTime=1.33558s
MPI Rank 0: 07/15/2016 00:56:33: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:33: learnRatePerSample reduced to 9.5367433e-008
MPI Rank 0: 07/15/2016 00:56:33: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:33: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:33: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.05-seconds latency this time; accumulated time on sync point = 0.05 seconds , average latency = 0.05 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.26 seconds since last report (0.02 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 17.09k samplesPerSecond , throughputPerWorker = 8.54k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:33:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17162422 * 2128; EvalErrorPrediction = 0.59351504 * 2128; time = 0.2519s; samplesPerSecond = 8446.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.07 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 15.73k samplesPerSecond , throughputPerWorker = 7.87k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:34:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.12031708 * 2090; EvalErrorPrediction = 0.55933014 * 2090; time = 0.2778s; samplesPerSecond = 7523.9
MPI Rank 0: 07/15/2016 00:56:34:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04902094 * 2075; EvalErrorPrediction = 0.56048193 * 2075; time = 0.2445s; samplesPerSecond = 8486.4
MPI Rank 0: 07/15/2016 00:56:34:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01516487 * 2100; EvalErrorPrediction = 0.56095238 * 2100; time = 0.1403s; samplesPerSecond = 14969.8
MPI Rank 0: 07/15/2016 00:56:34:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.02095639 * 2099; EvalErrorPrediction = 0.55312053 * 2099; time = 0.1391s; samplesPerSecond = 15091.1
MPI Rank 0: 07/15/2016 00:56:34:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.03070033 * 2126; EvalErrorPrediction = 0.55973659 * 2126; time = 0.1394s; samplesPerSecond = 15246.5
MPI Rank 0: 07/15/2016 00:56:34:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.06582033 * 1397; EvalErrorPrediction = 0.56692913 * 1397; time = 0.0922s; samplesPerSecond = 15146.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.15 seconds , average latency = 0.05 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.24k samplesPerSecond , throughputPerWorker = 7.62k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:34: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07168053 * 20480; EvalErrorPrediction = 0.56635742 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.5367433e-008; epochTime=1.33576s
MPI Rank 0: 07/15/2016 00:56:34: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:34: learnRatePerSample reduced to 4.7683717e-008
MPI Rank 0: 07/15/2016 00:56:34: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:35: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.02 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.13k samplesPerSecond , throughputPerWorker = 7.57k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:35:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17162481 * 2128; EvalErrorPrediction = 0.59351504 * 2128; time = 0.2857s; samplesPerSecond = 7447.5
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 15.88k samplesPerSecond , throughputPerWorker = 7.94k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:35:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.12031988 * 2090; EvalErrorPrediction = 0.55933014 * 2090; time = 0.2751s; samplesPerSecond = 7597.1
MPI Rank 0: 07/15/2016 00:56:35:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04902703 * 2075; EvalErrorPrediction = 0.56048193 * 2075; time = 0.2447s; samplesPerSecond = 8479.9
MPI Rank 0: 07/15/2016 00:56:36:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01517465 * 2100; EvalErrorPrediction = 0.56095238 * 2100; time = 0.1402s; samplesPerSecond = 14977.4
MPI Rank 0: 07/15/2016 00:56:36:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.02096849 * 2099; EvalErrorPrediction = 0.55312053 * 2099; time = 0.1395s; samplesPerSecond = 15048.4
MPI Rank 0: 07/15/2016 00:56:36:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.03071813 * 2126; EvalErrorPrediction = 0.55973659 * 2126; time = 0.1395s; samplesPerSecond = 15236.4
MPI Rank 0: 07/15/2016 00:56:36:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.06584142 * 1397; EvalErrorPrediction = 0.56692913 * 1397; time = 0.0923s; samplesPerSecond = 15141.5
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.22k samplesPerSecond , throughputPerWorker = 7.61k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:36: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07168805 * 20480; EvalErrorPrediction = 0.56635742 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 4.7683717e-008; epochTime=1.33643s
MPI Rank 0: 07/15/2016 00:56:36: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:36: learnRatePerSample reduced to 2.3841858e-008
MPI Rank 0: 07/15/2016 00:56:36: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:36: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:36: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.02 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.35k samplesPerSecond , throughputPerWorker = 7.68k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:36:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17162511 * 2128; EvalErrorPrediction = 0.59351504 * 2128; time = 0.2815s; samplesPerSecond = 7558.9
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 15.82k samplesPerSecond , throughputPerWorker = 7.91k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:37:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.12032129 * 2090; EvalErrorPrediction = 0.55933014 * 2090; time = 0.2764s; samplesPerSecond = 7562.3
MPI Rank 0: 07/15/2016 00:56:37:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04903008 * 2075; EvalErrorPrediction = 0.56048193 * 2075; time = 0.2436s; samplesPerSecond = 8518.4
MPI Rank 0: 07/15/2016 00:56:37:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01517953 * 2100; EvalErrorPrediction = 0.56095238 * 2100; time = 0.1405s; samplesPerSecond = 14946.7
MPI Rank 0: 07/15/2016 00:56:37:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.02097454 * 2099; EvalErrorPrediction = 0.55312053 * 2099; time = 0.1388s; samplesPerSecond = 15121.0
MPI Rank 0: 07/15/2016 00:56:37:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.03072704 * 2126; EvalErrorPrediction = 0.55973659 * 2126; time = 0.1398s; samplesPerSecond = 15210.8
MPI Rank 0: 07/15/2016 00:56:37:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.06585197 * 1397; EvalErrorPrediction = 0.56692913 * 1397; time = 0.0925s; samplesPerSecond = 15100.4
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.24k samplesPerSecond , throughputPerWorker = 7.62k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:37: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07169181 * 20480; EvalErrorPrediction = 0.56635742 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 2.3841858e-008; epochTime=1.33283s
MPI Rank 0: 07/15/2016 00:56:37: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:38: learnRatePerSample reduced to 1.1920929e-008
MPI Rank 0: 07/15/2016 00:56:38: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:38: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:38: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.02 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.35k samplesPerSecond , throughputPerWorker = 7.68k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:38:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17162526 * 2128; EvalErrorPrediction = 0.59351504 * 2128; time = 0.2815s; samplesPerSecond = 7559.7
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 15.70k samplesPerSecond , throughputPerWorker = 7.85k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:38:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.12032199 * 2090; EvalErrorPrediction = 0.55933014 * 2090; time = 0.2783s; samplesPerSecond = 7509.2
MPI Rank 0: 07/15/2016 00:56:39:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04903160 * 2075; EvalErrorPrediction = 0.56048193 * 2075; time = 0.2430s; samplesPerSecond = 8539.0
MPI Rank 0: 07/15/2016 00:56:39:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01518198 * 2100; EvalErrorPrediction = 0.56095238 * 2100; time = 0.1406s; samplesPerSecond = 14930.8
MPI Rank 0: 07/15/2016 00:56:39:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.02097757 * 2099; EvalErrorPrediction = 0.55312053 * 2099; time = 0.1392s; samplesPerSecond = 15083.8
MPI Rank 0: 07/15/2016 00:56:39:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.03073150 * 2126; EvalErrorPrediction = 0.55973659 * 2126; time = 0.1395s; samplesPerSecond = 15243.1
MPI Rank 0: 07/15/2016 00:56:39:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.06585724 * 1397; EvalErrorPrediction = 0.56692913 * 1397; time = 0.0925s; samplesPerSecond = 15110.1
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.25k samplesPerSecond , throughputPerWorker = 7.62k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:39: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07169369 * 20480; EvalErrorPrediction = 0.56635742 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 1.1920929e-008; epochTime=1.33461s
MPI Rank 0: 07/15/2016 00:56:39: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:39: learnRatePerSample reduced to 5.9604646e-009
MPI Rank 0: 07/15/2016 00:56:39: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:39: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:39: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.03 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.13k samplesPerSecond , throughputPerWorker = 7.57k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:40:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17162533 * 2128; EvalErrorPrediction = 0.59351504 * 2128; time = 0.2857s; samplesPerSecond = 7448.1
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 15.68k samplesPerSecond , throughputPerWorker = 7.84k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:40:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.12032234 * 2090; EvalErrorPrediction = 0.55933014 * 2090; time = 0.2787s; samplesPerSecond = 7499.9
MPI Rank 0: 07/15/2016 00:56:40:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04903236 * 2075; EvalErrorPrediction = 0.56048193 * 2075; time = 0.2421s; samplesPerSecond = 8570.7
MPI Rank 0: 07/15/2016 00:56:40:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01518320 * 2100; EvalErrorPrediction = 0.56095238 * 2100; time = 0.1406s; samplesPerSecond = 14935.6
MPI Rank 0: 07/15/2016 00:56:40:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.02097908 * 2099; EvalErrorPrediction = 0.55312053 * 2099; time = 0.1387s; samplesPerSecond = 15131.6
MPI Rank 0: 07/15/2016 00:56:41:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.03073372 * 2126; EvalErrorPrediction = 0.55973659 * 2126; time = 0.1397s; samplesPerSecond = 15215.8
MPI Rank 0: 07/15/2016 00:56:41:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.06585988 * 1397; EvalErrorPrediction = 0.56692913 * 1397; time = 0.0922s; samplesPerSecond = 15149.1
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.28k samplesPerSecond , throughputPerWorker = 7.64k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:41: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07169463 * 20480; EvalErrorPrediction = 0.56635742 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 5.9604646e-009; epochTime=1.33669s
MPI Rank 0: 07/15/2016 00:56:41: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:41: learnRatePerSample reduced to 2.9802323e-009
MPI Rank 0: 07/15/2016 00:56:41: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:41: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:41: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.09 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.02 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.37k samplesPerSecond , throughputPerWorker = 7.68k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:41:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17162537 * 2128; EvalErrorPrediction = 0.59351504 * 2128; time = 0.2813s; samplesPerSecond = 7564.2
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.09 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 15.76k samplesPerSecond , throughputPerWorker = 7.88k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:41:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.12032251 * 2090; EvalErrorPrediction = 0.55933014 * 2090; time = 0.2772s; samplesPerSecond = 7538.4
MPI Rank 0: 07/15/2016 00:56:42:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04903274 * 2075; EvalErrorPrediction = 0.56048193 * 2075; time = 0.2426s; samplesPerSecond = 8553.0
MPI Rank 0: 07/15/2016 00:56:42:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01518381 * 2100; EvalErrorPrediction = 0.56095238 * 2100; time = 0.1402s; samplesPerSecond = 14979.0
MPI Rank 0: 07/15/2016 00:56:42:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.02097984 * 2099; EvalErrorPrediction = 0.55312053 * 2099; time = 0.1390s; samplesPerSecond = 15102.2
MPI Rank 0: 07/15/2016 00:56:42:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.03073484 * 2126; EvalErrorPrediction = 0.55973659 * 2126; time = 0.1391s; samplesPerSecond = 15285.7
MPI Rank 0: 07/15/2016 00:56:42:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.06586120 * 1397; EvalErrorPrediction = 0.56692913 * 1397; time = 0.0925s; samplesPerSecond = 15102.7
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.18 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.28k samplesPerSecond , throughputPerWorker = 7.64k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:42: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07169510 * 20480; EvalErrorPrediction = 0.56635742 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 2.9802323e-009; epochTime=1.33151s
MPI Rank 0: 07/15/2016 00:56:42: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:42: learnRatePerSample reduced to 1.4901161e-009
MPI Rank 0: 07/15/2016 00:56:42: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:42: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 0: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 0: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 0 of 2, with 1 datapasses
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:42: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 0: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.10-seconds latency this time; accumulated time on sync point = 0.10 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.02 seconds on comm.); 4392 samples processed by 2 workers (2128 by me);
MPI Rank 0: 		(model aggregation stats) 1-th sync: totalThroughput = 15.18k samplesPerSecond , throughputPerWorker = 7.59k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:43:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.17162539 * 2128; EvalErrorPrediction = 0.59351504 * 2128; time = 0.2848s; samplesPerSecond = 7472.4
MPI Rank 0: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.09-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.10 seconds
MPI Rank 0: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.02 seconds on comm.); 4376 samples processed by 2 workers (2090 by me);
MPI Rank 0: 		(model aggregation stats) 2-th sync: totalThroughput = 15.83k samplesPerSecond , throughputPerWorker = 7.91k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:43:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.12032260 * 2090; EvalErrorPrediction = 0.55933014 * 2090; time = 0.2762s; samplesPerSecond = 7567.7
MPI Rank 0: 07/15/2016 00:56:43:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.04903293 * 2075; EvalErrorPrediction = 0.56048193 * 2075; time = 0.2448s; samplesPerSecond = 8475.6
MPI Rank 0: 07/15/2016 00:56:43:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01518412 * 2100; EvalErrorPrediction = 0.56095238 * 2100; time = 0.1402s; samplesPerSecond = 14977.9
MPI Rank 0: 07/15/2016 00:56:44:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.02098021 * 2099; EvalErrorPrediction = 0.55312053 * 2099; time = 0.1388s; samplesPerSecond = 15127.4
MPI Rank 0: 07/15/2016 00:56:44:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.03073539 * 2126; EvalErrorPrediction = 0.55973659 * 2126; time = 0.1398s; samplesPerSecond = 15212.8
MPI Rank 0: 07/15/2016 00:56:44:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.06586186 * 1397; EvalErrorPrediction = 0.56692913 * 1397; time = 0.0922s; samplesPerSecond = 15148.1
MPI Rank 0: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.19 seconds , average latency = 0.06 seconds
MPI Rank 0: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.00 seconds on comm.); 11712 samples processed by 2 workers (9797 by me);
MPI Rank 0: 		(model aggregation stats) 3-th sync: totalThroughput = 15.23k samplesPerSecond , throughputPerWorker = 7.61k samplesPerSecond
MPI Rank 0: 07/15/2016 00:56:44: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07169534 * 20480; EvalErrorPrediction = 0.56635742 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 1.4901161e-009; epochTime=1.33595s
MPI Rank 0: 07/15/2016 00:56:44: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 0: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:44: learnRatePerSample reduced to 7.4505807e-010
MPI Rank 0: 07/15/2016 00:56:44: SGD: revoke back to and update checkpoint file for epoch 3
MPI Rank 0: 07/15/2016 00:56:44: Learn Rate Per Sample for Epoch[4] = 7.4505807e-010 is less than minLearnRate 9.9999997e-010. Training complete.
MPI Rank 0: 07/15/2016 00:56:44: CNTKCommandTrainEnd: speechTrain
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:44: Action "train" complete.
MPI Rank 0: 
MPI Rank 0: 07/15/2016 00:56:44: __COMPLETED__
MPI Rank 0: ~MPIWrapper
MPI Rank 1: 07/15/2016 00:56:08: Redirecting stderr to file C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/stderr_speechTrain.logrank1
MPI Rank 1: 07/15/2016 00:56:08: -------------------------------------------------------------------
MPI Rank 1: 07/15/2016 00:56:08: Build info: 
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:08: 		Built time: Jul 15 2016 00:48:16
MPI Rank 1: 07/15/2016 00:56:08: 		Last modified date: Fri Jul  8 02:53:05 2016
MPI Rank 1: 07/15/2016 00:56:08: 		Build type: Release
MPI Rank 1: 07/15/2016 00:56:08: 		Build target: GPU
MPI Rank 1: 07/15/2016 00:56:08: 		With 1bit-SGD: no
MPI Rank 1: 07/15/2016 00:56:08: 		Math lib: mkl
MPI Rank 1: 07/15/2016 00:56:08: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
MPI Rank 1: 07/15/2016 00:56:08: 		CUB_PATH: c:\src\cub-1.4.1
MPI Rank 1: 07/15/2016 00:56:08: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
MPI Rank 1: 07/15/2016 00:56:08: 		Build Branch: HEAD
MPI Rank 1: 07/15/2016 00:56:08: 		Build SHA1: 500f0ccaa040821405404d7879c0e823003f1544
MPI Rank 1: 07/15/2016 00:56:08: 		Built by svcphil on Philly-Pool1
MPI Rank 1: 07/15/2016 00:56:08: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
MPI Rank 1: 07/15/2016 00:56:08: -------------------------------------------------------------------
MPI Rank 1: 07/15/2016 00:56:08: -------------------------------------------------------------------
MPI Rank 1: 07/15/2016 00:56:08: GPU info:
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:08: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8090 MB
MPI Rank 1: 07/15/2016 00:56:08: -------------------------------------------------------------------
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:08: Running on cntk-muc00 at 2016/07/15 00:56:08
MPI Rank 1: 07/15/2016 00:56:08: Command line: 
MPI Rank 1: C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN/ParallelBM/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu  DeviceId=0  timestamping=true  numCPUThreads=2  precision=double  speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]  stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:08: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 07/15/2016 00:56:08: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = $DeviceId$
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "$RunDir$/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = $DeviceId$
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "$DataDir$/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "$DataDir$/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 1: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu
MPI Rank 1: DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 1: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN
MPI Rank 1: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=2
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:08: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:08: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: 07/15/2016 00:56:08: precision = "float"
MPI Rank 1: command = speechTrain
MPI Rank 1: deviceId = 0
MPI Rank 1: parallelTrain = true
MPI Rank 1: speechTrain = [
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = 0
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ]
MPI Rank 1: currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 1: RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu
MPI Rank 1: DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 1: ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN
MPI Rank 1: OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu
MPI Rank 1: DeviceId=0
MPI Rank 1: timestamping=true
MPI Rank 1: numCPUThreads=2
MPI Rank 1: precision=double
MPI Rank 1: speechTrain=[SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/stderr
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:08: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:08: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
MPI Rank 1: configparameters: cntk.cntk:command=speechTrain
MPI Rank 1: configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\DNN
MPI Rank 1: configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 1: configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
MPI Rank 1: configparameters: cntk.cntk:deviceId=0
MPI Rank 1: configparameters: cntk.cntk:numCPUThreads=2
MPI Rank 1: configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu
MPI Rank 1: configparameters: cntk.cntk:parallelTrain=true
MPI Rank 1: configparameters: cntk.cntk:precision=double
MPI Rank 1: configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu
MPI Rank 1: configparameters: cntk.cntk:speechTrain=[
MPI Rank 1:     action = "train"
MPI Rank 1:     modelPath = "C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn"
MPI Rank 1:     deviceId = 0
MPI Rank 1:     traceLevel = 1
MPI Rank 1:     SimpleNetworkBuilder = [
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = "CrossEntropyWithSoftmax"
MPI Rank 1:         evalCriterion = "ErrorPrediction"
MPI Rank 1:         layerTypes = "Sigmoid"
MPI Rank 1:         initValueScale = 1.0
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         uniformInit = true
MPI Rank 1:         needPrior = true
MPI Rank 1:     ]
MPI Rank 1:     ExperimentalNetworkBuilder = [    // the same as above but with BS. Not active; activate by commenting out the SimpleNetworkBuilder entry above
MPI Rank 1:         layerSizes = 363:512:512:132
MPI Rank 1:         trainingCriterion = 'CE'
MPI Rank 1:         evalCriterion = 'Err'
MPI Rank 1:         applyMeanVarNorm = true
MPI Rank 1:         L = Length(layerSizes)-1    // number of model layers
MPI Rank 1:         features = Input(layerSizes[0], 1, tag='feature') ; labels = Input(layerSizes[Length(layerSizes)-1], 1, tag='label')
MPI Rank 1:         featNorm = if applyMeanVarNorm
MPI Rank 1:                    then MeanVarNorm(features)
MPI Rank 1:                    else features
MPI Rank 1:         layers[layer:1..L-1] = if layer > 1
MPI Rank 1:                                then SBFF(layers[layer-1].Eh, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:                                else SBFF(featNorm, layerSizes[layer], layerSizes[layer-1])
MPI Rank 1:         outLayer = BFF(layers[L-1].Eh, layerSizes[L], layerSizes[L-1])
MPI Rank 1:         outZ = outLayer.z        // + PastValue(layerSizes[L], 1, outLayer.z)
MPI Rank 1:         CE = if trainingCriterion == 'CE'
MPI Rank 1:              then CrossEntropyWithSoftmax(labels, outZ, tag='criterion')
MPI Rank 1:              else Fail('unknown trainingCriterion ' + trainingCriterion)
MPI Rank 1:         Err = if evalCriterion == 'Err' then
MPI Rank 1:               ErrorPrediction(labels, outZ, tag='evaluation')
MPI Rank 1:               else Fail('unknown evalCriterion ' + evalCriterion)
MPI Rank 1:         logPrior = LogPrior(labels)
MPI Rank 1:         // TODO: how to add a tag to an infix operation?
MPI Rank 1:         ScaledLogLikelihood = Minus (outZ, logPrior, tag='output')
MPI Rank 1:     ]
MPI Rank 1:     SGD = [
MPI Rank 1:         epochSize = 20480
MPI Rank 1:         minibatchSize = 64:256:1024
MPI Rank 1:         learningRatesPerMB = 1.0:0.5:0.1
MPI Rank 1:         numMBsToShowResult = 3
MPI Rank 1:         momentumPerMB = 0.9:0.656119
MPI Rank 1:         dropoutRate = 0.0
MPI Rank 1:         maxEpochs = 5
MPI Rank 1:         keepCheckPointFiles = true
MPI Rank 1:         clippingThresholdPerSample = 1#INF
MPI Rank 1:         ParallelTrain = [
MPI Rank 1:             parallelizationMethod = "BlockMomentumSGD"
MPI Rank 1:             distributedMBReading = true
MPI Rank 1:             syncPerfStats=1
MPI Rank 1:             BlockMomentumSGD = [
MPI Rank 1:                 blockSizePerWorker=2048
MPI Rank 1:                 resetSGDMomentum=true
MPI Rank 1:                 useNesterovMomentum=true
MPI Rank 1:             ]
MPI Rank 1:         ]
MPI Rank 1:         AutoAdjust = [
MPI Rank 1:             reduceLearnRateIfImproveLessThan = 0
MPI Rank 1:             loadBestModel = true
MPI Rank 1:             increaseLearnRateIfImproveMoreThan = 1000000000
MPI Rank 1:             learnRateDecreaseFactor = 0.5
MPI Rank 1:             learnRateIncreaseFactor = 1.382
MPI Rank 1:             autoAdjustLR = "adjustAfterEpoch"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1:     reader = [
MPI Rank 1:         readerType = "HTKMLFReader"
MPI Rank 1:         readMethod = "blockRandomize"
MPI Rank 1:         miniBatchMode = "partial"
MPI Rank 1:         randomize = "auto"
MPI Rank 1:         verbosity = 0
MPI Rank 1:         features = [
MPI Rank 1:             dim = 363
MPI Rank 1:             type = "real"
MPI Rank 1:             scpFile = "glob_0000.scp"
MPI Rank 1:         ]
MPI Rank 1:         labels = [
MPI Rank 1:             mlfFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf"
MPI Rank 1:             labelMappingFile = "C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list"
MPI Rank 1:             labelDim = 132
MPI Rank 1:             labelType = "category"
MPI Rank 1:         ]
MPI Rank 1:     ]
MPI Rank 1: ] [SGD=[ParallelTrain=[parallelizationStartEpoch=2]]]
MPI Rank 1: 
MPI Rank 1: configparameters: cntk.cntk:stderr=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/stderr
MPI Rank 1: configparameters: cntk.cntk:timestamping=true
MPI Rank 1: 07/15/2016 00:56:08: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
MPI Rank 1: 07/15/2016 00:56:08: Commands: speechTrain
MPI Rank 1: 07/15/2016 00:56:08: Precision = "double"
MPI Rank 1: 07/15/2016 00:56:08: Using 2 CPU threads.
MPI Rank 1: 07/15/2016 00:56:08: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn
MPI Rank 1: 07/15/2016 00:56:08: CNTKCommandTrainInfo: speechTrain : 5
MPI Rank 1: 07/15/2016 00:56:08: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 5
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:08: ##############################################################################
MPI Rank 1: 07/15/2016 00:56:08: #                                                                            #
MPI Rank 1: 07/15/2016 00:56:08: # Action "train"                                                             #
MPI Rank 1: 07/15/2016 00:56:08: #                                                                            #
MPI Rank 1: 07/15/2016 00:56:08: ##############################################################################
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:08: CNTKCommandTrainBegin: speechTrain
MPI Rank 1: SimpleNetworkBuilder Using GPU 0
MPI Rank 1: reading script file glob_0000.scp ... 946 entries
MPI Rank 1: total 132 state names in state list C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/state.list
MPI Rank 1: htkmlfreader: reading MLF file C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/glob_0000.mlf ... total 948 entries
MPI Rank 1: ...............................................................................................feature set 0: 252508 frames in 946 out of 946 utterances
MPI Rank 1: label set 0: 129 classes
MPI Rank 1: minibatchutterancesource: 946 utterances grouped into 3 chunks, av. chunk size: 315.3 utterances, 84169.3 frames
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:09: Creating virgin network.
MPI Rank 1: Microsoft::MSR::CNTK::GPUMatrix<ElemType>::SetUniformRandomValue (GPU): creating curand object with seed 1, sizeof(ElemType)==8
MPI Rank 1: 
MPI Rank 1: Post-processing network...
MPI Rank 1: 
MPI Rank 1: 7 roots:
MPI Rank 1: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
MPI Rank 1: 	EvalErrorPrediction = ErrorPrediction()
MPI Rank 1: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 	MeanOfFeatures = Mean()
MPI Rank 1: 	PosteriorProb = Softmax()
MPI Rank 1: 	Prior = Mean()
MPI Rank 1: 	ScaledLogLikelihood = Minus()
MPI Rank 1: 
MPI Rank 1: Validating network. 25 nodes to process in pass 1.
MPI Rank 1: 
MPI Rank 1: Validating --> labels = InputValue() :  -> [132 x *]
MPI Rank 1: Validating --> W2 = LearnableParameter() :  -> [132 x 512]
MPI Rank 1: Validating --> W1 = LearnableParameter() :  -> [512 x 512]
MPI Rank 1: Validating --> W0 = LearnableParameter() :  -> [512 x 363]
MPI Rank 1: Validating --> features = InputValue() :  -> [363 x *]
MPI Rank 1: Validating --> MeanOfFeatures = Mean (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> InvStdOfFeatures = InvStdDev (features) : [363 x *] -> [363]
MPI Rank 1: Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [363 x *], [363], [363] -> [363 x *]
MPI Rank 1: Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [512 x 363], [363 x *] -> [512 x *]
MPI Rank 1: Validating --> B0 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W0*features+B0 = Plus (W0*features, B0) : [512 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H1 = Sigmoid (W0*features+B0) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W1*H1 = Times (W1, H1) : [512 x 512], [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> B1 = LearnableParameter() :  -> [512 x 1]
MPI Rank 1: Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [512 x 1 x *], [512 x 1] -> [512 x 1 x *]
MPI Rank 1: Validating --> H2 = Sigmoid (W1*H1+B1) : [512 x 1 x *] -> [512 x 1 x *]
MPI Rank 1: Validating --> W2*H1 = Times (W2, H2) : [132 x 512], [512 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> B2 = LearnableParameter() :  -> [132 x 1]
MPI Rank 1: Validating --> HLast = Plus (W2*H1, B2) : [132 x 1 x *], [132 x 1] -> [132 x 1 x *]
MPI Rank 1: Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [132 x *], [132 x 1 x *] -> [1]
MPI Rank 1: Validating --> PosteriorProb = Softmax (HLast) : [132 x 1 x *] -> [132 x 1 x *]
MPI Rank 1: Validating --> Prior = Mean (labels) : [132 x *] -> [132]
MPI Rank 1: Validating --> LogOfPrior = Log (Prior) : [132] -> [132]
MPI Rank 1: Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [132 x 1 x *], [132] -> [132 x 1 x *]
MPI Rank 1: 
MPI Rank 1: Validating network. 17 nodes to process in pass 2.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Validating network, final pass.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 12 out of 25 nodes do not share the minibatch layout with the input data.
MPI Rank 1: 
MPI Rank 1: Post-processing network complete.
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:09: Created model with 25 nodes on GPU 0.
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:09: Training criterion node(s):
MPI Rank 1: 07/15/2016 00:56:09: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:09: Evaluation criterion node(s):
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:09: 	EvalErrorPrediction = ErrorPrediction
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: Allocating matrices for forward and/or backward propagation.
MPI Rank 1: 
MPI Rank 1: Memory Sharing Structure:
MPI Rank 1: 
MPI Rank 1: 0000000000000000: {[EvalErrorPrediction Gradient[1]] [InvStdOfFeatures Gradient[363]] [LogOfPrior Gradient[132]] [MVNormalizedFeatures Gradient[363 x *]] [MeanOfFeatures Gradient[363]] [PosteriorProb Gradient[132 x 1 x *]] [PosteriorProb Value[132 x 1 x *]] [Prior Gradient[132]] [ScaledLogLikelihood Gradient[132 x 1 x *]] [features Gradient[363 x *]] [labels Gradient[132 x *]] }
MPI Rank 1: 0000009DA0DB01C0: {[W0 Value[512 x 363]] }
MPI Rank 1: 0000009DA0DB0D00: {[InvStdOfFeatures Value[363]] }
MPI Rank 1: 0000009DA0DB1200: {[MeanOfFeatures Value[363]] }
MPI Rank 1: 0000009DA111A8A0: {[B1 Gradient[512 x 1]] [H2 Gradient[512 x 1 x *]] [HLast Gradient[132 x 1 x *]] }
MPI Rank 1: 0000009DA111A940: {[B2 Gradient[132 x 1]] }
MPI Rank 1: 0000009DA111B3E0: {[W2*H1 Gradient[132 x 1 x *]] }
MPI Rank 1: 0000009DA111B5C0: {[CrossEntropyWithSoftmax Gradient[1]] }
MPI Rank 1: 0000009DA132BD80: {[B2 Value[132 x 1]] }
MPI Rank 1: 0000009DA132BE20: {[B0 Value[512 x 1]] }
MPI Rank 1: 0000009DA132BF60: {[B1 Value[512 x 1]] }
MPI Rank 1: 0000009DA132C460: {[ScaledLogLikelihood Value[132 x 1 x *]] }
MPI Rank 1: 0000009DA132C500: {[CrossEntropyWithSoftmax Value[1]] }
MPI Rank 1: 0000009DA132C5A0: {[LogOfPrior Value[132]] }
MPI Rank 1: 0000009DA132C640: {[W0*features Value[512 x *]] }
MPI Rank 1: 0000009DA132C6E0: {[W0*features+B0 Gradient[512 x 1 x *]] [W1*H1 Value[512 x 1 x *]] }
MPI Rank 1: 0000009DA132CAA0: {[Prior Value[132]] }
MPI Rank 1: 0000009DA132CBE0: {[MVNormalizedFeatures Value[363 x *]] }
MPI Rank 1: 0000009DA132CDC0: {[labels Value[132 x *]] }
MPI Rank 1: 0000009DA132CF00: {[W0 Gradient[512 x 363]] [W0*features+B0 Value[512 x 1 x *]] }
MPI Rank 1: 0000009DA132CFA0: {[W2 Value[132 x 512]] }
MPI Rank 1: 0000009DA132D360: {[EvalErrorPrediction Value[1]] }
MPI Rank 1: 0000009DA132D5E0: {[H1 Value[512 x 1 x *]] [W0*features Gradient[512 x *]] }
MPI Rank 1: 0000009DA132D680: {[W1 Gradient[512 x 512]] [W1*H1+B1 Value[512 x 1 x *]] }
MPI Rank 1: 0000009DA132D720: {[W1 Value[512 x 512]] }
MPI Rank 1: 0000009DA132D860: {[H2 Value[512 x 1 x *]] [W1*H1 Gradient[512 x 1 x *]] }
MPI Rank 1: 0000009DA132D900: {[B0 Gradient[512 x 1]] [H1 Gradient[512 x 1 x *]] [W1*H1+B1 Gradient[512 x 1 x *]] [W2*H1 Value[132 x 1 x *]] }
MPI Rank 1: 0000009DA132D9A0: {[HLast Value[132 x 1 x *]] [W2 Gradient[132 x 512]] }
MPI Rank 1: 0000009DFE1C4870: {[features Value[363 x *]] }
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:09: Precomputing --> 3 PreCompute nodes found.
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:09: 	MeanOfFeatures = Mean()
MPI Rank 1: 07/15/2016 00:56:09: 	InvStdOfFeatures = InvStdDev()
MPI Rank 1: 07/15/2016 00:56:09: 	Prior = Mean()
MPI Rank 1: minibatchiterator: epoch 0: frames [0..252508] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: requiredata: determined feature kind as 33-dimensional 'USER' with frame shift 10.0 ms
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:11: Precomputing --> Completed.
MPI Rank 1: 
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:11: Starting Epoch 1: learning rate per sample = 0.015625  effective momentum = 0.900000  momentum as time constant = 607.4 samples
MPI Rank 1: minibatchiterator: epoch 0: frames [0..20480] (first utterance at frame 0), data subset 0 of 1, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:11: Starting minibatch loop.
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[   1-   3, 0.94%]: CrossEntropyWithSoftmax = 4.54985671 * 192; EvalErrorPrediction = 0.90625000 * 192; time = 0.0294s; samplesPerSecond = 6538.0
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[   4-   6, 1.88%]: CrossEntropyWithSoftmax = 4.62421727 * 192; EvalErrorPrediction = 0.89062500 * 192; time = 0.0265s; samplesPerSecond = 7234.6
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[   7-   9, 2.81%]: CrossEntropyWithSoftmax = 4.60673092 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0258s; samplesPerSecond = 7438.4
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  10-  12, 3.75%]: CrossEntropyWithSoftmax = 4.97632255 * 192; EvalErrorPrediction = 0.94270833 * 192; time = 0.0270s; samplesPerSecond = 7120.9
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  13-  15, 4.69%]: CrossEntropyWithSoftmax = 4.66584622 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0269s; samplesPerSecond = 7132.0
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  16-  18, 5.63%]: CrossEntropyWithSoftmax = 4.18831920 * 192; EvalErrorPrediction = 0.92708333 * 192; time = 0.0268s; samplesPerSecond = 7158.0
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  19-  21, 6.56%]: CrossEntropyWithSoftmax = 4.13295634 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.0269s; samplesPerSecond = 7133.8
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  22-  24, 7.50%]: CrossEntropyWithSoftmax = 4.18511141 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0269s; samplesPerSecond = 7143.4
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  25-  27, 8.44%]: CrossEntropyWithSoftmax = 3.98331448 * 192; EvalErrorPrediction = 0.91666667 * 192; time = 0.0268s; samplesPerSecond = 7156.7
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  28-  30, 9.38%]: CrossEntropyWithSoftmax = 4.16919401 * 192; EvalErrorPrediction = 0.92187500 * 192; time = 0.0269s; samplesPerSecond = 7137.8
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  31-  33, 10.31%]: CrossEntropyWithSoftmax = 4.09981466 * 192; EvalErrorPrediction = 0.93750000 * 192; time = 0.0269s; samplesPerSecond = 7128.8
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  34-  36, 11.25%]: CrossEntropyWithSoftmax = 3.83972586 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0269s; samplesPerSecond = 7137.8
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  37-  39, 12.19%]: CrossEntropyWithSoftmax = 3.75721610 * 192; EvalErrorPrediction = 0.85937500 * 192; time = 0.0269s; samplesPerSecond = 7137.3
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  40-  42, 13.13%]: CrossEntropyWithSoftmax = 3.79732611 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0268s; samplesPerSecond = 7158.3
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  43-  45, 14.06%]: CrossEntropyWithSoftmax = 3.86692363 * 192; EvalErrorPrediction = 0.88541667 * 192; time = 0.0269s; samplesPerSecond = 7134.9
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  46-  48, 15.00%]: CrossEntropyWithSoftmax = 3.67286346 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0267s; samplesPerSecond = 7180.3
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  49-  51, 15.94%]: CrossEntropyWithSoftmax = 3.87106136 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0269s; samplesPerSecond = 7139.1
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  52-  54, 16.88%]: CrossEntropyWithSoftmax = 3.75056797 * 192; EvalErrorPrediction = 0.90104167 * 192; time = 0.0270s; samplesPerSecond = 7118.0
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  55-  57, 17.81%]: CrossEntropyWithSoftmax = 3.84544346 * 192; EvalErrorPrediction = 0.88541667 * 192; time = 0.0269s; samplesPerSecond = 7138.3
MPI Rank 1: 07/15/2016 00:56:11:  Epoch[ 1 of 5]-Minibatch[  58-  60, 18.75%]: CrossEntropyWithSoftmax = 3.64287052 * 192; EvalErrorPrediction = 0.86458333 * 192; time = 0.0269s; samplesPerSecond = 7147.4
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  61-  63, 19.69%]: CrossEntropyWithSoftmax = 3.92078976 * 192; EvalErrorPrediction = 0.89583333 * 192; time = 0.0268s; samplesPerSecond = 7155.9
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  64-  66, 20.63%]: CrossEntropyWithSoftmax = 3.79566577 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0270s; samplesPerSecond = 7122.7
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  67-  69, 21.56%]: CrossEntropyWithSoftmax = 3.61988387 * 192; EvalErrorPrediction = 0.82291667 * 192; time = 0.0267s; samplesPerSecond = 7182.1
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  70-  72, 22.50%]: CrossEntropyWithSoftmax = 3.74199773 * 192; EvalErrorPrediction = 0.86979167 * 192; time = 0.0270s; samplesPerSecond = 7124.0
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  73-  75, 23.44%]: CrossEntropyWithSoftmax = 3.63084952 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0269s; samplesPerSecond = 7133.8
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  76-  78, 24.38%]: CrossEntropyWithSoftmax = 3.45945773 * 192; EvalErrorPrediction = 0.84895833 * 192; time = 0.0269s; samplesPerSecond = 7140.2
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  79-  81, 25.31%]: CrossEntropyWithSoftmax = 3.55141658 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0269s; samplesPerSecond = 7132.5
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  82-  84, 26.25%]: CrossEntropyWithSoftmax = 3.44071315 * 192; EvalErrorPrediction = 0.82291667 * 192; time = 0.0268s; samplesPerSecond = 7154.8
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  85-  87, 27.19%]: CrossEntropyWithSoftmax = 3.31704470 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0268s; samplesPerSecond = 7150.8
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  88-  90, 28.13%]: CrossEntropyWithSoftmax = 3.62294748 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0270s; samplesPerSecond = 7107.7
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  91-  93, 29.06%]: CrossEntropyWithSoftmax = 3.51139878 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.0267s; samplesPerSecond = 7198.6
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  94-  96, 30.00%]: CrossEntropyWithSoftmax = 3.51339983 * 192; EvalErrorPrediction = 0.81250000 * 192; time = 0.0269s; samplesPerSecond = 7135.4
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[  97-  99, 30.94%]: CrossEntropyWithSoftmax = 3.54667155 * 192; EvalErrorPrediction = 0.83854167 * 192; time = 0.0268s; samplesPerSecond = 7162.3
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 100- 102, 31.87%]: CrossEntropyWithSoftmax = 3.43704752 * 192; EvalErrorPrediction = 0.84375000 * 192; time = 0.0268s; samplesPerSecond = 7176.0
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 103- 105, 32.81%]: CrossEntropyWithSoftmax = 3.57815526 * 192; EvalErrorPrediction = 0.81250000 * 192; time = 0.0268s; samplesPerSecond = 7170.6
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 106- 108, 33.75%]: CrossEntropyWithSoftmax = 3.33757570 * 192; EvalErrorPrediction = 0.83333333 * 192; time = 0.0269s; samplesPerSecond = 7133.3
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 109- 111, 34.69%]: CrossEntropyWithSoftmax = 3.15832412 * 192; EvalErrorPrediction = 0.75000000 * 192; time = 0.0269s; samplesPerSecond = 7134.1
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 112- 114, 35.63%]: CrossEntropyWithSoftmax = 3.05551739 * 192; EvalErrorPrediction = 0.78125000 * 192; time = 0.0268s; samplesPerSecond = 7161.5
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 115- 117, 36.56%]: CrossEntropyWithSoftmax = 3.40350558 * 192; EvalErrorPrediction = 0.82812500 * 192; time = 0.0269s; samplesPerSecond = 7127.2
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 118- 120, 37.50%]: CrossEntropyWithSoftmax = 3.18639281 * 192; EvalErrorPrediction = 0.79166667 * 192; time = 0.0268s; samplesPerSecond = 7150.8
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 121- 123, 38.44%]: CrossEntropyWithSoftmax = 3.22695349 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0267s; samplesPerSecond = 7178.4
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 124- 126, 39.38%]: CrossEntropyWithSoftmax = 3.18736051 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0269s; samplesPerSecond = 7145.2
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 127- 129, 40.31%]: CrossEntropyWithSoftmax = 3.26793036 * 192; EvalErrorPrediction = 0.78645833 * 192; time = 0.0267s; samplesPerSecond = 7185.9
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 130- 132, 41.25%]: CrossEntropyWithSoftmax = 3.17620983 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0270s; samplesPerSecond = 7114.8
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 133- 135, 42.19%]: CrossEntropyWithSoftmax = 3.05395443 * 192; EvalErrorPrediction = 0.73958333 * 192; time = 0.0269s; samplesPerSecond = 7141.5
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 136- 138, 43.13%]: CrossEntropyWithSoftmax = 3.17101776 * 192; EvalErrorPrediction = 0.73958333 * 192; time = 0.0268s; samplesPerSecond = 7167.7
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 139- 141, 44.06%]: CrossEntropyWithSoftmax = 3.16266163 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0269s; samplesPerSecond = 7137.5
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 142- 144, 45.00%]: CrossEntropyWithSoftmax = 3.04947943 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0268s; samplesPerSecond = 7176.0
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 145- 147, 45.94%]: CrossEntropyWithSoftmax = 3.03787804 * 192; EvalErrorPrediction = 0.76041667 * 192; time = 0.0269s; samplesPerSecond = 7142.1
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 148- 150, 46.88%]: CrossEntropyWithSoftmax = 3.37505611 * 192; EvalErrorPrediction = 0.79687500 * 192; time = 0.0269s; samplesPerSecond = 7148.4
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 151- 153, 47.81%]: CrossEntropyWithSoftmax = 3.11576940 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0269s; samplesPerSecond = 7147.4
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 154- 156, 48.75%]: CrossEntropyWithSoftmax = 3.09661420 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0268s; samplesPerSecond = 7154.0
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 157- 159, 49.69%]: CrossEntropyWithSoftmax = 3.24909614 * 192; EvalErrorPrediction = 0.77083333 * 192; time = 0.0269s; samplesPerSecond = 7142.9
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 160- 162, 50.63%]: CrossEntropyWithSoftmax = 3.24574806 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0269s; samplesPerSecond = 7126.7
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 163- 165, 51.56%]: CrossEntropyWithSoftmax = 3.22551994 * 192; EvalErrorPrediction = 0.77083333 * 192; time = 0.0269s; samplesPerSecond = 7146.8
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 166- 168, 52.50%]: CrossEntropyWithSoftmax = 3.07646835 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0270s; samplesPerSecond = 7119.3
MPI Rank 1: 07/15/2016 00:56:12:  Epoch[ 1 of 5]-Minibatch[ 169- 171, 53.44%]: CrossEntropyWithSoftmax = 2.96517688 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0269s; samplesPerSecond = 7126.4
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 172- 174, 54.37%]: CrossEntropyWithSoftmax = 3.02513893 * 192; EvalErrorPrediction = 0.78645833 * 192; time = 0.0268s; samplesPerSecond = 7174.4
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 175- 177, 55.31%]: CrossEntropyWithSoftmax = 2.88973893 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0269s; samplesPerSecond = 7143.7
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 178- 180, 56.25%]: CrossEntropyWithSoftmax = 2.75494001 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0268s; samplesPerSecond = 7162.3
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 181- 183, 57.19%]: CrossEntropyWithSoftmax = 3.25271651 * 192; EvalErrorPrediction = 0.80208333 * 192; time = 0.0269s; samplesPerSecond = 7136.5
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 184- 186, 58.13%]: CrossEntropyWithSoftmax = 2.68362652 * 192; EvalErrorPrediction = 0.65104167 * 192; time = 0.0268s; samplesPerSecond = 7150.8
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 187- 189, 59.06%]: CrossEntropyWithSoftmax = 2.91338829 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0268s; samplesPerSecond = 7164.4
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 190- 192, 60.00%]: CrossEntropyWithSoftmax = 2.94477536 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0269s; samplesPerSecond = 7126.2
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 193- 195, 60.94%]: CrossEntropyWithSoftmax = 2.94022818 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0268s; samplesPerSecond = 7167.1
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 196- 198, 61.88%]: CrossEntropyWithSoftmax = 2.76999441 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0269s; samplesPerSecond = 7143.9
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 199- 201, 62.81%]: CrossEntropyWithSoftmax = 2.57738224 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0269s; samplesPerSecond = 7138.9
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 202- 204, 63.75%]: CrossEntropyWithSoftmax = 2.80973999 * 192; EvalErrorPrediction = 0.71354167 * 192; time = 0.0269s; samplesPerSecond = 7135.2
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 205- 207, 64.69%]: CrossEntropyWithSoftmax = 2.80985528 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0268s; samplesPerSecond = 7165.5
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 208- 210, 65.63%]: CrossEntropyWithSoftmax = 2.65858712 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.0268s; samplesPerSecond = 7155.1
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 211- 213, 66.56%]: CrossEntropyWithSoftmax = 2.93366494 * 192; EvalErrorPrediction = 0.70833333 * 192; time = 0.0253s; samplesPerSecond = 7596.4
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 214- 216, 67.50%]: CrossEntropyWithSoftmax = 2.75795196 * 192; EvalErrorPrediction = 0.66666667 * 192; time = 0.0268s; samplesPerSecond = 7176.8
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 217- 219, 68.44%]: CrossEntropyWithSoftmax = 2.77030221 * 192; EvalErrorPrediction = 0.73437500 * 192; time = 0.0268s; samplesPerSecond = 7159.1
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 220- 222, 69.38%]: CrossEntropyWithSoftmax = 2.93586418 * 192; EvalErrorPrediction = 0.76562500 * 192; time = 0.0268s; samplesPerSecond = 7157.2
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 223- 225, 70.31%]: CrossEntropyWithSoftmax = 2.56269117 * 192; EvalErrorPrediction = 0.69270833 * 192; time = 0.0269s; samplesPerSecond = 7139.4
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 226- 228, 71.25%]: CrossEntropyWithSoftmax = 2.68413019 * 192; EvalErrorPrediction = 0.64583333 * 192; time = 0.0268s; samplesPerSecond = 7163.4
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 229- 231, 72.19%]: CrossEntropyWithSoftmax = 2.61743301 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0267s; samplesPerSecond = 7183.2
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 232- 234, 73.13%]: CrossEntropyWithSoftmax = 2.70835473 * 192; EvalErrorPrediction = 0.68750000 * 192; time = 0.0268s; samplesPerSecond = 7168.2
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 235- 237, 74.06%]: CrossEntropyWithSoftmax = 2.77084696 * 192; EvalErrorPrediction = 0.71875000 * 192; time = 0.0270s; samplesPerSecond = 7116.9
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 238- 240, 75.00%]: CrossEntropyWithSoftmax = 2.72317929 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0269s; samplesPerSecond = 7136.2
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 241- 243, 75.94%]: CrossEntropyWithSoftmax = 2.70887975 * 192; EvalErrorPrediction = 0.65625000 * 192; time = 0.0269s; samplesPerSecond = 7137.5
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 244- 246, 76.88%]: CrossEntropyWithSoftmax = 2.64868942 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0267s; samplesPerSecond = 7185.6
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 247- 249, 77.81%]: CrossEntropyWithSoftmax = 2.75929689 * 192; EvalErrorPrediction = 0.68229167 * 192; time = 0.0269s; samplesPerSecond = 7145.5
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 250- 252, 78.75%]: CrossEntropyWithSoftmax = 2.48219263 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0268s; samplesPerSecond = 7174.6
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 253- 255, 79.69%]: CrossEntropyWithSoftmax = 2.69453834 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0269s; samplesPerSecond = 7150.6
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 256- 258, 80.63%]: CrossEntropyWithSoftmax = 2.36278558 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0268s; samplesPerSecond = 7152.4
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 259- 261, 81.56%]: CrossEntropyWithSoftmax = 2.47682883 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0269s; samplesPerSecond = 7145.8
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 262- 264, 82.50%]: CrossEntropyWithSoftmax = 2.49591450 * 192; EvalErrorPrediction = 0.67708333 * 192; time = 0.0269s; samplesPerSecond = 7132.2
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 265- 267, 83.44%]: CrossEntropyWithSoftmax = 2.48175146 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0269s; samplesPerSecond = 7147.1
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 268- 270, 84.38%]: CrossEntropyWithSoftmax = 2.47786850 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.0268s; samplesPerSecond = 7166.9
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 271- 273, 85.31%]: CrossEntropyWithSoftmax = 2.57285866 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0269s; samplesPerSecond = 7145.8
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 274- 276, 86.25%]: CrossEntropyWithSoftmax = 2.61151360 * 192; EvalErrorPrediction = 0.67187500 * 192; time = 0.0270s; samplesPerSecond = 7121.9
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 277- 279, 87.19%]: CrossEntropyWithSoftmax = 2.47733105 * 192; EvalErrorPrediction = 0.69791667 * 192; time = 0.0269s; samplesPerSecond = 7132.2
MPI Rank 1: 07/15/2016 00:56:13:  Epoch[ 1 of 5]-Minibatch[ 280- 282, 88.13%]: CrossEntropyWithSoftmax = 2.48334402 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0268s; samplesPerSecond = 7171.4
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 283- 285, 89.06%]: CrossEntropyWithSoftmax = 2.39018807 * 192; EvalErrorPrediction = 0.60937500 * 192; time = 0.0269s; samplesPerSecond = 7136.5
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 286- 288, 90.00%]: CrossEntropyWithSoftmax = 2.27697327 * 192; EvalErrorPrediction = 0.56250000 * 192; time = 0.0267s; samplesPerSecond = 7185.9
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 289- 291, 90.94%]: CrossEntropyWithSoftmax = 2.48766249 * 192; EvalErrorPrediction = 0.60416667 * 192; time = 0.0268s; samplesPerSecond = 7170.9
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 292- 294, 91.88%]: CrossEntropyWithSoftmax = 2.56024809 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0270s; samplesPerSecond = 7114.8
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 295- 297, 92.81%]: CrossEntropyWithSoftmax = 2.37722995 * 192; EvalErrorPrediction = 0.64062500 * 192; time = 0.0269s; samplesPerSecond = 7139.1
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 298- 300, 93.75%]: CrossEntropyWithSoftmax = 2.24144919 * 192; EvalErrorPrediction = 0.59895833 * 192; time = 0.0270s; samplesPerSecond = 7122.2
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 301- 303, 94.69%]: CrossEntropyWithSoftmax = 2.47716220 * 192; EvalErrorPrediction = 0.62500000 * 192; time = 0.0270s; samplesPerSecond = 7117.7
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 304- 306, 95.63%]: CrossEntropyWithSoftmax = 2.30606477 * 192; EvalErrorPrediction = 0.57812500 * 192; time = 0.0267s; samplesPerSecond = 7178.6
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 307- 309, 96.56%]: CrossEntropyWithSoftmax = 2.32237792 * 192; EvalErrorPrediction = 0.58854167 * 192; time = 0.0269s; samplesPerSecond = 7137.3
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 310- 312, 97.50%]: CrossEntropyWithSoftmax = 2.36995349 * 192; EvalErrorPrediction = 0.63541667 * 192; time = 0.0269s; samplesPerSecond = 7139.9
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 313- 315, 98.44%]: CrossEntropyWithSoftmax = 2.21978806 * 192; EvalErrorPrediction = 0.59375000 * 192; time = 0.0269s; samplesPerSecond = 7134.4
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 1 of 5]-Minibatch[ 316- 318, 99.38%]: CrossEntropyWithSoftmax = 2.67073901 * 192; EvalErrorPrediction = 0.66145833 * 192; time = 0.0269s; samplesPerSecond = 7137.0
MPI Rank 1: 07/15/2016 00:56:14: Finished Epoch[ 1 of 5]: [Training] CrossEntropyWithSoftmax = 3.15272097 * 20480; EvalErrorPrediction = 0.75156250 * 20480; totalSamplesSeen = 20480; learningRatePerSample = 0.015625; epochTime=2.90559s
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:14: Starting Epoch 2: learning rate per sample = 0.001953  effective momentum = 0.656119  momentum as time constant = 607.5 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 1: frames [20480..40960] (first utterance at frame 20480), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:14: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[   1-   3, 3.75%]: CrossEntropyWithSoftmax = 2.23337621 * 226; EvalErrorPrediction = 0.61504425 * 226; time = 0.0318s; samplesPerSecond = 7105.6
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[   4-   6, 7.50%]: CrossEntropyWithSoftmax = 2.37721863 * 237; EvalErrorPrediction = 0.67932489 * 237; time = 0.0422s; samplesPerSecond = 5622.1
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[   7-   9, 11.25%]: CrossEntropyWithSoftmax = 2.44761176 * 215; EvalErrorPrediction = 0.67441860 * 215; time = 0.0292s; samplesPerSecond = 7370.3
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  10-  12, 15.00%]: CrossEntropyWithSoftmax = 2.16684002 * 222; EvalErrorPrediction = 0.57657658 * 222; time = 0.0389s; samplesPerSecond = 5710.8
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  13-  15, 18.75%]: CrossEntropyWithSoftmax = 2.48864273 * 247; EvalErrorPrediction = 0.66801619 * 247; time = 0.0467s; samplesPerSecond = 5294.3
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  16-  18, 22.50%]: CrossEntropyWithSoftmax = 2.33104235 * 223; EvalErrorPrediction = 0.63677130 * 223; time = 0.0384s; samplesPerSecond = 5801.2
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  19-  21, 26.25%]: CrossEntropyWithSoftmax = 2.17364751 * 215; EvalErrorPrediction = 0.55813953 * 215; time = 0.0284s; samplesPerSecond = 7560.6
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  22-  24, 30.00%]: CrossEntropyWithSoftmax = 2.16293833 * 205; EvalErrorPrediction = 0.56585366 * 205; time = 0.0239s; samplesPerSecond = 8561.3
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  25-  27, 33.75%]: CrossEntropyWithSoftmax = 2.20908176 * 211; EvalErrorPrediction = 0.56872038 * 211; time = 0.0157s; samplesPerSecond = 13442.9
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.32 seconds since last report (0.00 seconds on comm.); 4236 samples processed by 2 workers (2064 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 13.36k samplesPerSecond , throughputPerWorker = 6.68k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  28-  30, 37.50%]: CrossEntropyWithSoftmax = 2.30867479 * 220; EvalErrorPrediction = 0.59545455 * 220; time = 0.0394s; samplesPerSecond = 5577.7
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  31-  33, 41.25%]: CrossEntropyWithSoftmax = 2.16069960 * 224; EvalErrorPrediction = 0.54910714 * 224; time = 0.0394s; samplesPerSecond = 5690.6
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  34-  36, 45.00%]: CrossEntropyWithSoftmax = 2.12774188 * 217; EvalErrorPrediction = 0.53917051 * 217; time = 0.0397s; samplesPerSecond = 5462.3
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  37-  39, 48.75%]: CrossEntropyWithSoftmax = 2.20321154 * 221; EvalErrorPrediction = 0.56561086 * 221; time = 0.0397s; samplesPerSecond = 5572.9
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  40-  42, 52.50%]: CrossEntropyWithSoftmax = 2.21871108 * 240; EvalErrorPrediction = 0.53750000 * 240; time = 0.0406s; samplesPerSecond = 5915.3
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  43-  45, 56.25%]: CrossEntropyWithSoftmax = 2.21383420 * 204; EvalErrorPrediction = 0.54411765 * 204; time = 0.0387s; samplesPerSecond = 5270.1
MPI Rank 1: 07/15/2016 00:56:14:  Epoch[ 2 of 5]-Minibatch[  46-  48, 60.00%]: CrossEntropyWithSoftmax = 2.20676001 * 240; EvalErrorPrediction = 0.54166667 * 240; time = 0.0251s; samplesPerSecond = 9548.4
MPI Rank 1: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  49-  51, 63.75%]: CrossEntropyWithSoftmax = 2.24123519 * 226; EvalErrorPrediction = 0.58849558 * 226; time = 0.0229s; samplesPerSecond = 9875.5
MPI Rank 1: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  52-  54, 67.50%]: CrossEntropyWithSoftmax = 2.07440979 * 214; EvalErrorPrediction = 0.54205607 * 214; time = 0.0164s; samplesPerSecond = 13083.9
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.31 seconds since last report (0.00 seconds on comm.); 4285 samples processed by 2 workers (2103 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 13.74k samplesPerSecond , throughputPerWorker = 6.87k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  55-  57, 71.25%]: CrossEntropyWithSoftmax = 2.10545954 * 246; EvalErrorPrediction = 0.53252033 * 246; time = 0.0359s; samplesPerSecond = 6860.0
MPI Rank 1: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  58-  60, 75.00%]: CrossEntropyWithSoftmax = 2.10885785 * 242; EvalErrorPrediction = 0.55371901 * 242; time = 0.0510s; samplesPerSecond = 4746.1
MPI Rank 1: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  61-  63, 78.75%]: CrossEntropyWithSoftmax = 2.13697232 * 222; EvalErrorPrediction = 0.61711712 * 222; time = 0.0422s; samplesPerSecond = 5254.6
MPI Rank 1: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  64-  66, 82.50%]: CrossEntropyWithSoftmax = 2.23755193 * 225; EvalErrorPrediction = 0.56888889 * 225; time = 0.0401s; samplesPerSecond = 5606.2
MPI Rank 1: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  67-  69, 86.25%]: CrossEntropyWithSoftmax = 2.11367366 * 247; EvalErrorPrediction = 0.58704453 * 247; time = 0.0409s; samplesPerSecond = 6036.9
MPI Rank 1: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  70-  72, 90.00%]: CrossEntropyWithSoftmax = 2.24198951 * 197; EvalErrorPrediction = 0.58375635 * 197; time = 0.0361s; samplesPerSecond = 5451.0
MPI Rank 1: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  73-  75, 93.75%]: CrossEntropyWithSoftmax = 2.24249258 * 224; EvalErrorPrediction = 0.58035714 * 224; time = 0.0252s; samplesPerSecond = 8906.2
MPI Rank 1: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  76-  78, 97.50%]: CrossEntropyWithSoftmax = 2.15132083 * 214; EvalErrorPrediction = 0.57476636 * 214; time = 0.0163s; samplesPerSecond = 13167.6
MPI Rank 1: 07/15/2016 00:56:15:  Epoch[ 2 of 5]-Minibatch[  79-  81, 101.25%]: CrossEntropyWithSoftmax = 2.33070316 * 132; EvalErrorPrediction = 0.59090909 * 132; time = 0.0101s; samplesPerSecond = 13034.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.81 seconds since last report (0.53 seconds on comm.); 11959 samples processed by 2 workers (1789 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 14.72k samplesPerSecond , throughputPerWorker = 7.36k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:15: Finished Epoch[ 2 of 5]: [Training] CrossEntropyWithSoftmax = 2.16612986 * 20480; EvalErrorPrediction = 0.57690430 * 20480; totalSamplesSeen = 40960; learningRatePerSample = 0.001953125; epochTime=1.44228s
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:16: Starting Epoch 3: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 2: frames [40960..61440] (first utterance at frame 40960), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:16: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:16:  Epoch[ 3 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08245867 * 945; EvalErrorPrediction = 0.56507937 * 945; time = 0.1038s; samplesPerSecond = 9104.1
MPI Rank 1: 07/15/2016 00:56:16:  Epoch[ 3 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.04185596 * 884; EvalErrorPrediction = 0.56108597 * 884; time = 0.0923s; samplesPerSecond = 9581.8
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.27 seconds since last report (0.02 seconds on comm.); 4268 samples processed by 2 workers (2141 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.79k samplesPerSecond , throughputPerWorker = 7.89k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:16:  Epoch[ 3 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.07542075 * 901; EvalErrorPrediction = 0.57269700 * 901; time = 0.1231s; samplesPerSecond = 7316.8
MPI Rank 1: 07/15/2016 00:56:16:  Epoch[ 3 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.06228973 * 935; EvalErrorPrediction = 0.56363636 * 935; time = 0.1194s; samplesPerSecond = 7833.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.26 seconds since last report (0.00 seconds on comm.); 4329 samples processed by 2 workers (2141 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 16.53k samplesPerSecond , throughputPerWorker = 8.26k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:16:  Epoch[ 3 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.11783491 * 947; EvalErrorPrediction = 0.57127772 * 947; time = 0.1533s; samplesPerSecond = 6177.1
MPI Rank 1: 07/15/2016 00:56:16:  Epoch[ 3 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 2.10106845 * 965; EvalErrorPrediction = 0.56683938 * 965; time = 0.1335s; samplesPerSecond = 7230.9
MPI Rank 1: 07/15/2016 00:56:16:  Epoch[ 3 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.06791436 * 641; EvalErrorPrediction = 0.58346334 * 641; time = 0.0486s; samplesPerSecond = 13193.6
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.76 seconds since last report (0.51 seconds on comm.); 11883 samples processed by 2 workers (1936 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.58k samplesPerSecond , throughputPerWorker = 7.79k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:17: Finished Epoch[ 3 of 5]: [Training] CrossEntropyWithSoftmax = 2.05996534 * 20480; EvalErrorPrediction = 0.55991211 * 20480; totalSamplesSeen = 61440; learningRatePerSample = 9.7656251e-005; epochTime=1.29589s
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:17: Starting Epoch 4: learning rate per sample = 0.000098  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:17: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:17:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08706172 * 944; EvalErrorPrediction = 0.57097458 * 944; time = 0.1184s; samplesPerSecond = 7971.6
MPI Rank 1: 07/15/2016 00:56:17:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.14912825 * 982; EvalErrorPrediction = 0.58044807 * 982; time = 0.1265s; samplesPerSecond = 7765.1
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.27k samplesPerSecond , throughputPerWorker = 7.63k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:17:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.12963064 * 997; EvalErrorPrediction = 0.57673019 * 997; time = 0.1254s; samplesPerSecond = 7953.0
MPI Rank 1: 07/15/2016 00:56:17:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01132004 * 972; EvalErrorPrediction = 0.56893004 * 972; time = 0.1311s; samplesPerSecond = 7415.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 16.01k samplesPerSecond , throughputPerWorker = 8.00k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:18:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.04710622 * 973; EvalErrorPrediction = 0.56834532 * 973; time = 0.0964s; samplesPerSecond = 10098.0
MPI Rank 1: 07/15/2016 00:56:18:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.97967419 * 946; EvalErrorPrediction = 0.54016913 * 946; time = 0.1325s; samplesPerSecond = 7137.1
MPI Rank 1: 07/15/2016 00:56:18:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.12701050 * 651; EvalErrorPrediction = 0.58832565 * 651; time = 0.0662s; samplesPerSecond = 9834.7
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.76 seconds since last report (0.51 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.47k samplesPerSecond , throughputPerWorker = 7.73k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:18: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.06081675 * 20480; EvalErrorPrediction = 0.56269531 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.7656251e-005; epochTime=1.31909s
MPI Rank 1: 07/15/2016 00:56:18: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:18: learnRatePerSample reduced to 4.8828126e-005
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:19: Starting Epoch 4: learning rate per sample = 0.000049  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:19: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:19:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08723007 * 944; EvalErrorPrediction = 0.57097458 * 944; time = 0.1195s; samplesPerSecond = 7898.1
MPI Rank 1: 07/15/2016 00:56:19:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.14986602 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1237s; samplesPerSecond = 7938.4
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.28 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.46k samplesPerSecond , throughputPerWorker = 7.73k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:19:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13226698 * 997; EvalErrorPrediction = 0.57572718 * 997; time = 0.1242s; samplesPerSecond = 8029.0
MPI Rank 1: 07/15/2016 00:56:19:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01402477 * 972; EvalErrorPrediction = 0.56893004 * 972; time = 0.1295s; samplesPerSecond = 7508.7
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 15.99k samplesPerSecond , throughputPerWorker = 7.99k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:19:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05100894 * 973; EvalErrorPrediction = 0.56834532 * 973; time = 0.0983s; samplesPerSecond = 9899.6
MPI Rank 1: 07/15/2016 00:56:19:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98428127 * 946; EvalErrorPrediction = 0.53805497 * 946; time = 0.1318s; samplesPerSecond = 7175.5
MPI Rank 1: 07/15/2016 00:56:19:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13301889 * 651; EvalErrorPrediction = 0.59139785 * 651; time = 0.0665s; samplesPerSecond = 9790.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.76 seconds since last report (0.51 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.44k samplesPerSecond , throughputPerWorker = 7.72k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:20: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.06545214 * 20480; EvalErrorPrediction = 0.56401367 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 4.8828126e-005; epochTime=1.31727s
MPI Rank 1: 07/15/2016 00:56:20: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:20: learnRatePerSample reduced to 2.4414063e-005
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:20: Starting Epoch 4: learning rate per sample = 0.000024  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:20: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:20:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08731555 * 944; EvalErrorPrediction = 0.57203390 * 944; time = 0.1235s; samplesPerSecond = 7646.0
MPI Rank 1: 07/15/2016 00:56:20:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.15025177 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1216s; samplesPerSecond = 8075.4
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.37k samplesPerSecond , throughputPerWorker = 7.68k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:21:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13365964 * 997; EvalErrorPrediction = 0.57673019 * 997; time = 0.1238s; samplesPerSecond = 8051.4
MPI Rank 1: 07/15/2016 00:56:21:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01544263 * 972; EvalErrorPrediction = 0.56893004 * 972; time = 0.1285s; samplesPerSecond = 7563.8
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.27 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 16.06k samplesPerSecond , throughputPerWorker = 8.03k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:21:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05311396 * 973; EvalErrorPrediction = 0.56937307 * 973; time = 0.0980s; samplesPerSecond = 9923.8
MPI Rank 1: 07/15/2016 00:56:21:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98684172 * 946; EvalErrorPrediction = 0.53911205 * 946; time = 0.1328s; samplesPerSecond = 7123.2
MPI Rank 1: 07/15/2016 00:56:21:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13628540 * 651; EvalErrorPrediction = 0.58832565 * 651; time = 0.0685s; samplesPerSecond = 9504.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.52 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.26k samplesPerSecond , throughputPerWorker = 7.63k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:22: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.06826797 * 20480; EvalErrorPrediction = 0.56489258 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 2.4414063e-005; epochTime=1.32742s
MPI Rank 1: 07/15/2016 00:56:22: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:22: learnRatePerSample reduced to 1.2207031e-005
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:22: Starting Epoch 4: learning rate per sample = 0.000012  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:22: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:22:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08735862 * 944; EvalErrorPrediction = 0.57203390 * 944; time = 0.1248s; samplesPerSecond = 7563.4
MPI Rank 1: 07/15/2016 00:56:22:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.15044903 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1235s; samplesPerSecond = 7952.2
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.14k samplesPerSecond , throughputPerWorker = 7.57k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:22:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13437613 * 997; EvalErrorPrediction = 0.57472417 * 997; time = 0.1274s; samplesPerSecond = 7827.1
MPI Rank 1: 07/15/2016 00:56:22:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01617096 * 972; EvalErrorPrediction = 0.56995885 * 972; time = 0.1313s; samplesPerSecond = 7404.1
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 15.73k samplesPerSecond , throughputPerWorker = 7.86k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:22:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05421263 * 973; EvalErrorPrediction = 0.56834532 * 973; time = 0.0987s; samplesPerSecond = 9862.0
MPI Rank 1: 07/15/2016 00:56:23:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98820094 * 946; EvalErrorPrediction = 0.54228330 * 946; time = 0.1331s; samplesPerSecond = 7107.9
MPI Rank 1: 07/15/2016 00:56:23:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13799688 * 651; EvalErrorPrediction = 0.58678955 * 651; time = 0.0681s; samplesPerSecond = 9566.1
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.52 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.24k samplesPerSecond , throughputPerWorker = 7.62k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:23: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.06988452 * 20480; EvalErrorPrediction = 0.56557617 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 1.2207031e-005; epochTime=1.33775s
MPI Rank 1: 07/15/2016 00:56:23: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:23: learnRatePerSample reduced to 6.1035157e-006
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:23: Starting Epoch 4: learning rate per sample = 0.000006  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:23: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:24:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08738024 * 944; EvalErrorPrediction = 0.57203390 * 944; time = 0.1251s; samplesPerSecond = 7546.7
MPI Rank 1: 07/15/2016 00:56:24:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.15054878 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1233s; samplesPerSecond = 7963.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.14k samplesPerSecond , throughputPerWorker = 7.57k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:24:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13473962 * 997; EvalErrorPrediction = 0.57472417 * 997; time = 0.1267s; samplesPerSecond = 7868.2
MPI Rank 1: 07/15/2016 00:56:24:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01654039 * 972; EvalErrorPrediction = 0.56995885 * 972; time = 0.1308s; samplesPerSecond = 7430.3
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 15.85k samplesPerSecond , throughputPerWorker = 7.93k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:24:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05477475 * 973; EvalErrorPrediction = 0.56937307 * 973; time = 0.0974s; samplesPerSecond = 9990.9
MPI Rank 1: 07/15/2016 00:56:24:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98890279 * 946; EvalErrorPrediction = 0.54228330 * 946; time = 0.1332s; samplesPerSecond = 7100.2
MPI Rank 1: 07/15/2016 00:56:24:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13887466 * 651; EvalErrorPrediction = 0.58678955 * 651; time = 0.0675s; samplesPerSecond = 9645.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.52 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.23k samplesPerSecond , throughputPerWorker = 7.61k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:25: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07076247 * 20480; EvalErrorPrediction = 0.56601563 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 6.1035157e-006; epochTime=1.33615s
MPI Rank 1: 07/15/2016 00:56:25: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:25: learnRatePerSample reduced to 3.0517579e-006
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:25: Starting Epoch 4: learning rate per sample = 0.000003  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:25: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:25:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08739107 * 944; EvalErrorPrediction = 0.57203390 * 944; time = 0.1256s; samplesPerSecond = 7516.5
MPI Rank 1: 07/15/2016 00:56:25:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.15059894 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1236s; samplesPerSecond = 7942.2
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.07k samplesPerSecond , throughputPerWorker = 7.54k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:25:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13492270 * 997; EvalErrorPrediction = 0.57472417 * 997; time = 0.1266s; samplesPerSecond = 7874.0
MPI Rank 1: 07/15/2016 00:56:25:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01672649 * 972; EvalErrorPrediction = 0.56995885 * 972; time = 0.1314s; samplesPerSecond = 7395.7
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 15.82k samplesPerSecond , throughputPerWorker = 7.91k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:26:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05505919 * 973; EvalErrorPrediction = 0.56937307 * 973; time = 0.0977s; samplesPerSecond = 9960.2
MPI Rank 1: 07/15/2016 00:56:26:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98925964 * 946; EvalErrorPrediction = 0.54228330 * 946; time = 0.1332s; samplesPerSecond = 7104.6
MPI Rank 1: 07/15/2016 00:56:26:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13931945 * 651; EvalErrorPrediction = 0.58678955 * 651; time = 0.0682s; samplesPerSecond = 9546.7
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.52 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.26k samplesPerSecond , throughputPerWorker = 7.63k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:26: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07122168 * 20480; EvalErrorPrediction = 0.56601563 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 3.0517579e-006; epochTime=1.33624s
MPI Rank 1: 07/15/2016 00:56:26: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:26: learnRatePerSample reduced to 1.5258789e-006
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:27: Starting Epoch 4: learning rate per sample = 0.000002  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:27: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:27:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08739649 * 944; EvalErrorPrediction = 0.57203390 * 944; time = 0.1203s; samplesPerSecond = 7845.9
MPI Rank 1: 07/15/2016 00:56:27:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.15062409 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1242s; samplesPerSecond = 7909.4
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.38k samplesPerSecond , throughputPerWorker = 7.69k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:27:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13501458 * 997; EvalErrorPrediction = 0.57372116 * 997; time = 0.1260s; samplesPerSecond = 7915.6
MPI Rank 1: 07/15/2016 00:56:27:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01681989 * 972; EvalErrorPrediction = 0.56995885 * 972; time = 0.1315s; samplesPerSecond = 7389.4
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 15.72k samplesPerSecond , throughputPerWorker = 7.86k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:27:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05520228 * 973; EvalErrorPrediction = 0.57040082 * 973; time = 0.0993s; samplesPerSecond = 9794.4
MPI Rank 1: 07/15/2016 00:56:27:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98943960 * 946; EvalErrorPrediction = 0.54228330 * 946; time = 0.1331s; samplesPerSecond = 7106.2
MPI Rank 1: 07/15/2016 00:56:27:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13954337 * 651; EvalErrorPrediction = 0.58678955 * 651; time = 0.0680s; samplesPerSecond = 9567.3
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.52 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.25k samplesPerSecond , throughputPerWorker = 7.62k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:28: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07145673 * 20480; EvalErrorPrediction = 0.56625977 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 1.5258789e-006; epochTime=1.33298s
MPI Rank 1: 07/15/2016 00:56:28: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:28: learnRatePerSample reduced to 7.6293946e-007
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:28: Starting Epoch 4: learning rate per sample = 0.000001  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:28: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:28:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08739920 * 944; EvalErrorPrediction = 0.57203390 * 944; time = 0.1247s; samplesPerSecond = 7568.1
MPI Rank 1: 07/15/2016 00:56:28:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.15063668 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1243s; samplesPerSecond = 7903.0
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.13k samplesPerSecond , throughputPerWorker = 7.57k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:29:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13506060 * 997; EvalErrorPrediction = 0.57372116 * 997; time = 0.1318s; samplesPerSecond = 7567.2
MPI Rank 1: 07/15/2016 00:56:29:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01686668 * 972; EvalErrorPrediction = 0.56995885 * 972; time = 0.1297s; samplesPerSecond = 7495.3
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 15.60k samplesPerSecond , throughputPerWorker = 7.80k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:29:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05527404 * 973; EvalErrorPrediction = 0.57040082 * 973; time = 0.0975s; samplesPerSecond = 9983.1
MPI Rank 1: 07/15/2016 00:56:29:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98952996 * 946; EvalErrorPrediction = 0.54228330 * 946; time = 0.1328s; samplesPerSecond = 7126.0
MPI Rank 1: 07/15/2016 00:56:29:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13965572 * 651; EvalErrorPrediction = 0.58678955 * 651; time = 0.0675s; samplesPerSecond = 9645.4
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.52 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.26k samplesPerSecond , throughputPerWorker = 7.63k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:29: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07157567 * 20480; EvalErrorPrediction = 0.56640625 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 7.6293946e-007; epochTime=1.3388s
MPI Rank 1: 07/15/2016 00:56:29: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:30: learnRatePerSample reduced to 3.8146973e-007
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:30: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:30: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:30:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08740056 * 944; EvalErrorPrediction = 0.57203390 * 944; time = 0.1251s; samplesPerSecond = 7545.3
MPI Rank 1: 07/15/2016 00:56:30:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.15064298 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1240s; samplesPerSecond = 7921.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.13k samplesPerSecond , throughputPerWorker = 7.56k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:30:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13508364 * 997; EvalErrorPrediction = 0.57372116 * 997; time = 0.1258s; samplesPerSecond = 7927.2
MPI Rank 1: 07/15/2016 00:56:30:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01689009 * 972; EvalErrorPrediction = 0.56995885 * 972; time = 0.1319s; samplesPerSecond = 7369.9
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 15.79k samplesPerSecond , throughputPerWorker = 7.90k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:30:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05530998 * 973; EvalErrorPrediction = 0.57040082 * 973; time = 0.0979s; samplesPerSecond = 9936.4
MPI Rank 1: 07/15/2016 00:56:30:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98957525 * 946; EvalErrorPrediction = 0.54228330 * 946; time = 0.1338s; samplesPerSecond = 7070.6
MPI Rank 1: 07/15/2016 00:56:31:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13971199 * 651; EvalErrorPrediction = 0.58678955 * 651; time = 0.0679s; samplesPerSecond = 9587.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.52 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.24k samplesPerSecond , throughputPerWorker = 7.62k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:31: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07163550 * 20480; EvalErrorPrediction = 0.56650391 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 3.8146973e-007; epochTime=1.33681s
MPI Rank 1: 07/15/2016 00:56:31: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:31: learnRatePerSample reduced to 1.9073487e-007
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:31: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:31: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:31:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08740123 * 944; EvalErrorPrediction = 0.57203390 * 944; time = 0.1204s; samplesPerSecond = 7842.4
MPI Rank 1: 07/15/2016 00:56:32:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.15064613 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1278s; samplesPerSecond = 7686.9
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.18k samplesPerSecond , throughputPerWorker = 7.59k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:32:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13509516 * 997; EvalErrorPrediction = 0.57372116 * 997; time = 0.1275s; samplesPerSecond = 7820.7
MPI Rank 1: 07/15/2016 00:56:32:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01690181 * 972; EvalErrorPrediction = 0.56995885 * 972; time = 0.1312s; samplesPerSecond = 7407.7
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 15.71k samplesPerSecond , throughputPerWorker = 7.86k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:32:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05532796 * 973; EvalErrorPrediction = 0.57040082 * 973; time = 0.0987s; samplesPerSecond = 9863.0
MPI Rank 1: 07/15/2016 00:56:32:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98959791 * 946; EvalErrorPrediction = 0.54228330 * 946; time = 0.1332s; samplesPerSecond = 7103.9
MPI Rank 1: 07/15/2016 00:56:32:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13974015 * 651; EvalErrorPrediction = 0.58678955 * 651; time = 0.0670s; samplesPerSecond = 9716.1
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.51 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.28k samplesPerSecond , throughputPerWorker = 7.64k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:33: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07166550 * 20480; EvalErrorPrediction = 0.56645508 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 1.9073487e-007; epochTime=1.33514s
MPI Rank 1: 07/15/2016 00:56:33: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:33: learnRatePerSample reduced to 9.5367433e-008
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:33: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:33: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:33:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08740157 * 944; EvalErrorPrediction = 0.57203390 * 944; time = 0.0960s; samplesPerSecond = 9831.0
MPI Rank 1: 07/15/2016 00:56:33:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.15064771 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1411s; samplesPerSecond = 6960.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.32k samplesPerSecond , throughputPerWorker = 7.66k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:33:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13510092 * 997; EvalErrorPrediction = 0.57372116 * 997; time = 0.1348s; samplesPerSecond = 7396.3
MPI Rank 1: 07/15/2016 00:56:33:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01690766 * 972; EvalErrorPrediction = 0.56893004 * 972; time = 0.1310s; samplesPerSecond = 7421.4
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 15.74k samplesPerSecond , throughputPerWorker = 7.87k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:34:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05533695 * 973; EvalErrorPrediction = 0.57040082 * 973; time = 0.0991s; samplesPerSecond = 9820.5
MPI Rank 1: 07/15/2016 00:56:34:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98960925 * 946; EvalErrorPrediction = 0.54228330 * 946; time = 0.1338s; samplesPerSecond = 7072.3
MPI Rank 1: 07/15/2016 00:56:34:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13975424 * 651; EvalErrorPrediction = 0.58678955 * 651; time = 0.0688s; samplesPerSecond = 9461.9
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.52 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.23k samplesPerSecond , throughputPerWorker = 7.62k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:34: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07168053 * 20480; EvalErrorPrediction = 0.56635742 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 9.5367433e-008; epochTime=1.3344s
MPI Rank 1: 07/15/2016 00:56:34: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:34: learnRatePerSample reduced to 4.7683717e-008
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:35: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:35: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:35:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08740174 * 944; EvalErrorPrediction = 0.57203390 * 944; time = 0.1240s; samplesPerSecond = 7610.8
MPI Rank 1: 07/15/2016 00:56:35:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.15064850 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1253s; samplesPerSecond = 7839.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.12k samplesPerSecond , throughputPerWorker = 7.56k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:35:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13510380 * 997; EvalErrorPrediction = 0.57372116 * 997; time = 0.1252s; samplesPerSecond = 7965.6
MPI Rank 1: 07/15/2016 00:56:35:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01691059 * 972; EvalErrorPrediction = 0.56893004 * 972; time = 0.1309s; samplesPerSecond = 7425.5
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 15.88k samplesPerSecond , throughputPerWorker = 7.94k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:35:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05534145 * 973; EvalErrorPrediction = 0.57040082 * 973; time = 0.0983s; samplesPerSecond = 9894.1
MPI Rank 1: 07/15/2016 00:56:35:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98961492 * 946; EvalErrorPrediction = 0.54228330 * 946; time = 0.1345s; samplesPerSecond = 7032.0
MPI Rank 1: 07/15/2016 00:56:35:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13976128 * 651; EvalErrorPrediction = 0.58678955 * 651; time = 0.0675s; samplesPerSecond = 9650.0
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.52 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.22k samplesPerSecond , throughputPerWorker = 7.61k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:36: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07168805 * 20480; EvalErrorPrediction = 0.56635742 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 4.7683717e-008; epochTime=1.33706s
MPI Rank 1: 07/15/2016 00:56:36: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:36: learnRatePerSample reduced to 2.3841858e-008
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:36: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:36: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:36:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08740183 * 944; EvalErrorPrediction = 0.57203390 * 944; time = 0.1204s; samplesPerSecond = 7839.4
MPI Rank 1: 07/15/2016 00:56:36:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.15064889 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1245s; samplesPerSecond = 7889.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.36k samplesPerSecond , throughputPerWorker = 7.68k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:37:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13510524 * 997; EvalErrorPrediction = 0.57372116 * 997; time = 0.1258s; samplesPerSecond = 7922.6
MPI Rank 1: 07/15/2016 00:56:37:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01691206 * 972; EvalErrorPrediction = 0.56893004 * 972; time = 0.1312s; samplesPerSecond = 7409.4
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 15.79k samplesPerSecond , throughputPerWorker = 7.90k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:37:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05534370 * 973; EvalErrorPrediction = 0.57040082 * 973; time = 0.0984s; samplesPerSecond = 9888.1
MPI Rank 1: 07/15/2016 00:56:37:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98961776 * 946; EvalErrorPrediction = 0.54228330 * 946; time = 0.1343s; samplesPerSecond = 7044.6
MPI Rank 1: 07/15/2016 00:56:37:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13976481 * 651; EvalErrorPrediction = 0.58678955 * 651; time = 0.0670s; samplesPerSecond = 9723.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.52 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.24k samplesPerSecond , throughputPerWorker = 7.62k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:37: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07169181 * 20480; EvalErrorPrediction = 0.56635742 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 2.3841858e-008; epochTime=1.33234s
MPI Rank 1: 07/15/2016 00:56:37: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:38: learnRatePerSample reduced to 1.1920929e-008
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:38: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:38: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:38:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08740187 * 944; EvalErrorPrediction = 0.57203390 * 944; time = 0.1196s; samplesPerSecond = 7893.3
MPI Rank 1: 07/15/2016 00:56:38:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.15064909 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1253s; samplesPerSecond = 7838.3
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.34k samplesPerSecond , throughputPerWorker = 7.67k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:38:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13510596 * 997; EvalErrorPrediction = 0.57372116 * 997; time = 0.1259s; samplesPerSecond = 7917.3
MPI Rank 1: 07/15/2016 00:56:38:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01691279 * 972; EvalErrorPrediction = 0.56893004 * 972; time = 0.1319s; samplesPerSecond = 7371.0
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 15.70k samplesPerSecond , throughputPerWorker = 7.85k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:38:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05534482 * 973; EvalErrorPrediction = 0.57040082 * 973; time = 0.0994s; samplesPerSecond = 9785.5
MPI Rank 1: 07/15/2016 00:56:38:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98961917 * 946; EvalErrorPrediction = 0.54228330 * 946; time = 0.1342s; samplesPerSecond = 7047.8
MPI Rank 1: 07/15/2016 00:56:39:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13976657 * 651; EvalErrorPrediction = 0.58678955 * 651; time = 0.0666s; samplesPerSecond = 9774.5
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.52 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.25k samplesPerSecond , throughputPerWorker = 7.62k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:39: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07169369 * 20480; EvalErrorPrediction = 0.56635742 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 1.1920929e-008; epochTime=1.33389s
MPI Rank 1: 07/15/2016 00:56:39: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:39: learnRatePerSample reduced to 5.9604646e-009
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:39: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:39: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:39:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08740189 * 944; EvalErrorPrediction = 0.57203390 * 944; time = 0.1243s; samplesPerSecond = 7592.9
MPI Rank 1: 07/15/2016 00:56:40:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.15064919 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1239s; samplesPerSecond = 7925.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.15k samplesPerSecond , throughputPerWorker = 7.57k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:40:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13510632 * 997; EvalErrorPrediction = 0.57372116 * 997; time = 0.1279s; samplesPerSecond = 7792.5
MPI Rank 1: 07/15/2016 00:56:40:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01691316 * 972; EvalErrorPrediction = 0.56893004 * 972; time = 0.1310s; samplesPerSecond = 7417.9
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 15.68k samplesPerSecond , throughputPerWorker = 7.84k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:40:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05534539 * 973; EvalErrorPrediction = 0.57040082 * 973; time = 0.0993s; samplesPerSecond = 9794.4
MPI Rank 1: 07/15/2016 00:56:40:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98961988 * 946; EvalErrorPrediction = 0.54228330 * 946; time = 0.1333s; samplesPerSecond = 7098.6
MPI Rank 1: 07/15/2016 00:56:40:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13976745 * 651; EvalErrorPrediction = 0.58678955 * 651; time = 0.0668s; samplesPerSecond = 9746.8
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.52 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.27k samplesPerSecond , throughputPerWorker = 7.64k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:41: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07169463 * 20480; EvalErrorPrediction = 0.56635742 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 5.9604646e-009; epochTime=1.33669s
MPI Rank 1: 07/15/2016 00:56:41: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:41: learnRatePerSample reduced to 2.9802323e-009
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:41: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:41: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:41:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08740190 * 944; EvalErrorPrediction = 0.57203390 * 944; time = 0.1203s; samplesPerSecond = 7848.5
MPI Rank 1: 07/15/2016 00:56:41:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.15064924 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1251s; samplesPerSecond = 7851.5
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.36k samplesPerSecond , throughputPerWorker = 7.68k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:41:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13510650 * 997; EvalErrorPrediction = 0.57372116 * 997; time = 0.1255s; samplesPerSecond = 7946.5
MPI Rank 1: 07/15/2016 00:56:41:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01691334 * 972; EvalErrorPrediction = 0.56893004 * 972; time = 0.1317s; samplesPerSecond = 7379.1
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 15.76k samplesPerSecond , throughputPerWorker = 7.88k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:41:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05534567 * 973; EvalErrorPrediction = 0.57040082 * 973; time = 0.0982s; samplesPerSecond = 9909.0
MPI Rank 1: 07/15/2016 00:56:42:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98962024 * 946; EvalErrorPrediction = 0.54228330 * 946; time = 0.1334s; samplesPerSecond = 7092.3
MPI Rank 1: 07/15/2016 00:56:42:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13976789 * 651; EvalErrorPrediction = 0.58678955 * 651; time = 0.0672s; samplesPerSecond = 9687.2
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.52 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.28k samplesPerSecond , throughputPerWorker = 7.64k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:42: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07169510 * 20480; EvalErrorPrediction = 0.56635742 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 2.9802323e-009; epochTime=1.33105s
MPI Rank 1: 07/15/2016 00:56:42: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:42: learnRatePerSample reduced to 1.4901161e-009
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:42: Starting Epoch 4: learning rate per sample = 0.000000  effective momentum = 0.656119  momentum as time constant = 2429.9 samples
MPI Rank 1: Parallel training (2 workers) using BlockMomentumSGD with block momentum = 0.5000, block momentum time constant (per worker) = 2954.6394, block learning rate = 1.0000, block size per worker = 2048 samples, using Nesterov-style block momentum, resetting SGD momentum after sync.
MPI Rank 1: minibatchiterator: epoch 3: frames [61440..81920] (first utterance at frame 61440), data subset 1 of 2, with 1 datapasses
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:42: Starting minibatch loop, distributed reading is ENABLED.
MPI Rank 1: 07/15/2016 00:56:43:  Epoch[ 4 of 5]-Minibatch[   1-   3, 15.00%]: CrossEntropyWithSoftmax = 2.08740191 * 944; EvalErrorPrediction = 0.57203390 * 944; time = 0.1247s; samplesPerSecond = 7567.6
MPI Rank 1: 07/15/2016 00:56:43:  Epoch[ 4 of 5]-Minibatch[   4-   6, 30.00%]: CrossEntropyWithSoftmax = 2.15064926 * 982; EvalErrorPrediction = 0.57841141 * 982; time = 0.1243s; samplesPerSecond = 7899.6
MPI Rank 1: 		(model aggregation stats): 1-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 1-th sync:     0.29 seconds since last report (0.00 seconds on comm.); 4392 samples processed by 2 workers (2264 by me);
MPI Rank 1: 		(model aggregation stats) 1-th sync: totalThroughput = 15.17k samplesPerSecond , throughputPerWorker = 7.58k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:43:  Epoch[ 4 of 5]-Minibatch[   7-   9, 45.00%]: CrossEntropyWithSoftmax = 2.13510659 * 997; EvalErrorPrediction = 0.57372116 * 997; time = 0.1251s; samplesPerSecond = 7971.8
MPI Rank 1: 07/15/2016 00:56:43:  Epoch[ 4 of 5]-Minibatch[  10-  12, 60.00%]: CrossEntropyWithSoftmax = 2.01691343 * 972; EvalErrorPrediction = 0.56893004 * 972; time = 0.1315s; samplesPerSecond = 7394.2
MPI Rank 1: 		(model aggregation stats): 2-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 2-th sync:     0.28 seconds since last report (0.00 seconds on comm.); 4376 samples processed by 2 workers (2286 by me);
MPI Rank 1: 		(model aggregation stats) 2-th sync: totalThroughput = 15.83k samplesPerSecond , throughputPerWorker = 7.91k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:43:  Epoch[ 4 of 5]-Minibatch[  13-  15, 75.00%]: CrossEntropyWithSoftmax = 2.05534581 * 973; EvalErrorPrediction = 0.57040082 * 973; time = 0.0982s; samplesPerSecond = 9913.2
MPI Rank 1: 07/15/2016 00:56:43:  Epoch[ 4 of 5]-Minibatch[  16-  18, 90.00%]: CrossEntropyWithSoftmax = 1.98962042 * 946; EvalErrorPrediction = 0.54228330 * 946; time = 0.1338s; samplesPerSecond = 7068.4
MPI Rank 1: 07/15/2016 00:56:43:  Epoch[ 4 of 5]-Minibatch[  19-  21, 105.00%]: CrossEntropyWithSoftmax = 2.13976811 * 651; EvalErrorPrediction = 0.58678955 * 651; time = 0.0684s; samplesPerSecond = 9521.0
MPI Rank 1: 		(model aggregation stats): 3-th sync point was hit, introducing a 0.00-seconds latency this time; accumulated time on sync point = 0.00 seconds , average latency = 0.00 seconds
MPI Rank 1: 		(model aggregation stats) 3-th sync:     0.77 seconds since last report (0.52 seconds on comm.); 11712 samples processed by 2 workers (1915 by me);
MPI Rank 1: 		(model aggregation stats) 3-th sync: totalThroughput = 15.23k samplesPerSecond , throughputPerWorker = 7.61k samplesPerSecond
MPI Rank 1: 07/15/2016 00:56:44: Finished Epoch[ 4 of 5]: [Training] CrossEntropyWithSoftmax = 2.07169534 * 20480; EvalErrorPrediction = 0.56635742 * 20480; totalSamplesSeen = 81920; learningRatePerSample = 1.4901161e-009; epochTime=1.33594s
MPI Rank 1: 07/15/2016 00:56:44: Loading (rolling back to) previous model with best training-criterion value: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160715005451.919244\Speech\DNN_ParallelBM@release_gpu/models/cntkSpeech.dnn.3.
MPI Rank 1: ValidateSubNetwork: InvStdOfFeatures InvStdDev operation changed, from [363 x 1] to [363].ValidateSubNetwork: MeanOfFeatures Mean operation changed, from [363 x 1] to [363].ValidateSubNetwork: Prior Mean operation changed, from [132 x 1] to [132].07/15/2016 00:56:44: learnRatePerSample reduced to 7.4505807e-010
MPI Rank 1: 07/15/2016 00:56:44: Learn Rate Per Sample for Epoch[4] = 7.4505807e-010 is less than minLearnRate 9.9999997e-010. Training complete.
MPI Rank 1: 07/15/2016 00:56:44: CNTKCommandTrainEnd: speechTrain
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:44: Action "train" complete.
MPI Rank 1: 
MPI Rank 1: 07/15/2016 00:56:44: __COMPLETED__
MPI Rank 1: ~MPIWrapper